# Linear Models {#linear}

```{r}
#| include: false
library(rethinking)
library(brms)
library(dplyr)
library(tidyr)
library(tidybayes)
library(tidybayes.rethinking)
library(modelr)
library(simstudy)
library(ggplot2)
library(ggdist)
library(patchwork)
library(paletteer)
library(splines)
```

```{r}
#  For execution on a local, multicore CPU with excess RAM
options(mc.cores = parallel::detectCores())
#  To avoid recompilation of unchanged Stan programs
rstan_options(auto_write = TRUE)
```

```{r}
# The default theme is by the plot
ggplot2::theme_set(ggdist::theme_ggdist())
ggplot2::theme_update(title = element_text(color = "midnightblue"))
```


## 4E1 {#prac4E1 .unnumbered}

See section 4.4.1 in @elreath2020

$y_i \sim \mathcal{N}(\mu, \sigma)$

## 4E2 {#prac4E2 .unnumbered}

2 parameters, $\mu$ and $\sigma$ which are in the posterior distribution $y_i \sim \mathcal{N}(\mu, \sigma)$

## 4E3 {#prac4E3 .unnumbered}

See Overthinking in section 4.3.1

\$\$ \begin{align*}
P(\mu, \sigma \mid \textbf{y}) &=

\frac{
    P(\textbf{y}, \mu, \sigma)
}{
    P(\textbf{y})
} \\

&= \frac{
    P(\textbf{y}, \mu, \sigma)
}{
    \int_{\sigma} \int_{\mu} P(\textbf{y} \mid \mu, \sigma) \cdot P(\mu, \sigma) d\mu d\sigma \\
} \\

&= 

\frac{
    \prod_i P(y_i, \mu, \sigma)
}{
    \int_{\sigma} \int_{\mu} \prod_i P(y_i \mid \mu, \sigma) \cdot P(\mu, \sigma) d\mu d\sigma \\
} \\

&=

\frac{
    \prod_i P(y_i \mid \mu, \sigma) \cdot P(\mu) \cdot P(\sigma)
}{
    \int_{\sigma} \int_{\mu} \prod_i P(y_i \mid \mu, \sigma) \cdot P(\mu) \cdot P(\sigma) d\mu d\sigma \\
} \\

&=

\frac{
    \prod_i \mathcal{N}(y_i \mid \mu, \sigma) \cdot \mathcal{N}(\mu \mid mean = 0, sd = 10) \cdot \mathcal{Exp}(\sigma \mid rate = 1)
}{
    \int_{\sigma} \int_{\mu}{
        \prod_{i=1}^n \mathcal{N}(y_i \mid \mu, \sigma) \cdot \mathcal{N}(\mu \mid mean = 0, sd = 10) \cdot \mathcal{Exp}(\sigma \mid rate = 1)
    }
    d\mu d\sigma
}

\end{align*} \$\$

## 4E4 {#prac4E4 .unnumbered}

$\mu_i = \alpha + \beta x_i$

## 4E5 {#prac4E5 .unnumbered}

2 parameters, $\mu$ and $\sigma$

## 4M1 {#prac4M1 .unnumbered}

See R code 4.13 in section 4.3.2 using this model.

We use the `simstudy` package to do the simulation. It is a wonderful tools to simulate models and will be used repeatedly in this project.

Also we use the `posterior` package to use the many tools this package offers to simplify using posterior samples.

```{r}
sim04M01 <- list()
sim04M01 <- within(sim04M01, {
  def <- defData(varname = "mu", dist = "normal", formula = 0, variance = 10^2)
  def <- defData(def, varname = "sigma", dist = "exponential", formula = 1)
  def <- defData(def, varname = "height", dist = "normal", formula = "mu", 
               variance = "sigma")
  # generate the data
  set.seed(53)  # for fun: 53 is a balanced prime
  data <- genData(n = 5000, dtDefs = def)
  
  # get the intervals
  widths <- c(0.67, 0.95, 1)
  intrvl <- data |>
    select(-id) |>
    pivot_longer(cols = everything()) |>
    group_by(name) |>
    ggdist::median_qi(.width = widths)
  
  # the breaks used for the x axis
  breaks_x <- intrvl |>
    filter(name == "height") |>
    select(.lower, value, .upper) |>
    pivot_longer(cols = everything()) |>
    arrange(value) |>
    pull(value)
  })
```

```{r}
ggplot(sim04M01$data, mapping = aes(x = height)) +
  ggdist::stat_halfeye(aes(fill = after_stat(cut_cdf_qi(cdf, .width = sim04M01$widths))),
                       point_interval = median_qi,
                       color = "darkorange") +
  scale_x_continuous(breaks = sim04M01$breaks_x,
                     labels = scales::label_number(accuracy = 0.1)) +
  scale_fill_paletteer_d("ggsci::indigo_material",
                         direction = 1,
                         name = "levels %",
                         labels = round(100 * sim04M01$widths, 0),
                         na.translate = FALSE) +
  theme(legend.position = c(0.8, 0.8)) +
  labs(title = "4M1: Prior prediction of height", 
       subtitle = sprintf("sample size = %d", nrow(sim04M01$data)))
```

## 4M2 {#prac4M2 .unnumbered}

See section 4.4.2 on how to use `quap`, R code 4.43 with linear equation with the `quap` formula, i.e. `flist = alist(...)`.

```{r eval=FALSE}
alist(
    height ~ dnorm(mean = mu, sd = sigma),
    mu = a + b * x,
    a ~ dnorm(mean = 0, sd = 10),
    b ~ dnorm(mean = 0, sd = 1),
    sigma ~ dexp(rate = 1)
    )
```

## 4M3 {#prac4M3 .unnumbered}

Make sure you remember to index the $y$ so that it is $y_i$ as well as $\mu$. See section 4.4.2. The published answer does not put an index on $\mu$ but it has one on $y$ which involves a constant $\mu$ which is normally the intercept! This question is confusing, here we assume the same meaning as in section 4.4.2., that is $\mu$ varies for each $x_i$

$$
\begin{align*}
y_i &\sim \mathcal{N}(mean = \mu_i, sd = \sigma)\\
\mu_i &= \alpha + \beta x_i \\
\alpha &\sim \mathcal{N}(mean = 0, sd = 10) \\
\beta &\sim \mathcal{Uniform}(mean = 0, sd = 1) \\
\sigma &\sim \mathcal{Exponential}(\lambda = 1)
\end{align*}
$$

## 4M4 {#prac4M4 .unnumbered}

Don't forget the index so that $height$ is $height_i$.

This will be giving the average height per year. The question is not clear that it wants it by student also.

$$
\begin{align*}
height_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta \cdot year_i \\
\alpha &\sim \mathcal{N}(100, 10) \\
\beta &\sim \mathcal{Uniform}(0, 10) \\
\sigma &\sim \mathcal{Exponential}(1)
\end{align*}
$$

The choice of priors are \* $\alpha$: The intercept reflect the population average which is 100 and we expect the 95% of the population to be between 80 and 120 at the very most \* $\beta$: The coefficient should be nonnegative as the height should increase or stay the same in younger age. We choose uniform distribution as we have no information whatsoever about the rate of growth. \* $\sigma$: The overall outcome variance should be positive with a skewed distribution, hence using $\mathcal{Exponential}(1)$. See p. 118 and p. 119 on using the exponential distribution in the textbook.

## 4M5 {#prac4M5 .unnumbered}

This tells us that $\beta$ should always be positive be with large values unlikely. We therefore use the log-normal dist as a prior for $\beta$. See section 4.4.2.

$$
\begin{align*}
height_i &\sim Normal(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta \cdot year_i \\
\alpha &\sim \mathcal{Normal}(100, 10) \\
\beta &\sim \mathcal{LogNormal}(0, 1) \\
\sigma &\sim \mathcal{Exponential}(1)
\end{align*}
$$

## 4M6 {#prac4M6 .unnumbered}

Instead of using the average range as a prior for $\sigma$ we would use $\sigma = \sqrt{64} = 8$.

> In the official solution solution McElreath says it should be $\sigma \sim Uniform(0, 64)$, no sqrt of the *variance* to obtain the *standard deviation* is done.

$$
height_i \sim Normal(\mu_i, \sigma) \\
mu_i = \alpha + \beta \cdot year_i \\
\alpha \sim Normal(120, 10) \\
\beta \sim Normal(0, 10) \\
\sigma \sim Uniform(0, 8)
$$

## 4M7 {#prac4M7 .unnumbered}

See section 4.4.2 for model m4.3. We add the centered weight to the data and call it $weight_c$.

```{r}
data(Howell1)
data04M07 <- Howell1 |>
  filter(age  >= 18) |>
  mutate(weight_c = as.vector(scale(weight, center = TRUE, scale = FALSE)))
rm(Howell1)
skimr::skim(data04M07)
```

### Model {#prac4M7-Model .unnumbered}

$$
\begin{align*}
height_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta(x_i - \bar{x}) \\
\alpha &\sim \mathcal{N}(178, 20) \\
\beta &\sim \mathcal{LogNormal}(0, 1) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

### Fitting strategies {.unnumbered}

This practice is used to illustrate 3 different methods that can be used to fit the model to the data. They are from the package `rethinking` (of course), the very well-known package `brms` that is used in @kurtz2020a and the package `INLA` which state of the art and is explained, for example, by @gomez2020 and @wang2018.

The package `tidybayes` is used to harmonize the different commands and demonstrate that the process is the same. Since there is no tidybayes command for `INLA`, similar functions are coded in the `eflINLA` package.

The package `posterior` is used to harmonize the results from these 3 types of fit.

### Priors {#prac4M7-Priors .unnumbered}

We simulate the priors using the specifications from the model. The lognormal distribution is not available in `simstudy`. The solution is to create a custom (nonrandom) distribution as demonstrated in [lognormal](https://githubmemory.com/repo/kgoldfeld/simstudy/issues/99). However this gives me an error message, so instead, beta is exponentiated in `mu`'s formula.

```{r}
sim04M07 <- list()
sim04M07 <- within(sim04M07, {
  xrng <- paste(round(range(data04M07$weight_c)), collapse = ";")
  def <- defData(varname = "x", dist = "uniform", formula = xrng)
  def <- defData(def, varname = "alpha", formula = 178, variance = 20^2)
  def <- defData(def, varname = "beta", formula = 0, variance = 1^2)
  def <- defData(def, varname = "sigma", dist = "exponential", formula = 1)
  forml <- "alpha + exp(beta) *x"  # convert beta to exp since it is lognormal dist
  def <- defData(def, varname = "mu", dist = "nonrandom", formula = forml)
  def <- defData(def, varname = "height", formula = "mu", variance = "sigma")
  
  set.seed(157)  # for fun: 157 is a balanced prime
  data <- genData(n = 1000, dtDefs = def)
  
  # stats used for vertical lines by the plot
  vlines <- data.frame(
    model = c("prior", "observed"),
    mode = c(ggdist::Mode(data$height), ggdist::Mode(data04M07$height)))
})
```

```{r}
ggplot(sim04M07$data) +
  geom_density(aes(x = height, y = after_stat(scaled), color = "prior"),
               linewidth = 1, alpha = 0.8) +
  geom_density(data = data04M07, aes(x = height, y = after_stat(scaled), color = "observed"),
               linewidth = 1, alpha = 0.8) +
  geom_vline(data = sim04M07$vlines, mapping = aes(xintercept = mode, color = model),
             linetype = "dashed") +
  scale_color_manual(values = c("prior" = "mediumvioletred", 
                                "observed" = "mediumseagreen")) +
  scale_x_continuous(breaks = scales::breaks_pretty(n = 7)) +
  coord_cartesian(xlim = c(50, 300)) +
  theme(legend.position = c(0.8, 0.8)) +
  labs(title = paste0(
    "4M7: Comparing prior predictive distribution vs observed distribution",
    "\n", "vertical lines = mode"),
    x = "height", y = NULL, color = NULL)
```

The prior is reasonable as it reflects an opinion on the overall general population.

### Using `quap` {.unnumbered}

#### Fits {.unnumbered}

The fit using the centered, model m4.3 in textbook.

```{r ch04_fit04M07_quap_ctr}
fit04M07 <- list()
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "1 secs."))
fit04M07$quap_ctr <- xfun::cache_rds({
  quap(
    flist = alist(
      height ~ dnorm(mu, sigma),
      mu <- a + b * weight_c,
      a ~ dnorm(178, 20),
      b ~ dlnorm(0, 1),
      sigma ~ dunif(0, 50)
      ),
    data = data04M07,
    start = list(a = mean(data04M07$weight), b = 0.5, sigma = 25)
    )},
  file = "ch04_fit04M07_quap_ctr")
tictoc::toc()
```

and the summary is

```{r}
precis(fit04M07$quap_ctr)[, 1:2]
```

The fit using the predictor on the natural scale

```{r ch04_fit04M07_quap_nat}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "1 secs."))
fit04M07$quap_nat <- xfun::cache_rds({
  quap(
    flist = alist(
      height ~ dnorm(mu, sigma),
      mu <- a + b * weight,
      a ~ dnorm(178, 20),
      b ~ dlnorm(0, 1),
      sigma ~ dunif(0, 50)
      ),
    data = data04M07,
    start = list(a = mean(data04M07$weight), b = 0.5, sigma = 10)
    )},
  file = "ch04_fit04M07_quap_nat")
tictoc::toc()
precis(fit04M07$quap_nat)[, 1:2]
```

#### Covariances {.unnumbered}

The parameter `corr = TRUE` does not seem to work in `precis` so we use the var-cov matrix and convert it to correlations.

```{r}
round(cov2cor(vcov(fit04M07$quap_ctr)), 4)
```

```{r}
round(cov2cor(vcov(fit04M07$quap_nat)), 4)
```

Comments:

-   The effect ($b$) and sigma are the same but the $a$ (Intercepts) coefficients are different.
-   The correlations are strong on the natural scale and non-existent on the centered scale. This is an effect that is well documented with the correlation coefficient when *distant data points from the origin* are observed
-   The 2 models, on centered and natural scales give the same prediction.

#### Posteriors {.unnumbered}

Get the samples from the posteriors of the 2 models (centered and natural scales).

```{r}
# get the posterior samples for both models (centered and natural scale)
post04M07 <- list()
post04M07 <- within(post04M07, {
  ndraws <- 500L
  
  # the model on centered scale
  quap_ctr <- tidy_draws(fit04M07$quap_ctr, n = ndraws) |>
    # .chain and .iteration are NA and will generate error
    select(-.chain, -.iteration) |>
    as_draws_df()
  
  # the model with on natural scale
  quap_nat <- tidy_draws(fit04M07$quap_nat, n = ndraws) |>
    select(-.chain, -.iteration) |>
    as_draws_df()
  
  # bind the 2 dataframes together
  quap_all <- bind_rows("ctr" = quap_ctr, "nat" = quap_nat, .id ="model")
  
  # long format used for plotting
  quap_all <- quap_all |>
    group_by(model) |>
    tidybayes::gather_variables()
  })
```

and plot them by variable

```{r}
ggplot(post04M07$quap_all, aes(x = .value, color = model)) +
  ggdist::stat_slabinterval(point_interval = mode_qi, fill = "antiquewhite") +
  scale_color_paletteer_d("ggthemes::calc") +
  facet_grid(model ~ .variable, scales = "free") +
  theme(legend.position = "right") +
  labs(title = "4M7: Posterior comparisons by model using quap",
       subtitle = sprintf("sample size = %d", post04M07$ndraws),
       x = NULL, y = NULL)
```

Conclusion: The main difference is with respect to the intercept which is different for uncentered and centered weight. The difference is not only in the location but also in the scale. The uncentered weight is less accurate as its variance is large compared to the centered weight.

#### Predictions {.unnumbered}

```{r}
# the predictions for the centered model
pred04M07 <- list()
pred04M07 <- within(pred04M07, {
  ndraws<- 500L
  
  quap_ctr <- list()
  quap_ctr$newdata <- data.frame(
    weight_c = seq_range(data04M07$weight_c, n = 30L))
  quap_ctr$draws <- predicted_draws(
    fit04M07$quap_ctr,
    newdata = quap_ctr$newdata,
    ndraws = ndraws)
  # get the intervals
  quap_ctr$intrvl <- median_qi(quap_ctr$draws) |>
  # put weight on natural scale to enable comparisons
    mutate(weight = weight_c + mean(data04M07$weight))
  
  quap_nat <- list()
  quap_nat$newdata <- data.frame(
    weight = seq_range(data04M07$weight, n = 30L))
  quap_nat$draws <- predicted_draws(
    fit04M07$quap_nat, 
    newdata = quap_nat$newdata, 
    ndraws = ndraws)
  # get the intervals
  quap_nat$intrvl <- median_qi(quap_nat$draws)
  
  # put all intervals together
  quap_all <- list()
  quap_all$intrvl <- bind_rows(
    "ctr"= quap_ctr$intrvl, "nat" = quap_nat$intrvl, .id = "model")
  })
```

and the plot is

```{r}
ggplot(pred04M07$quap_all$intrvl, 
       aes(x = weight, y = .prediction, ymin = .lower, ymax = .upper,
           color = model)) +
  geom_pointinterval(position = position_dodge(width = 0.5),
                     fatten_point = 2, size = 1) +
  scale_color_paletteer_d("ggthemes::calc") +
  theme(legend.position = "bottom",
        panel.grid.major.y = element_line()) +
  labs(title = "Centered vs Natural Predictions",
       subtitle = "4M7 using quap")
```

### Using `brm` {.unnumbered}

We will use `brm` only for the centered model since this is only to compare with `quap` and `inla`.

#### Fits {.unnumbered}

```{r ch04_fit04M07_brm_ctr}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "65 secs."))
fit04M07$brm_ctr <- xfun::cache_rds({
  brms::brm(
  data = data04M07,
  family = gaussian,
  formula = height ~ 1 + weight_c,
  prior = c(
    prior(normal(178, 20), class = Intercept),
    prior(lognormal(0, 1), class = b, lb = 0, ub = 3),
    prior(exponential(1), class = sigma)),
  iter = 2000, warmup = 1000, chains = 4, cores = detectCores(),  seed = 4)},
  file = "ch04_fit04M07_brm_ctr")
tictoc::toc()
```

```{r}
summary(fit04M07$brm_ctr)
```

```{r ch04_fit04M07_brm_nat}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit04M07$brm_nat <- xfun::cache_rds({
  brms::brm(
  data = data04M07,
  family = gaussian,
  formula = height ~ 1 + weight,
  prior = c(
    prior(normal(178, 20), class = Intercept),
    prior(lognormal(0, 1), class = b, lb = 0, ub = 3),
    prior(exponential(1), class = sigma)),
  iter = 2000, warmup = 1000, chains = 4, cores = detectCores(),  seed = 4)},
  file = "ch04_fit04M07_brm_nat")
tictoc::toc()
```

```{r}
summary(fit04M07$brm_nat)
```

#### Posteriors {.unnumbered}

We extract the samples using `tidybayes` which gives the exact same commands as for `rethinking::quap` above.

```{r}
post04M07 <- within(post04M07, {
  brm_ctr <- tidy_draws(fit04M07$brm_ctr, n = ndraws) |>
    # .chain and .iteration are NA and will generate error
    select(-.chain, -.iteration) |>
    # mutate(model = 1) |>
    as_draws_df() |>
    # mutate_variables(model = 1) |>
    identity()
  
  
  brm_nat <- tidy_draws(fit04M07$brm_nat, n = ndraws) |>
    select(-.chain, -.iteration) |>
    # mutate(model = 2) |>
    as_draws_df() |>
    # mutate_variables(model = 2) |>
    identity()
  
  # bind the 2 dataframes together
  brm_all <- bind_rows("ctr" = brm_ctr, "nat" = brm_nat, .id ="model")
  
  # long format used for plotting
  brm_all_lng <- brm_all |>
    group_by(model) |>
    tidybayes::gather_variables() |>
    mutate(.variable = if_else(.variable == "b_weight_c", "b_weight", .variable))
  })
```

and plot them by variable

```{r}
post04M07$brm_all_lng |>
  filter(.variable %in% c("b_Intercept", "b_weight")) |>
  ggplot(aes(x = .value, color = model)) +
  ggdist::stat_slabinterval(point_interval = mode_qi, fill = "antiquewhite") +
  scale_color_paletteer_d("ggthemes::calc") +
  facet_grid(model ~ .variable, scales = "free") +
  theme(legend.position = "right") +
  labs(title = "4M7: Posterior comparisons by model using brm",
       subtitle = sprintf("sample size = %d", post04M07$ndraws),
       x = NULL, y = NULL)
```

#### Predictions {.unnumbered}

And, again, we can use the exact same command using `tidybayes` with `brms` as we used with `rethinking`.

```{r}
# the predictions for the centered model
pred04M07 <- within(pred04M07, {
  brm_ctr <- list()
  brm_ctr$newdata <- data.frame(
    weight_c = seq_range(data04M07$weight_c, n = 30L))
  brm_ctr$draws <- predicted_draws(
    fit04M07$brm_ctr,
    newdata = brm_ctr$newdata,
    ndraws = ndraws)
  # get the intervals
  brm_ctr$intrvl <- median_qi(brm_ctr$draws) |>
  # put weight on natural scale to enable comparisons
    mutate(weight = weight_c + mean(data04M07$weight))
  
  brm_nat <- list()
  brm_nat$newdata <- data.frame(
    weight = seq_range(data04M07$weight, n = 30L))
  brm_nat$draws <- predicted_draws(
    fit04M07$brm_nat, 
    newdata = brm_nat$newdata, 
    ndraws = ndraws)
  # get the intervals
  brm_nat$intrvl <- median_qi(brm_nat$draws)
  
  # put all intervals together
  brm_all<- list()
  brm_all$intrvl <- bind_rows(
    "ctr"= brm_ctr$intrvl, "nat" = brm_nat$intrvl, .id = "model")
  })
```

and the plot

```{r}
ggplot(pred04M07$brm_all$intrvl, 
       aes(x = weight, y = .prediction, ymin = .lower, ymax = .upper,
           color = model)) +
  geom_pointinterval(position = position_dodge(width = 0.5),
                     fatten_point = 2, size = 1) +
  scale_color_paletteer_d("ggthemes::calc") +
  theme(legend.position = "bottom",
        panel.grid.major.y = element_line()) +
  labs(title = "Centered vs Natural Predictions",
       subtitle = "4M7 using brm")
```

## 4M8 {#prac4M8 .unnumbered}

The methodology used here comes from section 4.5 of @kurtz2020b to whom I am forever grateful for the wonderful books he gives us.

We remove the rows with `NA` in the `doy` variable.

```{r}
data("cherry_blossoms")
data04M08 <- cherry_blossoms |>
  drop_na(doy)
rm(cherry_blossoms)
stopifnot(all.equal(dim(data04M08), c(827L, 5L)))
skimr::skim(data04M08, year, doy, temp)
```


### Model {.unnumbered}

$$
\begin{align*}
doy_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \sum_{k=1}^Kw_kB_{k, i} \\
\alpha &\sim \mathcal{N}(100, 10) \\
w_j &\sim \mathcal{N}(0, 10) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

### Functions {.unnumbered}

This function will be used to create the B matrix. See R code 4.74 in section 4.5.2 of the textbook.

```{r}
# create the B (basis) matrix
get_B <- function(x, knots, degree = 3L, intercept = TRUE) {
  out <- splines::bs(x = x, 
                     knots = knots[-c(1, length(knots))], 
                     degree = degree, 
                     intercept = intercept)
  stopifnot(all.equal(dim(out), c(length(x), length(knots) + degree - 1)))
  out
}
```


A function to create the plot used in this practice

```{r}
# the basic plot used in 4M8
plot_04M08 <- function(data, x_var = "year", y_var = "doy", color_var = "temp", 
                       knots = 15L, leg_pos = c(0.05, 0.8), 
                       colrs = "grDevices::SunsetDark",
                       titles = list()) {
  
  ggplot(data, aes(x = .data[[x_var]], y = .data[[y_var]], 
                   color = .data[[color_var]])) +
    geom_point(shape = 20, size = 2, alpha = 2/3) +
    geom_vline(xintercept = knots, color = "slateblue", alpha = 1/2) +
    scale_x_continuous(breaks = knots, labels = scales::label_number(big.mark = "")) +
  scale_color_paletteer_c(colrs) +
  theme(legend.position = leg_pos,
        axis.text.x = element_text(size = rel(0.9))) +
  labs(title = titles$title, subtitle = titles$subtitle)
}
```



### a) Knots = 15, $w_j \sim \mathcal{N}(0, 10)$

Create the knots and bias function with degree 3 (cubic spline) and an intercept

```{r}
splinA <- list()
splinA <- within(splinA, {
  data <- data04M08
  knots = quantile(data$year, 
                   probs = seq(from = 0, to = 1, length.out = 15L))
  B <- get_B(x = data$year, knots = knots, degree = 3L, intercept = TRUE)
  bias <- B |>
    as.data.frame() |>
    setNames(sprintf("B%02d", seq_len(ncol(B)))) |>
    mutate(year = data$year) |>
    pivot_longer(cols = -year, names_to = "bias_func", values_to = "bias")
  # the last column is a matrix column, with same nb of rows as the other
  # columns but with a column including 17 subcolumns (!)
  data <- data |>
    mutate(B = B)
})
```

```{r ch04_fit04M08_splinA}
fit04M08 <- list()
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit04M08$splinA <- xfun::cache_rds({
  brm(data = splinA$data,
      family = gaussian,
      doy ~ 1 + B,
      prior = c(prior(normal(100, 10), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(exponential(1), class = sigma)),
      cores = detectCores(), seed = 4)},
  file = "ch04_fit04M08_splinA")
tictoc::toc()
```

```{r}
summary(fit04M08$splinA)
```

```{r}
# get the fitted values (linpred)
lpred04M08 <- list()
lpred04M08 <- within(lpred04M08,{
  data <- data04M08
  A <- list()
  A$newdata <- data.frame(
    year = seq_range(data$year, n = 30)) |>
    # NOTE: must use mutate() to add B matrix "as is"
    mutate(B = get_B(x = year, knots = splinA$knots, 
                     degree = 3, intercept = TRUE))
  
  # linpred_draws is the same as fitted
  A$intrvl <- linpred_draws(fit04M08$splinA, newdata = A$newdata) |>
    as.data.frame() |>
    select(-B) |>
    group_by(year) |>
    mean_qi()
  })
```

```{r}
# plot the fitted values
plot04M08 <- list()
titles <- list(
  title = sprintf(
    "4M8 a): Cherry Blossom in Japan with %d knots", length(splinA$knots)),
  subtitle = sprintf("%d observations", nrow(data04M08)))
plot04M08$A <- plot_04M08(data04M08, knots = splinA$knots, titles = titles) +
  labs(subtitle = "4M8 a)") +
  geom_smooth(data = lpred04M08$A$intrvl, 
              mapping = aes(x = year, y = .linpred, ymin = .lower, ymax = .upper),
              inherit.aes = FALSE,
              color = "blueviolet", fill = "cornflowerblue", alpha = 1/2)
plot04M08$A
```

### b) Knots = 25, $w_j \sim \mathcal{N}(0, 10)$ {.unnumbered}

We use the same process as in a) above but with different nb of knots

```{r}
splinB <- list()
splinB <- within(splinB, {
  data <- data04M08
  knots = quantile(data$year, 
                   probs = seq(from = 0, to = 1, length.out = 25L))
  B <- get_B(x = data$year, knots = knots, degree = 3L, intercept = TRUE)
  bias <- B |>
    as.data.frame() |>
    setNames(sprintf("B%02d", seq_len(ncol(B)))) |>
    mutate(year = data$year) |>
    pivot_longer(cols = -year, names_to = "bias_func", values_to = "bias")
  # the last column is a matrix column, with same nb of rows as the other
  # columns but with a column including 17 subcolumns (!)
  data <- data |>
    mutate(B = B)
})
```

```{r ch04_fit04M08_splinB}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit04M08$splinB <- xfun::cache_rds({
  brm(data = splinB$data,
      family = gaussian,
      doy ~ 1 + B,
      prior = c(prior(normal(100, 10), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(exponential(1), class = sigma)),
      cores = detectCores(), seed = 4)},
  file = "ch04_fit04M08_splinB")
tictoc::toc()
```

```{r}
summary(fit04M08$splinB)
```

```{r}
# get the fitted values (linpred)
lpred04M08 <- within(lpred04M08,{
  B <- list()
  B$newdata <- data.frame(
    year = seq_range(data$year, n = 30)) |>
    # NOTE: must use mutate() to add B matrix "as is"
    mutate(B = get_B(x = year, knots = splinB$knots, 
                     degree = 3L, intercept = TRUE))
  
  # linpred_draws is the same as fitted
  B$intrvl <- linpred_draws(fit04M08$splinB, newdata = B$newdata) |>
    as.data.frame() |>
    select(-B) |>
    group_by(year) |>
    mean_qi()
  })
```

```{r}
# plot the fitted values
titles <- list(
  title = sprintf(
    "4M8 b): Cherry Blossom in Japan with %d knots", length(splinB$knots)),
  subtitle = sprintf("%d observations", nrow(data04M08)))
plot04M08$B <- plot_04M08(data04M08, knots = splinB$knots, titles = titles) +
  geom_smooth(data = lpred04M08$B$intrvl, 
              mapping = aes(x = year, y = .linpred, ymin = .lower, ymax = .upper),
              inherit.aes = FALSE,
              color = "blueviolet", fill = "cornflowerblue", alpha = 1/2)
plot04M08$B
```

### c) Knots = 25, $w_j \sim \mathcal{N}(0, 20)$ {.unnumbered}

```{r}
splinC <- list()
splinC <- within(splinC, {
  data <- data04M08
  knots = quantile(data$year, 
                   probs = seq(from = 0, to = 1, length.out = 25L))
  B <- get_B(x = data$year, knots = knots, degree = 3L, intercept = TRUE)
  bias <- B |>
    as.data.frame() |>
    setNames(sprintf("B%02d", seq_len(ncol(B)))) |>
    mutate(year = data$year) |>
    pivot_longer(cols = -year, names_to = "bias_func", values_to = "bias")
  # the last column is a matrix column, with same nb of rows as the other
  # columns but with a column including 17 subcolumns (!)
  data <- data |>
    mutate(B = B)
})
```

```{r ch04_fit04M08_splinC}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit04M08$splinC <- xfun::cache_rds({
  brm(data = splinC$data,
      family = gaussian,
      doy ~ 1 + B,
      prior = c(prior(normal(100, 10), class = Intercept),
                prior(normal(0, 20), class = b),
                prior(exponential(1), class = sigma)),
      cores = detectCores(), seed = 4)},
  file = "ch04_fit04M08_splinC")
tictoc::toc()
```

```{r}
summary(fit04M08$splinC)
```

```{r}
# get the fitted values (linpred)
lpred04M08 <- within(lpred04M08,{
  C <- list()
  C$newdata <- data.frame(
    year = seq_range(data$year, n = 30)) |>
    # NOTE: must use mutate() to add B matrix "as is"
    mutate(B = get_B(x = year, knots = splinC$knots, 
                     degree = 3L, intercept = TRUE))
  
  # linpred_draws is the same as fitted
  C$intrvl <- linpred_draws(fit04M08$splinC, newdata = C$newdata) |>
    as.data.frame() |>
    select(-B) |>
    group_by(year) |>
    mean_qi()
  })
```

```{r}
# plot the fitted values
titles <- list(
  title = sprintf(
    "4M8 c): Cherry Blossom in Japan with %d knots and increased weight sd to 20",
    length(splinB$knots)),
  subtitle = sprintf("%d observations", nrow(data04M08)))
plot04M08$C <- plot_04M08(data04M08, knots = splinC$knots, titles = titles) +
  geom_smooth(data = lpred04M08$C$intrvl, 
              mapping = aes(x = year, y = .linpred, ymin = .lower, ymax = .upper),
              inherit.aes = FALSE,
              color = "blueviolet", fill = "cornflowerblue", alpha = 1/2)
plot04M08$C
```

### Conclusion {.unnumbered}

#### Plots {.unnumbered}

The increase of nb of knots increases the fits (i.e. nb of turns)

```{r}
plot04M08$A / plot04M08$B
```

and the increase in variability of the weight increase the range of the coefficient.

```{r}
plot04M08$B / plot04M08$C
```

However this is not visually obvious when looking at the scatter plot. See just below the coefficient comparisons which is more informative.

#### Summaries {.unnumbered}

```{r}
summ <- list()
summ$A <- data.frame(model = "A", fixef(fit04M08$splinA)) |>
  tibble::rownames_to_column(var = "variable")
summ$B <- data.frame(model = "B", fixef(fit04M08$splinB)) |>
  tibble::rownames_to_column(var = "variable")
summ$C <- data.frame(model = "C", fixef(fit04M08$splinC)) |>
  tibble::rownames_to_column(var = "variable")
summ$data <- bind_rows(summ$A, summ$B, summ$C) |>
  mutate(variable = factor(variable,
                           levels = c("Intercept", sprintf("B%d", 1:27)),
                           ordered = TRUE))

ggplot(summ$data[summ$data$variable != "Intercept", ], 
       aes(x = variable, y = Estimate, ymin = Q2.5, ymax = Q97.5, color = model)) +
  geom_pointinterval(position = position_dodge(width = 1/2)) +
  scale_color_paletteer_d("futurevisions::cancri") +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        panel.grid.major.y = element_line(),
        axis.text.x = element_text(size = rel(0.85))) +
  labs(title = "Comparing the models' coefficients (excludding intercept)",
       subtitle = "4M8",
       x = NULL, y = NULL)
```

We can see that the model are similar expect that

-   Model A has significantly lower B16 and B17 coefficients. They are nonetheless similar to the B26 and B27 coefficients of models B and C
-   Model B and C have the same coefficient but model C which is the model with the increased prior variance for the weights has a wider confidence range for all coefficients

To better visualize, we could look at the models coefficient after aliging the knots with the year

## 4H1 {#prac4H1 .unnumbered}

### Data and model {.unnumbered}

```{r}
data("Howell1")
data04H01 <- Howell1 |>
  filter(age >= 18) |>
  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE))
rm("Howell1")
stopifnot(identical(dim(data04H01), c(352L, 5L)))
```

and the model that will be used

$$
\begin{align*}
height_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta \cdot weight_i \\
\alpha &\sim \mathcal{N}(178, 20) \\
\beta &\sim \mathcal{LogNormal}(1, 0.5) \\
\sigma &\sim \mathcal{Exponential}(1)
\end{align*}
$$

and get the fit with `quap`

```{r ch04_fit04H01}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "1 secs."))
fit04H01 <- xfun::cache_rds({
  quap(
    flist = alist(
      height ~ dnorm(mu, sigma),
      mu <- a + b * weight,
      a ~ dnorm(178, 20),
      b ~ dlnorm(1, 0.5),
      sigma ~ dexp(1)),
  data = data04H01,
  start = list(a = mean(data04H01$height), b = 0.5, sigma = 0.5))},
  file = "ch04_fit04H01")
tictoc::toc()
```

```{r}
summary(fit04H01)
```

get the samples of posterior likelihood

```{r}
post04H01 <- extract.samples(fit04H01, n = 1000L)
```

### Using `rethinking::link()` {.unnumbered}

Find the predictions using the detailed method as described in overthinking box of section 4.4.3.4. The `rethinking::link()` function does that.

```{r}
pred04H01 <- list()
pred04H01 <- within(pred04H01, {
  weights <- c(46.95, 43.72, 64.78, 32.59, 54.63)
  names(weights) <- paste0("ind", seq_along(weights))
  newdata <- data.frame("weight" = weights,
                        row.names = names(weights))
  
  sim <- sapply(X = newdata$weight, FUN = function(x) {
    set.seed(173)  # for fun: balanced prime number
    mu <- post04H01$a + post04H01$b * x
    rnorm(n = length(mu), mean = mu, sd = post04H01$sigma)
    })
  
  # get the confidence intervals
  intrvl <- apply(X = sim, MARGIN = 2, FUN = ggdist::mean_hdi, .width = 0.89)
  intrvl <- do.call(rbind, intrvl) |>
    data.frame(row.names = names(weights))
})
```

### Using `tidyverse` {.unnumbered}

The tidyverse way will be used from hereon.

```{r}
pred04H01 <- list()
pred04H01 <- within(pred04H01, {
  weights <- c(46.95, 43.72, 64.78, 32.59, 54.63)
  names(weights) <- paste0("ind", seq_along(weights))
  newdata <- data.frame("weight" = weights,
                        row.names = names(weights))
  # get the simulated predictions
  sim <- purrr::map_dfr(
    .x = weights,
    .f = function(x) {
      set.seed(173)  # for fun: balanced prime number
      mu <- post04H01$a + post04H01$b * x
      y <- rnorm(n = length(mu), mean = mu, sd = post04H01$sigma)
      data.frame(weight = x, height = y)},
    .id = "ind")
  
  # the predictions intervals
  intrvl <- sim |>
    group_by(weight) |>
    ggdist::mean_hdi(height, .width = 0.89) |>
    mutate(individual = names(weights)[order(weights)]) |>
    relocate(individual)
})
# glimpse(pred04H01$intr)
```

## 4H2 {#prac4H2 .unnumbered}

Load the data

```{r ch04_data04H02}
data("Howell1")
data04H02 <- Howell1 |>
  filter(age < 18) |>
  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE))
rm("Howell1")
# there should be 192 rows
stopifnot(identical(dim(data04H02), c(192L, 5L)))
skimr::skim(data04H02)
```

### Model {.unnumbered}

$$
\begin{align*}
height_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta \cdot weight_i \\
\alpha &\sim \mathcal{N}(80, 40) \\
\beta &\sim \mathcal{LogNormal}(1, 0.5) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

### 4H2 a) with `quap` {.unnumbered}

-   Note on priors
    -   Using sigma \~ dexp(rate = 1) which seems to work well with this model
    -   a \~ dnorm(80, 40) is based on the average height of the kids
    -   b \~ dlnorm(1, 0.5) since we assume the growth rate is positive
-   Start values
    -   using start data helps very much for this model converge consistently
    -   for $a$ simply use the average height
    -   for $b$ we use 1 as it should be strictly positive and assuming kids grow faster than adults.

```{r ch04_fit04H02_quap}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "1 secs."))
fit04H02 <- list()
fit04H02$quap <- xfun::cache_rds({
  quap(
    flist = alist(
        height ~ dnorm(mu, sigma),
        mu <- a + b * weight,
        a ~ dnorm(80, 40),
        b ~ dlnorm(1, 0.5),
        sigma ~ dexp(1)
        ),
    data = data04H02,
    start = list(a = mean(data04H01$height), b = 1)
    )},
  file = "ch04_fit04H02_quap")
tictoc::toc()
```

```{r ch04_pred04H02_quap}
pred04H02 <- list()
pred04H02$quap <- rethinking::precis(fit04H02$quap, prob = 0.89)
pred04H02$quap
```

for 10 more units of weights the child should be taller by the following nb of cm

```{r}
with(pred04H02, {
  quap$mean[row.names(quap) == "a"] + 10 * quap$mean[row.names(quap) == "b"] 
  })
```

### 4H2 b) with `quap` {.unnumbered}

#### Get the fitted values with `quap` {.unnumbered}

See section 4.4.3.4 for more details.

```{r ch04_lpred04H02_quap}
lpred04H02 <- list()
lpred04H02 <- within(lpred04H02, {
  ndraws <- 1000L
  weights <- modelr::seq_range(data04H02$weight, n = 30L)
  newdata <- data.frame(weight = weights)
  
  quap <- list()
  # See the overthinking box in section 4.4.3.4 to explain `rethinking::link()'
  quap$draws <- rethinking::link(fit = fit04H02$quap, data = newdata, 
                                 n = ndraws)
  # compute the confidence intervals
  quap$intrvl <- apply(X = quap$draws, MARGIN = 2, FUN = function(x) {
    c("mean" = mean(x), rethinking::HPDI(x))
    }) |>
    t() |>
    bind_cols(weight = weights) |>
  as.data.frame() |>
    relocate(weight)
  })
```

and the prediction intervals are obtained as described in section 4.4.3.5 using `rethinking::sim()`

```{r}
pred04H02 <- list()
pred04H02 <- within(pred04H02, {
  ndraws <- 1000L
  weights <- modelr::seq_range(data04H02$weight, n = 30L)
  newdata <- data.frame(weight = weights)
  
  # the predicted samples
  quap <- list()
  quap$draws <- rethinking::sim(fit = fit04H02$quap,
                          data = newdata,
                          n = ndraws)
  # the intervals
  quap$intrvl <- apply(X = quap$draws, MARGIN = 2, 
        FUN = function(x) {
          c("mean" = mean(x), rethinking::HPDI(x))
          }) |> 
    t() |>
    bind_cols(weight = weights) |>
    as.data.frame() |>
    relocate(weight)
})
# pred04H02$quap$intrvl
```

```{r}
ggplot(data = data04H02, aes(x = weight)) +
  geom_ribbon(data = pred04H02$quap$intrvl,
              aes(ymin = `|0.89`, ymax = `0.89|`),
              fill = "lightcyan") +
  geom_smooth(data = lpred04H02$quap$intrvl,
              aes(y = mean, ymin = `|0.89`, ymax = `0.89|`),
              stat = "identity",
              fill = "lightcyan3", color = "black", alpha = 1, size = 1/2) +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.linear_kryw_5_100_c67") +
  theme(legend.position = c(0.1, 0.8)) +
  labs(title = "quap fit - Practice 4H2", x = "weight", y = "height")
```

### 4H2 a) with `brm` {.unnumbered}

Same comments and conclusion as for `quap` above

```{r ch04_fit04H02_brm}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "1 secs."))
fit04H02$brm <- xfun::cache_rds({
  brms::brm(
    data = data04H02,
    formula = height ~ 1 + weight,
    family = gaussian(),
    prior = c(
      prior(normal(100, 50), class = Intercept),
      prior(lognormal(0, 2), class = b, lb = 0),
      prior(cauchy(0, 1), class = sigma)),
    iter = 2000, warmup = 1000, chains = 4,
    cores = detectCores(), seed = 4)},
  file = "ch04_fit04H02_brm")
tictoc::toc()
```

```{r}
brms::fixef(fit04H02$brm)
```

### 4H2 b) with `brm` {.unnumbered}

The fitted values

```{r}
lpred04H02 <- within(lpred04H02, {
  brm <- list()
  brm$draws <- linpred_draws(fit04H02$brm, newdata = newdata, ndraws = ndraws)
  # compute the confidence intervals
  brm$intrvl <- median_qi(brm$draws)
  })
# glimpse(lpred04H02$brm$intrvl)
```

and the prediction intervals

```{r}
pred04H02 <- within(pred04H02, {
  brm <- list()
  brm$draws <- predicted_draws(fit04H02$brm, newdata = newdata, 
                                 ndraws = ndraws)
  # compute the confidence intervals
  brm$intrvl <- median_qi(brm$draws)
  })
```

and we illustrate the results

```{r}
ggplot(data = data04H02, aes(x = weight)) +
  geom_ribbon(data = pred04H02$brm$intrvl,
              aes(ymin = .lower, ymax = .upper),
              fill = "lightcyan") +
  geom_smooth(data = lpred04H02$brm$intrvl,
              aes(y = .linpred, ymin = .lower, ymax = .upper),
              stat = "identity",
              fill = "lightcyan3", color = "black", alpha = 1, linewidth = 1/2) +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.linear_kryw_5_100_c67") +
  theme(legend.position = c(0.1, 0.8)) +
  labs(title = "BRMS fit - Practice 4H2", x = "weight", y = "height")
```

### 4H2 c) {.unnumbered}

The data points seem to have a nonlinear relation with weight, visually. The relation could hypothetized to be quadratic. It could also be logarithmic.

## 4H3 {#prac4H3 .unnumbered}

This is covered by section 4.5.1 polynomial regression but instead of polynomial we use a logarithmic relation.

The data is

```{r ch04_data04H03}
data("Howell1")
data04H03 <- Howell1 |>
  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE),
         weight_log = log(weight))
rm("Howell1")
stopifnot(identical(dim(data04H03), c(544L, 6L)),
          all(is.finite(data04H03$weight_log)))
skimr::skim(data04H03)
```

The model used is

$$
\begin{align*}
height_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \log{(\beta)} \cdot weight_i \\
\alpha &\sim \mathcal{N}(178, 20) \\
\beta &\sim \mathcal{N}(0, 10) \\
\sigma &\sim \mathcal{Exponential}(1)
\end{align*}
$$

### 4H3 a) using `quap` {.unnumbered}

> Important: We have to use `dunif` for sigma to make the `quap` converge. Otherwise the cov matrix is not positive definite.

```{r ch04_fit04H03_quap}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "1 secs."))
fit04H03 <- list()
fit04H03$quap <- xfun::cache_rds({
  rethinking::quap(
    flist = alist(
        height ~ dnorm(mu, sigma),
        mu <- a + b * log(weight),
        a ~ dnorm(178, 20),
        b ~ dnorm(0, 10),
        sigma ~ dunif(0, 50)
        ),
    data = data04H03
    )},
  file = "ch04_fit04H03_quap")
tictoc::toc()
```

```{r}
precis(fit04H03$quap, prob = 0.89)
```

Since we use $\log{weight}$ than any change of $\log{weight}$ represents a percentage change of $weight$, therefore $b$ represents that, for every percentage increase of the weight, the height is increased by 46.76 of a percentage.

### 4H3 b) using `quap` {.unnumbered}

same process as in 4H2 above where we sample the fitted and predicted values

```{r ch04_lpred04H03_quap}
lpred04H03 <- list()
lpred04H03 <- within(lpred04H03, {
  ndraws <- 1000L
  weights <- modelr::seq_range(data04H03$weight, n = 30L)
  newdata <- data.frame(weight = weights)
  
  quap <- list()
  # See the overthinking box in section 4.4.3.4 to explain `rethinking::link()'
  quap$draws <- rethinking::link(fit = fit04H03$quap, data = newdata, 
                                 n = ndraws)
  # compute the confidence intervals
  quap$intrvl <- apply(X = quap$draws, MARGIN = 2, FUN = function(x) {
    c("mean" = mean(x), rethinking::HPDI(x))
    }) |>
    t() |>
    bind_cols(weight = weights) |>
  as.data.frame() |>
    relocate(weight)
  })
# glimpse(lpred04H03$quap$intrvl)
```

and the prediction intervals are obtained as described in section 4.4.3.5 using `rethinking::sim()`

```{r ch04_pred04H03_quap}
pred04H03 <- list()
pred04H03 <- within(pred04H03, {
  ndraws <- 1000L
  weights <- modelr::seq_range(data04H03$weight, n = 30L)
  newdata <- data.frame(weight = weights)
  
  # the predicted samples
  quap <- list()
  quap$draws <- rethinking::sim(fit = fit04H03$quap,
                          data = newdata,
                          n = ndraws)
  # the intervals
  quap$intrvl <- apply(X = quap$draws, MARGIN = 2, 
        FUN = function(x) {
          c("mean" = mean(x), rethinking::HPDI(x))
          }) |> 
    t() |>
    bind_cols(weight = weights) |>
    as.data.frame() |>
    relocate(weight)
})
# glimpse(pred04H03$quap$intrvl)
```

and the plot is

```{r}
ggplot(data = data04H03, aes(x = weight)) +
  geom_ribbon(data = pred04H03$quap$intrvl,
              aes(ymin = `|0.89`, ymax = `0.89|`),
              fill = "aquamarine1") +
  geom_smooth(data = lpred04H03$quap$intrvl,
              aes(y = mean, ymin = `|0.89`, ymax = `0.89|`),
              stat = "identity",
              fill = "aquamarine4", color = "black", alpha = 1, linewidth = 1/2) +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.linear_kry_5_98_c75") +
  theme(legend.position = c(0.1, 0.8)) +
  labs(title = "quap fit - Practice 4H3", x = "weight", y = "height")
```

### 4H3 a) using `brm` {.unnumbered}

Same comments and conclusion as for `quap` above. The results are very similar.

```{r ch04_fit04H03_brm}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit04H03$brm <- xfun::cache_rds({
  brms::brm(
    data = data04H03,
    formula = height ~ 1 + log(weight),
    family = gaussian,
    prior = 
      c(prior(normal(178, 20), class = Intercept),
        prior(normal(0, 10), class = b),
        prior(cauchy(0, 1), class = sigma)),
    iter = 2000, warmup = 1000, chains = 4,
    cores = detectCores(), seed = 4)},
  file = "ch04_fit04H03_brm")
tictoc::toc()
```

```{r}
brms::fixef(fit04H03$brm)
```

### 4H3 b) using `brm` {.unnumbered}

The fitted values

```{r ch04_lpred04H03_brm}
lpred04H03 <- within(lpred04H03, {
  brm <- list()
  brm$draws <- linpred_draws(fit04H03$brm, newdata = newdata, ndraws = ndraws)
  # compute the confidence intervals
  brm$intrvl <- median_qi(brm$draws)
  })
# glimpse(lpred04H03$brm$intrvl)
```

and the prediction intervals

```{r ch04_pred04H03_brm}
pred04H03 <- within(pred04H03, {
  brm <- list()
  brm$draws <- predicted_draws(fit04H03$brm, newdata = newdata, 
                                 ndraws = ndraws)
  # compute the confidence intervals
  brm$intrvl <- median_qi(brm$draws)
  })
```

and we illustrate the results which are similar to `quap` above.

```{r}
ggplot(data = data04H03, aes(x = weight)) +
  geom_ribbon(data = pred04H03$brm$intrvl,
              aes(ymin = .lower, ymax = .upper),
              fill = "aquamarine1") +
  geom_smooth(data = lpred04H03$brm$intrvl,
              aes(y = .linpred, ymin = .lower, ymax = .upper),
              stat = "identity",
              fill = "aquamarine4", color = "black", alpha = 1, linewidth = 1/2) +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.linear_kry_5_98_c75") +
  theme(legend.position = c(0.1, 0.8)) +
  labs(title = "BRMS fit - Practice 4H3", x = "weight", y = "height")
```

## 4H4 {#prac4H4 .unnumbered}

See section 4.5.1 for reference to this practice. R code 4.65 (p. 111)

The data is as in section 4.5.1. This practice is using techniques that are illustrated at the beginning of section 5.1 in the next chapter.

```{r ch04_data04H04}
data("Howell1")
data04H04 <- Howell1 |>
  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE),
         weight_c2 = weight_c ^ 2)
stopifnot(identical(dim(data04H04), c(544L, 6L)))
rm("Howell1")
skimr::skim(data04H04)
```

the model has been slightly modified by using the centered weight instead of the standard weight. It seems to work better with `quap`.

The values for $a$ are from the summary using `skimr` just above.

$$
\begin{align*}
h_i &\sim \mathcal{N}(\mu_i, \sigma)\\
\mu_i &= \alpha + \beta_1 \cdot weight\_c_i + \beta_2 \cdot weight\_c^2_i \\
\alpha &\sim \mathcal{N}(138, 50) \\
\beta_1 &\sim \mathcal{LogNormal}(0,1) \\
\beta_2 &\sim \mathcal{N}(0,1) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

### 4H4 using `quap` {.unnumbered}

```{r ch04_fit04H04_quap}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "1 secs."))
fit04H04 <- list()
fit04H04$quap <- xfun::cache_rds({
  rethinking::quap(
    flist = alist(
      height ~ dnorm(mu, sigma),
      mu <- a + b1 * weight_c + b2 * weight_c2,
      a ~ dnorm(138, 50),
      b1 ~ dlnorm(0, 1),
      b2 ~ dnorm(-0.25, 0.25),
      sigma ~ exp(1)),
  data = data04H04
)},
  file = "ch04_fit04H04_quap")
tictoc::toc()
```

```{r}
rethinking::precis(fit04H04$quap)
```

The function `rethinking::extract.prior()` is used to sample the prior distributions from the fit. Then the process of finding the mu's is the same as the overthinking box of section 4.4.3.4 (p.107). See also practice 4H1 above for the method.

```{r ch04_prior04H04_quap}
prior04H04 <- list()
prior04H04 <- within(prior04H04,{
  ndraws <-1000L
  quap <- list()
  quap$draws <- extract.prior(fit04H04$quap, n = ndraws) |>
    as.data.frame() |>
    mutate(sigma = rexp(n = n(), rate = 1)) |>
    identity()
})
# glimpse(prior04H04$quap$draws)
```

and find the predictions using the detailed method as described in overthinking box of section 4.4.3.4. The `rethinking::link()` function does that. For an example, see at the beginning of section 5.1 in the next chapter, R code 5.4.

For this exercise, we will do it the long way. See practice 4H1 for an example on how to do this.

```{r}
prior04H04 <- within(prior04H04, {
  newdata <- data.frame(
    weight_c = modelr::seq_range(data04H04$weight_c, n = 30L)) |>
    mutate(weight_c2 = weight_c^2)
  
  # simulate for each weight predictor using the draws
  quap$sim <- purrr::map_dfr(
    .x = newdata$weight_c,
    .f = function(x) {
      mu <- quap$draws$a + quap$draws$b1 * x + quap$draws$b2 * x^2
      y = rnorm(n = length(mu), mean = mu, sd = quap$draws$sigma)
      data.frame(weight_c = x, height = y)
    })
  
  quap$intrvl <- quap$sim |>
    group_by(weight_c) |>
    ggdist::mean_hdi(height, .width = 0.89)
})
# prior04H04$quap$intrvl
```

```{r}
ggplot(data = data04H04, aes(x = weight_c)) +
  geom_line(data = prior04H04$quap$intrvl, aes(y = height), linewidth = 1, color = "purple") +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.rainbow_bgyrm_35_85_c71") +
  theme(legend.position = c(0.85, 0.30)) +
  labs(title = "quap fit with PRIOR - Practice 4H4", x = "weight", y = "height")
```

which shows that the prior is not so bad, it's shape aligns with the data, only the intercept actually need to be modified.

> Conclusion: It's a very good idea to simulate the priors. It tells us if they make sense. It helps greatly in having a converging fit.

### 4H4 using `brm` {.unnumbered}

**Note the use of `sample_prior = TRUE`** to be able to obtain the prior samples. We use the prior $b1 \sim \mathcal{N}(0,1)$ instead of $\mathcal{LogNormal}$ which gives a much better prior in this case.

```{r ch04_fit04H04_brm}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit04H04$brm <- xfun::cache_rds({
  brms::brm(data = data04H04,
                   formula = height ~ 1 + weight_c + weight_c2,
                   family = gaussian,
                   prior =
                     c(prior(normal(138, 50), class = Intercept),
                       prior(normal(0, 1), class = b, coef = "weight_c"),
                       prior(normal(-0.25, 0.25), class = b, coef = "weight_c2"),
                       prior(cauchy(0, 1), class = sigma)),
                   iter = 2000, warmup = 1000, chains = 4,
                   sample_prior = TRUE,
                   cores = detectCores(), seed = 4)},
  file = "ch04_fit04H04_brm")
tictoc::toc()
```

```{r ch04_prior04H04_brm}
prior04H04 <- within(prior04H04,{
  brm <- list()
  brm$draws <- brms::prior_draws(fit04H04$brm)
  })
# glimpse(prior04H04$brm$draws)
```

```{r}
prior04H04 <- within(prior04H04, {
  # simulate for each weight predictor using the draws
  brm$sim <- purrr::map_dfr(
    .x = newdata$weight_c,
    .f = function(x) {
      mu <- brm$draws$Intercept + brm$draws$b_weight_c * x + 
        brm$draws$b_weight_c2 * x^2
      y = rnorm(n = length(mu), mean = mu, sd = brm$draws$sigma)
      data.frame(weight_c = x, height = y)
    })
  
  brm$intrvl <- brm$sim |>
    group_by(weight_c) |>
    ggdist::mean_hdi(height, .width = 0.89)
})
# glimpse(prior04H04$brm$intrvl)
```

```{r}
ggplot(data = data04H04, aes(x = weight_c)) +
  geom_line(data = prior04H04$brm$intrvl, aes(y = height), linewidth = 1, color = "purple") +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.rainbow_bgyrm_35_85_c71") +
  theme(legend.position = c(0.85, 0.30)) +
  labs(title = "brm fit with PRIOR - Practice 4H4", x = "weight", y = "height")
```

## 4H5 {#prac4H5 .unnumbered}

### The data

```{r ch04_data04H05}
data("cherry_blossoms")
data04H05 <- cherry_blossoms |>
  drop_na()
rm(cherry_blossoms)
skimr::skim(data04H05)
```

### The model

There does not seem to be an obvious relations in the data. We will therefore use cubic splines again.

$$
\begin{align*}
doy_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \sum_{k=1}^Kw_kB_{k, i} \\
\alpha &\sim \mathcal{N}(100, 10) \\
w_j &\sim \mathcal{N}(0, 10) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

### Functions used {-}

A function to create the plot

```{r}
# the basis plot used in 4M8
plot_4H5 <- function(data, x_var = "temp", y_var = "doy", color_var = "year", 
                     knots, colrs = "pals::isol", titles = list()) {
  ggplot(data, aes(x = .data[[x_var]], y = .data[[y_var]], 
                   color = .data[[color_var]])) +
    geom_point(shape = 20, size = 2, alpha = 2/3) +
    geom_vline(xintercept = knots, color = "slateblue", alpha = 1/2) +
    scale_x_continuous(breaks = knots,
                       labels = scales::label_number(accuracy = 0.1)) +
  scale_color_paletteer_c(colrs) +
  theme(legend.position = c(0.90, 0.85),
        axis.text.x = element_text(size = rel(0.9))) +
  labs(title = titles$title, subtitle = titles$subtitle)
}
```

### The splines {.unnumbered}

```{r}
# the data for the spline
splin <- list()
splin <- within(splin, {
  knots = quantile(data04H05$temp, 
                   probs = seq(from = 0, to = 1, length.out = 12))
  B <- get_B(x = data04H05$temp, knots = knots, degree = 3L, intercept = TRUE)
  data <- data04H05 |>
    mutate(B = B)
})
```

### With `quap` {.unnumbered}

See code example in R code 4.76, 4.77 and 4.78 in section4.5.2

```{r ch04_fit04H05_quap}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "1 secs."))
fit04H05 <- list()
fit04H05$quap <- xfun::cache_rds({
  rethinking::quap(
  alist(
    D ~ dnorm(mu, sigma),
    mu <- a + B %*% w,
    a ~ dnorm(100, 10),
    w ~ dnorm(0, 10),
    sigma ~ dexp(1)),
  data=list(D=data04H05$doy, B=splin$B),
  start=list(w=rep(0,ncol(splin$B)))
  )},
  file = "ch04_fit04H05_quap")
tictoc::toc()
```

and the fitted values with their interval

```{r ch04_lpred04H05_quap}
lpred04H05 <- list()
lpred04H05 <- within(lpred04H05, {
  ndraws <- 1000L
  
  quap <- list()
  # See the overthinking box in section 4.4.3.4 to explain `rethinking::link()'
  quap$draws <- rethinking::link(fit04H05$quap, n = ndraws) |>
    as.data.frame() |>
    pivot_longer(cols = everything(), names_to = "temp", values_to = "doy") |>
    mutate(temp = rep(data04H05$temp, times = ndraws))
  # compute the confidence intervals
  quap$intrvl <- quap$draws |>
    group_by(temp) |>
    ggdist::mean_qi(.width = 0.95)
  })
# glimpse(lpred04H05$quap$draws)
# glimpse(lpred04H05$quap$intrvl)
```

```{r}
titles <- list(
  title = sprintf("Cherry Blossom in Japan with %d knots with quap", length(splin$knots)),
  subtitle = sprintf("%d observations", nrow(data04H05)))
plot_4H5(data04H05, knots = splin$knots, titles= titles) +
  geom_smooth(data = lpred04H05$quap$intrvl,
              mapping = aes(x = temp, y = doy, ymin = .lower, ymax = .upper),
              inherit.aes = FALSE,
              stat = "identity", color = "darksalmon", fill = "sandybrown")
```

### With `brm` {.unnumbered}

```{r}
glimpse(splin$data)
```

```{r ch04_fit04H05_brm}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit04H05$brm <- xfun::cache_rds({
  brms::brm(data = splin$data,
      family = gaussian,
      doy ~ 1 + B,
      prior = c(prior(normal(100, 10), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(exponential(1), class = sigma)),
      cores = detectCores(), seed = 4)},
  file = "ch04_fit04H05_brm")
tictoc::toc()
```

```{r ch04_lpred04H05_brm}
lpred04H05 <- within(lpred04H05, {
  
  newdata <- data.frame(
    temp = seq_range(data04H05$temp, n = 30)) |>
    # NOTE: must use mutate() to add B matrix "as is"
    mutate(B = get_B(x = temp, knots = splin$knots,
                     degree = 3, intercept = TRUE))

  brm <- list()
  # linpred_draws is the same as fitted()
  brm$intrvl <- linpred_draws(fit04H05$brm, newdata = newdata) |>
    as.data.frame() |>
    select(-B) |>
    group_by(temp) |>
    mean_qi()
  })
# glimpse(lpred04H05$brm$draws)
# glimpse(lpred04H05$brm$intrvl)
```

and plot the results

```{r}
titles <- list(
  title = sprintf("Cherry Blossom in Japan with %d knots with brm", length(splin$knots)),
  subtitle = sprintf("%d observations", nrow(data04H05)))
plot_4H5(data04H05, knots = splin$knots, titles = titles) +
  geom_smooth(data = lpred04H05$brm$intrvl,
              mapping = aes(x = temp, y = .linpred, ymin = .lower, ymax = .upper),
              inherit.aes = FALSE,
              stat = "identity", color = "darksalmon", fill = "sandybrown")
```

## 4H6 {#prac4H6 .unnumbered}

See 4.5.2 on splines for a discussion on the spline matrix. The following simulation is inspired by that section.

The dimensions f the B matrix are explained in section 4.5.2, on p. 117, between R code 4.74 and R code 4.75.

### Data {.unnumbered}

```{r data04H06}
data("cherry_blossoms")
data04H06 <- cherry_blossoms |>
  drop_na()
skimr::skim(data04H06)
```

### Model {.unnumbered}

$$
\begin{align*}
doy_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \sum_{k=1}^Kw_kB_{k, i} \\
\alpha &\sim \mathcal{N}(100, 10) \\
w_j &\sim \mathcal{N}(0, 10) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

### Functions {-}

We need to create functions to simulate the prior and plotting.

The functions used for the simulation

```{r}
# simulate the prior using the B matrix
sim_prior_gam <- function(B, n = 1000L,
                          alpha_prior = list(mean = 0, sd = 10),
                          weight_prior = list(mean = 0, sd = 10),
                          sigma_prior = list(rate = 1)) {
  
  out <- sapply(X=seq_len(nrow(B)), FUN = function(i) {
    # get a sample of intercept
    intercept <- rnorm(n=1, alpha_prior$mean, sd=alpha_prior$sd)
    # get the sample of coefficients, one for each coefficient
    weights <- sapply(X = seq_len(ncol(B)), FUN = function(j) {
      rnorm(n=1, mean=weight_prior$mean, sd=weight_prior$sd)
      })
    # multiply the weights by the B matrix for that specific observation
    # to get the mu
    mu <- intercept + B[i, ] %*% weights
    # sample sigma
    sigma <- rexp(n = 1, rate = sigma_prior$rate)
    # sample the predictions with mu and sigma
    rnorm(n=n, mean=mu, sd=sigma)
  })
  stopifnot(all.equal(dim(out), c(n, nrow(B))))
  out
}

```

### Prior distribution simulation {.unnumbered}

The simulation with weight prior $sd = 10$

```{r sim04H06}
# the list used to hold sim data and variables
sim04H06 <- list()
sim04H06 <- within(sim04H06, {
  n <- 1000L
  # the knots used
  knots <- quantile(data04H06$temp, probs = seq(from = 0, to = 1, length.out = 12))
  # the predictors used
  preds <- seq_range(data04H06$temp, n = 20L)
  B <- get_B(x=preds, knots=knots, degree = 3L, intercept = TRUE)
  data <- sim_prior_gam(B=B, n = n,
                          alpha_prior = list(mean = 100, sd = 10),
                          weight_prior = list(mean = 0, sd = 10),
                          sigma_prior = list(rate = 1))
  })
```

```{r}
sim04H06 <- within(sim04H06, {
  # put data in log format for use with stat_lineribbon
  data_lng <- data |>
    as.data.frame() |>
    pivot_longer(cols = everything(), names_to = "temp", values_to = "doy") |>
    mutate(temp = rep(preds, times = n))
  
  # create dataframe of intervals for use with geom_smooth
  intrvl <- data_lng |>
    group_by(temp) |>
    ggdist::mean_qi()
})
```

and plot the results

```{r}
plot04H06 <- list()
plot04H06$A <- ggplot(data=data04H06,mapping=aes(x = temp, y = doy, color = year)) +
  geom_vline(xintercept = sim04H06$knots, color = "slateblue", alpha = 1/2) +
  geom_smooth(data=sim04H06$intrvl, inherit.aes = FALSE,
              mapping=aes(x = temp, y = doy, ymin = .lower, ymax = .upper),
              stat = "identity", linewidth = 1, color = "royalblue", fill = "lightskyblue") +
  geom_point(size = 1) +
  scale_x_continuous(breaks = sim04H06$knots, labels = scales::label_number(accuracy = 0.1)) +
  scale_y_continuous(breaks = scales::breaks_extended(n = 5), 
                     labels = scales::label_number(accuracy = 1),
                     limits = c(30, 150)) +
  scale_fill_paletteer_d("ggsci::amber_material") +
  scale_color_paletteer_c("pals::isol") +
  theme(legend.position = "none",
        axis.text.x = element_text(size = rel(0.9))) +
  labs(title = sprintf("Cherry Blossoms: Prior distribution with %d knots", length(sim04H06$knots)),
       subtitle = "with weights' sd = 10")
plot04H06$A
```

The simulation with weight prior $sd = 20$

```{r}
# the list used to hold sim data and variables
sim04H06 <- list()
sim04H06 <- within(sim04H06, {
  n <- 1000L
  # the knots used
  knots <- quantile(data04H06$temp, probs = seq(from = 0, to = 1, length.out = 12))
  # the predictors used
  preds <- seq_range(data04H06$temp, n = 20L)
  B <- get_B(x=preds, knots=knots, degree = 3L, intercept = TRUE)
  data <- sim_prior_gam(B=B, n = n,
                          alpha_prior = list(mean = 100, sd = 10),
                          weight_prior = list(mean = 0, sd = 20),
                          sigma_prior = list(rate = 1))
  })
```

```{r}
sim04H06 <- within(sim04H06, {
  # put data in log format for use with stat_lineribbon
  data_lng <- data |>
    as.data.frame() |>
    pivot_longer(cols = everything(), names_to = "temp", values_to = "doy") |>
    mutate(temp = rep(preds, times = n))
  
  # create dataframe of intervals for use with geom_smooth
  intrvl <- data_lng |>
    group_by(temp) |>
    ggdist::mean_qi()
})
```

and plot the results

```{r}
plot04H06$B <- ggplot(data=data04H06,mapping=aes(x = temp, y = doy, color = year)) +
  geom_vline(xintercept = sim04H06$knots, color = "slateblue", alpha = 1/2) +
  geom_smooth(data=sim04H06$intrvl, inherit.aes = FALSE,
              mapping=aes(x = temp, y = doy, ymin = .lower, ymax = .upper),
              stat = "identity", linewidth = 1, color = "royalblue", fill = "lightskyblue") +
  geom_point(size = 1) +
  scale_x_continuous(breaks = sim04H06$knots, labels = scales::label_number(accuracy = 0.1)) +
  scale_y_continuous(breaks = scales::breaks_extended(n = 5), 
                     labels = scales::label_number(accuracy = 1),
                     limits = c(30, 150)) +
  scale_fill_paletteer_d("ggsci::amber_material") +
  scale_color_paletteer_c("pals::isol") +
  theme(legend.position = "none",
        axis.text.x = element_text(size = rel(0.9))) +
  labs(title = sprintf("Cherry Blossoms: Prior distribution with %d knots", length(sim04H06$knots)),
       subtitle = "with weights' sd = 20")
plot04H06$B
```

and comparing the 2 plots

```{r}
plot04H06$A / plot04H06$B
```

Conclusion: The prior affect the weights in the same manner as the priors affects regression coefficients. In the current example, by increasing the sd of the normally distributed prior we affect the variability of the weights.

## 4H7 {#prac4H7 .unnumbered}

```{r }
#| echo: false
message("Practice 4H7 is missing in the second edition!")
```

## 4H8 {#prac4H8 .unnumbered}

To answer the question about what needs to be done to make the model without
intercept work, here is the suggested answer

1. Use argument `intercept = FALSE` in `spline::bs()`
2. Change the formula to `doy ~ 0 + B` from `doy ~ 1 + B`
3. Remove the prior `prior(normal(100, 10), class = Intercept)`


```{r data04H08}
data("cherry_blossoms")
data04H08 <- cherry_blossoms |>
  drop_na(doy)
rm(cherry_blossoms)
stopifnot(identical(dim(data04H08), c(827L, 5L)))
skimr::skim(data04H08)
```

Define the knots

```{r}
knots <- quantile(data04H08$year, probs = seq(from = 0, to = 1, length.out = 15))
knots
```
the code `knots[-c(1, nknots)]` is required because `bs` places knots at 
the boundaries by default, so we have to remove them.

> Important: Since we don't have an intercept, we set the parameter
`intercept = FALSE` in `spline::bs()`.


```{r}
B <- splines::bs(x = data04H08$year, 
                 knots = knots, 
                 degree = 3, intercept = FALSE)
# str(B)
```

We first append the matrix to the data in one column. See @kurtz2020b 
on this data structure. We need to use `mutate` to keep the matrix as is.


```{r}
data04H08 <- data04H08 |>
  mutate(B = B)
```


and we fit *without the intercept*

```{r ch04_fit04H08}
tictoc::tic(msg = sprintf("run time of %s, use the cache.", "60 secs."))
fit04H08 <- xfun::cache_rds({
  brm(data = data04H08,
      formula = doy ~ 0 + B,
      family = gaussian,
      prior = c(prior(normal(0, 10), class = b),
                prior(exponential(1), class = sigma)),
      cores = detectCores(), seed = 4)},
  file = "ch04_fit04H08")
tictoc::toc()
```
get the fitted value (linear prediction in tidybayes)

```{r}
lpred04H08 <- list()
lpred04H08 <- within(lpred04H08, {
  newdata <- data04H08
  draws <- linpred_draws(fit04H08, newdata = newdata)
  intrvl <- draws |>
    ungroup() |>
    select(-B) |>
    group_by(year) |>
    mean_qi(.linpred)
  })
```



```{r}
clrs <- unclass(paletteer::paletteer_d("futurevisions::cancri"))
ggplot(lpred04H08$intrvl, aes(x = year, y = .linpred)) +
  geom_vline(xintercept = knots, color = "slateblue", alpha = 1/2) +
  geom_point(data04H08, mapping = aes(x = year, y = doy, color = temp),
             inherit.aes = FALSE) +
  geom_lineribbon(aes(x = year, y = .linpred, ymin = .lower, ymax = .upper),
                  color = "blueviolet", fill = "cornflowerblue", alpha = 1/2) +
  scale_x_continuous(breaks = knots, labels = scales::label_number(big.mark = "")) +
  scale_color_gradientn(colors = clrs) +
  theme(legend.position = "none") +
  labs(title = "4H8: Cheery Blossom Spline Without Intercept",
       subtitle = sprintf("%d observations.", nrow(data04H08)),
       x = "year", y = "doy")
```

