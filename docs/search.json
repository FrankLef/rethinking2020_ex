[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "rethinking2020_ex",
    "section": "",
    "text": "sessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 22621)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_United States.utf8\n ctype    English_United States.utf8\n tz       America/New_York\n date     2023-01-03\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package        * version  date (UTC) lib source\n   abind            1.4-5    2016-07-21 [1] CRAN (R 4.2.0)\n   assertthat       0.2.1    2019-03-21 [1] CRAN (R 4.2.1)\n   backports        1.4.1    2021-12-13 [1] CRAN (R 4.2.0)\n   callr            3.7.3    2022-11-02 [1] CRAN (R 4.2.2)\n   checkmate        2.1.0    2022-04-21 [1] CRAN (R 4.2.1)\n   cli              3.4.1    2022-09-23 [1] CRAN (R 4.2.2)\n   cmdstanr       * 0.5.3    2022-12-09 [1] Github (stan-dev/cmdstanr@3b65de8)\n   coda             0.19-4   2020-09-30 [1] CRAN (R 4.2.1)\n   codetools        0.2-18   2020-11-04 [2] CRAN (R 4.2.2)\n   colorspace       2.0-3    2022-02-21 [1] CRAN (R 4.2.1)\n   crayon           1.5.2    2022-09-29 [1] CRAN (R 4.2.2)\n   curl             4.3.3    2022-10-06 [1] CRAN (R 4.2.2)\n   DBI              1.1.3    2022-06-18 [1] CRAN (R 4.2.1)\n   digest           0.6.30   2022-10-18 [1] CRAN (R 4.2.2)\n   distributional   0.3.1    2022-09-02 [1] CRAN (R 4.2.1)\n   dplyr            1.0.10   2022-09-01 [1] CRAN (R 4.2.2)\n   evaluate         0.18     2022-11-07 [1] CRAN (R 4.2.2)\n   fansi            1.0.3    2022-03-24 [1] CRAN (R 4.2.1)\n   farver           2.1.1    2022-07-06 [1] CRAN (R 4.2.1)\n   fastmap          1.1.0    2021-01-25 [1] CRAN (R 4.2.1)\n   generics         0.1.3    2022-07-05 [1] CRAN (R 4.2.1)\n   ggplot2          3.4.0    2022-11-04 [1] CRAN (R 4.2.2)\n   glue             1.6.2    2022-02-24 [1] CRAN (R 4.2.1)\n   gridExtra        2.3      2017-09-09 [1] CRAN (R 4.2.1)\n   gtable           0.3.1    2022-09-01 [1] CRAN (R 4.2.2)\n   htmltools        0.5.3    2022-07-18 [1] CRAN (R 4.2.1)\n   htmlwidgets      1.5.4    2021-09-08 [1] CRAN (R 4.2.1)\n   inline           0.3.19   2021-05-31 [1] CRAN (R 4.2.1)\n   jsonlite         1.8.4    2022-12-06 [1] CRAN (R 4.2.2)\n   knitr            1.41     2022-11-18 [1] CRAN (R 4.2.2)\n   lattice          0.20-45  2021-09-22 [2] CRAN (R 4.2.2)\n   lifecycle        1.0.3    2022-10-07 [1] CRAN (R 4.2.1)\n   loo              2.5.1    2022-03-24 [1] CRAN (R 4.2.1)\n   magrittr         2.0.3    2022-03-30 [1] CRAN (R 4.2.1)\n   MASS             7.3-58.1 2022-08-03 [2] CRAN (R 4.2.2)\n   matrixStats      0.63.0   2022-11-18 [1] CRAN (R 4.2.2)\n   munsell          0.5.0    2018-06-12 [1] CRAN (R 4.2.1)\n   mvtnorm          1.1-3    2021-10-08 [1] CRAN (R 4.2.0)\n   pillar           1.8.1    2022-08-19 [1] CRAN (R 4.2.2)\n   pkgbuild         1.4.0    2022-11-27 [1] CRAN (R 4.2.2)\n   pkgconfig        2.0.3    2019-09-22 [1] CRAN (R 4.2.1)\n   posterior        1.3.1    2022-09-06 [1] CRAN (R 4.2.1)\n   prettyunits      1.1.1    2020-01-24 [1] CRAN (R 4.2.1)\n   processx         3.8.0    2022-10-26 [1] CRAN (R 4.2.2)\n   ps               1.7.2    2022-10-26 [1] CRAN (R 4.2.2)\n   R6               2.5.1    2021-08-19 [1] CRAN (R 4.2.1)\n   Rcpp             1.0.9    2022-07-08 [1] CRAN (R 4.2.1)\n D RcppParallel     5.1.5    2022-01-05 [1] CRAN (R 4.2.1)\n   rethinking     * 2.21     2022-10-09 [1] Github (rmcelreath/rethinking@783d111)\n   rlang            1.0.6    2022-09-24 [1] CRAN (R 4.2.1)\n   rmarkdown        2.18     2022-11-09 [1] CRAN (R 4.2.2)\n   rstan          * 2.26.13  2022-06-25 [1] local\n   rstudioapi       0.14     2022-08-22 [1] CRAN (R 4.2.2)\n   scales           1.2.1    2022-08-20 [1] CRAN (R 4.2.2)\n   sessioninfo      1.2.2    2021-12-06 [1] CRAN (R 4.2.1)\n   shape            1.4.6    2021-05-19 [1] CRAN (R 4.2.0)\n   StanHeaders    * 2.26.13  2022-06-25 [1] local\n   stringi          1.7.8    2022-07-11 [1] CRAN (R 4.2.1)\n   stringr          1.4.1    2022-08-20 [1] CRAN (R 4.2.2)\n   tensorA          0.36.2   2020-11-19 [1] CRAN (R 4.2.0)\n   tibble           3.1.8    2022-07-22 [1] CRAN (R 4.2.1)\n   tidyselect       1.2.0    2022-10-10 [1] CRAN (R 4.2.1)\n   utf8             1.2.2    2021-07-24 [1] CRAN (R 4.2.1)\n   V8               4.2.2    2022-11-03 [1] CRAN (R 4.2.2)\n   vctrs            0.5.1    2022-11-16 [1] CRAN (R 4.2.1)\n   xfun             0.35     2022-11-16 [1] CRAN (R 4.2.2)\n   yaml             2.3.6    2022-10-18 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/Ephel/AppData/Local/R/win-library/4.2\n [2] C:/Program Files/R/R-4.2.2/library\n\n D ── DLL MD5 mismatch, broken installation.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "ch01_golem.html",
    "href": "ch01_golem.html",
    "title": "1  The Golem of Prague",
    "section": "",
    "text": "message(\"There is no practice for this chapter.\")\n\nThere is no practice for this chapter."
  },
  {
    "objectID": "ch02_worlds.html",
    "href": "ch02_worlds.html",
    "title": "2  Small Worlds and Large Worlds",
    "section": "",
    "text": "\\(Pr(rain \\mid Monday)\\) and \\(\\frac{Pr(rain, Monday)}{Pr(Monday)}\\)"
  },
  {
    "objectID": "ch02_worlds.html#prac2E2",
    "href": "ch02_worlds.html#prac2E2",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2E2",
    "text": "2E2\nProb that it is Monday, given it is raining"
  },
  {
    "objectID": "ch02_worlds.html#prac2E3",
    "href": "ch02_worlds.html#prac2E3",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2E3",
    "text": "2E3\n\\(Pr(Monday \\mid rain)\\) and \\(\\frac{Pr(rain \\mid Monday)Pr(Monday)}{Pr(rain)}\\)"
  },
  {
    "objectID": "ch02_worlds.html#prac2E4",
    "href": "ch02_worlds.html#prac2E4",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2E4",
    "text": "2E4\nBased on what we observe small world, the earth, we conjecture that water occupies 70% of the space."
  },
  {
    "objectID": "ch02_worlds.html#prac2M1",
    "href": "ch02_worlds.html#prac2M1",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2M1",
    "text": "2M1\nCreating the function to compute the grid\n\n# function to calculate the posterior grid as per 2M1\ncalc_post_water <- function(obs, grid_size, label) {\n    \n    # Parameters:\n    # obs: Character vector of observation with W and L\n    # grid_size: Number of grid elements\n    # label: String to identify the data, used later to plot\n\n    # convert to boolean values\n    obs <- obs == \"W\"\n    \n    # create a grid of possible values for the parameter p\n    param_grid <- seq(from = 0, to = 1, length.out = grid_size)\n    \n    # the prior is uniformely distributed\n    prior_grid <- dunif(x = param_grid, min = 0, max = 1)\n    \n    # the likelihood is binomial\n    like_grid <- dbinom(x = sum(obs), \n                        size = length(obs), \n                        prob = param_grid)\n    \n    # compute the posterior\n    post_grid <-  like_grid * prior_grid\n    # standardize the posterior by dividing by the sum of its possible values\n    post_grid <- post_grid / sum(post_grid)\n    # add param grid and build a dataframe\n    data.frame(param = param_grid, \n               post = post_grid,\n               label = rep(label, times = grid_size), stringsAsFactors = FALSE)\n}\n\n\n2M1 (1)\nCompute the grid for the given data using the function defined just abov\n\npost_grid_1 <- calc_post_water(c(\"W\", \"W\", \"W\"), 10, \"(1)\")\npost_grid_1\n\n       param         post label\n1  0.0000000 0.0000000000   (1)\n2  0.1111111 0.0004938272   (1)\n3  0.2222222 0.0039506173   (1)\n4  0.3333333 0.0133333333   (1)\n5  0.4444444 0.0316049383   (1)\n6  0.5555556 0.0617283951   (1)\n7  0.6666667 0.1066666667   (1)\n8  0.7777778 0.1693827160   (1)\n9  0.8888889 0.2528395062   (1)\n10 1.0000000 0.3600000000   (1)\n\n\n\n\n2M1 (2)\n\npost_grid_2 <- calc_post_water(c(\"W\", \"W\", \"W\", \"L\"), 10, \"(2)\")\n\n\n\n2M1 (3)\n\npost_grid_3 <- calc_post_water(c(\"L\", \"W\", \"W\", \"L\", \"W\", \"W\", \"W\"), 10, \"(3)\")\n\n\n\nplot\nAnd visualize the results\n\npd <- rbind(post_grid_1, post_grid_2, post_grid_3)  # data for graph\np2M1 <- ggplot(data = pd, mapping = aes(x = param, y = post, color = label)) +\n    geom_point(size = 3) + geom_line() +\n    scale_color_paletteer_d(palette = \"futurevisions::atomic_orange\") +\n    theme_classic() +\n    theme(plot.title = element_text(color = \"dark blue\", hjust = 0.5),\n          legend.position = c(0.1, 0.85)) +\n    labs(title = \"Exercise 2M1\", x = \"parameter p\", y = \"posterior prob\")\np2M1"
  },
  {
    "objectID": "ch02_worlds.html#prac2M2",
    "href": "ch02_worlds.html#prac2M2",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2M2",
    "text": "2M2\nSee R code 2.5 in for example of such a prior.\n\n# function to calculate the posterior grid as per 2M1\ncalc_post_water <- function(obs, grid_size, label) {\n    \n    # Parameters:\n    # obs: Character vector of observation with W and L\n    # grid_size: Number of grid elements\n    # label: String to identify the data, used later to plot\n    \n    # convert to boolean values\n    obs <- obs == \"W\"\n    \n    # create a grid of possible values for the parameter p\n    param_grid <- seq(from = 0, to = 1, length.out = grid_size)\n    \n    # the prior is uniformely distributed\n    prior_grid <- ifelse(param_grid >= 0.5, 0.1, 0)\n    \n    # the likelihood is binomial\n    like_grid <- dbinom(x = sum(obs), \n                        size = length(obs), \n                        prob = param_grid)\n    \n    # compute the posterior\n    post_grid <-  like_grid * prior_grid\n    # standardize the posterior by dividing by the sum of its possible values\n    post_grid <- post_grid / sum(post_grid)\n    # add param grid and build a dataframe\n    data.frame(param = param_grid, \n               post = post_grid,\n               label = rep(label, times = grid_size),\n               stringsAsFactors = FALSE)\n}\n\n\n2M2 (1)\nCompute the grid for the given data using the function defined just abov\n\npost_grid_1 <- calc_post_water(c(\"W\", \"W\", \"W\"), 10, \"(1)\")\npost_grid_1\n\n       param       post label\n1  0.0000000 0.00000000   (1)\n2  0.1111111 0.00000000   (1)\n3  0.2222222 0.00000000   (1)\n4  0.3333333 0.00000000   (1)\n5  0.4444444 0.00000000   (1)\n6  0.5555556 0.06493506   (1)\n7  0.6666667 0.11220779   (1)\n8  0.7777778 0.17818182   (1)\n9  0.8888889 0.26597403   (1)\n10 1.0000000 0.37870130   (1)\n\n\n\n\n2M2 (2)\n\npost_grid_2 <- calc_post_water(c(\"W\", \"W\", \"W\", \"L\"), 10, \"(2)\")\n\n\n\n2M2 (3)\n\npost_grid_3 <- calc_post_water(c(\"L\", \"W\", \"W\", \"L\", \"W\", \"W\", \"W\"), 10, \"(3)\")\n\n\n\n2M2 plot\nAnd visualize the results\n\npd <- rbind(post_grid_1, post_grid_2, post_grid_3)  # data for graph\np2M2 <- ggplot(data = pd, mapping = aes(x = param, y = post, color = label)) +\n    geom_point(size = 3) + geom_line() +\n    scale_color_paletteer_d(palette = \"futurevisions::atomic_red\") +\n    theme_classic() +\n    theme(plot.title = element_text(color = \"dark blue\", hjust = 0.5),\n          legend.position = c(0.1, 0.85)) +\n    labs(title = \"Exercise 2M2\", x = \"parameter p\", y = \"posterior prob\")\np2M2"
  },
  {
    "objectID": "ch02_worlds.html#prac2M3",
    "href": "ch02_worlds.html#prac2M3",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2M3",
    "text": "2M3\nWe first need to formulate the probabilites\n\\[\n\\begin{equation}\nP(Earth \\mid Land) = \\\\\n\\frac{P(Earth, Land)}{P(Land)} = \\\\\n\\frac{P(Land \\mid Earth) \\cdot P(Earth)}{P(Land)} = \\\\\n\\frac{P(Land \\mid Earth) \\cdot P(Earth)}\n{P(Land \\mid Earth) \\cdot P(Earth) + P(Land \\mid Mars) \\cdot P(Mars)}\n\\end{equation}\n\\]\n\nprob_earth <- 0.5\nprob_mars <- 1 - prob_earth\nprob_water_earth <- 0.7\nprob_water_mars <- 0\nprob_land_earth <- 1 - prob_water_earth\nprob_land_mars <- 1 - prob_water_mars\n\n# Pr(Earth | Land) = Pr(Earth, Land) / Pr(Land) = Pr(Land | Earth) * P(Earth) / Pr(Land) =\n# Pr(Land | Earth) * P(Earth) / (Pr(Land | Earth) * Pr(Earth) + Pr(Land | Mars) * Pr(Mars))\n(prob_land_earth * prob_earth) / \n    (prob_land_earth * prob_earth + prob_land_mars * prob_mars)\n\n[1] 0.2307692"
  },
  {
    "objectID": "ch02_worlds.html#prac2M4",
    "href": "ch02_worlds.html#prac2M4",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2M4",
    "text": "2M4\nWe have the random variables\n\\(F\\): Represent the face that we see.\n\n\\(F=b\\): We see the black side.\n\\(F=w\\): We see the white face.\n\n\\(H\\): Represent the face that we don’t see, the hidden face.\n\n\\(H=b\\): The hidden side is black.\n\\(H=w\\): The hidden side is white.\n\nThe probabilities of \\(F\\) are \\(P(F=b) = P(F=w) = 0.5\\)\n\\(C=i\\): Represents the card # i that we pick with the following values\n\n\\(C=1\\): we pick card 1 which is black & black, notation\n\\(C=2\\): we pick card 2 which is black & white\n\\(C=3\\): we pick card 3 which is white & white\n\nand the pdf of \\(C\\) is\n\n\n\nCard\nProbability\n\n\n\n\n\\(C=1\\)\n\\(\\frac{1}{3}\\)\n\n\n\\(C=2\\)\n\\(\\frac{1}{3}\\)\n\n\n\\(C=3\\)\n\\(\\frac{1}{3}\\)\n\n\n\n\\[\nP(H=b \\mid F=b) = \\frac{P(H=b,F=b)}{P(F=b)} = \\frac{P(C=1)}{P(F=b)}= \\\\\n\\frac{P(C=1)}{P(F=b \\mid C=1)P(C=1) + P(F=b \\mid C=2)P(C=2) + P(F=b \\mid C=3)P(C=3)} \\\\\n\\frac{\\frac{1}{3}}{1 \\cdot \\frac{1}{3} + 0.5 \\cdot \\frac{1}{3} + 0 \\cdot \\frac{1}{3}} = \\frac{2}{3} \\approx 0.67\n\\]"
  },
  {
    "objectID": "ch02_worlds.html#prac2M5",
    "href": "ch02_worlds.html#prac2M5",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2M5",
    "text": "2M5\nUsing the same convention as in 2M4 and given that\n\n\n\nCard\nProbability\n\n\n\n\n\\(C=1\\)\n\\(\\frac{2}{4}\\)\n\n\n\\(C=2\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(C=3\\)\n\\(\\frac{1}{4}\\)\n\n\n\nthen, same as in 2M4 but with different probabilities,\n\\[\n\\frac{\\frac{2}{4}}{1 \\cdot \\frac{2}{4} + 0.5 \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{4}} = \\frac{4}{5}=0.8\n\\]"
  },
  {
    "objectID": "ch02_worlds.html#prac2M6",
    "href": "ch02_worlds.html#prac2M6",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2M6",
    "text": "2M6\n\n\n\nCard\nProbability\n\n\n\n\n\\(C=1\\)\n\\(\\frac{1}{6}\\)\n\n\n\\(C=2\\)\n\\(\\frac{2}{6}\\)\n\n\n\\(C=3\\)\n\\(\\frac{3}{6}\\)\n\n\n\nthen, same as in 2M4 but with different probabilities,\n\\[\n\\frac{\\frac{1}{6}}{1 \\cdot \\frac{1}{6} + 0.5 \\cdot \\frac{2}{6} + 0 \\cdot \\frac{3}{6}} = \\frac{1}{2}\n\\]"
  },
  {
    "objectID": "ch02_worlds.html#prac2M7",
    "href": "ch02_worlds.html#prac2M7",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2M7",
    "text": "2M7\n\\(C_i\\): The card chosen in the \\(i\\) pick \\(F_i\\): The face on the \\(i\\) pick \\(H_i\\): The hidden face of the card on the \\(i\\) pich\nThe joint probability table is\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(C_1\\)\n\\(C_2\\)\n\\(F_1\\)\n\\(H_1\\)\n\\(F_2\\)\n\\(H_2\\)\nfreq\nprob\n\n\n\n\n1\n2\nb\nb\nb\nw\n2\n\\(\\frac{2}{24}\\)\n\n\n1\n2\nb\nb\nw\nb\n2\n\\(\\frac{2}{24}\\)\n\n\n1\n3\nb\nb\nw\nw\n4\n\\(\\frac{4}{24}\\)\n\n\n2\n1\nb\nw\nb\nb\n2\n\\(\\frac{2}{24}\\)\n\n\n2\n1\nw\nb\nb\nb\n2\n\\(\\frac{2}{24}\\)\n\n\n2\n3\nb\nw\nw\nw\n2\n\\(\\frac{2}{24}\\)\n\n\n2\n3\nw\nb\nw\nw\n2\n\\(\\frac{2}{24}\\)\n\n\n3\n1\nw\nw\nb\nb\n4\n\\(\\frac{4}{24}\\)\n\n\n3\n2\nw\nw\nb\nw\n2\n\\(\\frac{2}{24}\\)\n\n\n3\n2\nw\nw\nw\nb\n2\n\\(\\frac{2}{24}\\)\n\n\n\nand using probabilities we have\n\\[\nP(H_1 = b \\mid F_1 = b, F_2 = w) = \\\\\n\\frac{P(H_1 = b, F_1 = b, F_2 = w)}{P(F_1=b, F_2=w)} = \\\\\n\\frac{P(F_2 = w, C_1 = 1)}{P(F_1=b,F_2=w,H_1=b)+P(F_1=b,F_2=w,H_1=w)} =\\\\\n\\frac{P(F_2 = w, C_1 = 1)}\n{P(F_2=w,C_1=1)+P(F_1=b,F_2=w,H_1=w)} =\\\\\n\\frac{\\frac{2}{24} +\\frac{4}{24}}\n{\\frac{2}{24} + \\frac{4}{24} + \\frac{2}{24}}=\\frac{3}{4}=0.75\n\\]"
  },
  {
    "objectID": "ch02_worlds.html#prac2H1",
    "href": "ch02_worlds.html#prac2H1",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2H1",
    "text": "2H1\nWe use \\(A,B\\) to identify the species.\nWe use \\(T_i=1,0\\) to identify if birth at time \\(i\\) is twin \\(T_i=1\\) or singleton \\(T_i=0\\)\nwe have\n\\[\nP(T_i=1 \\mid A)=0.1 \\\\\nP(T_i=1 \\mid B)=0.2\n\\]\nWe need to find \\(P(B_2=t \\mid B_1=t)\\) therefore\n$$ P(T_2=1 T_1=1)=\\ =\\ =\\ == \n$$"
  },
  {
    "objectID": "ch02_worlds.html#prac2H2",
    "href": "ch02_worlds.html#prac2H2",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2H2",
    "text": "2H2\n\\[\nP(A \\mid T_1 = 1) = \\frac{P(A, T_1=1)}{P(T_1=1)} = \\\\\n\\frac{P(T_1=1 \\mid A)P(A)}{P(T_1=1 \\mid A)P(A) + P(T_1=1 \\mid B)P(B)} = \\\\\n\\frac{0.1 \\cdot 0.5}{0.1 \\cdot 0.5 + 0.2 \\cdot 0.5} = \\frac{1}{3} \\approx 0.33\n\\]"
  },
  {
    "objectID": "ch02_worlds.html#prac2H3",
    "href": "ch02_worlds.html#prac2H3",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2H3",
    "text": "2H3\nsince \\(T_i\\) are independent then\n\\[\nP(A \\mid T_1 = 1, T_2 =0)=\\\\\n\\frac{P(A,T_1=1,T_2=0)}{P(T_1=1,T_2=0)}=\\\\\n\\frac{P(T_1=1, T_2=0 \\mid A)P(A)}{P(T_1=1,T_2=0\\mid A)P(A) + P(T_1=1,T_2=0\\mid B)P(B)}=\\\\\n\\frac{0.1 \\times 0.9 \\times 0.5}{(0.1 \\times 0.9 \\times 0.5) + (0.2 \\times 0.8 \\times 0.5)} =\n\\frac{0.045}{0.045+0.08}=\\frac{9}{25}=0.36\n\\]"
  },
  {
    "objectID": "ch02_worlds.html#prac2H4",
    "href": "ch02_worlds.html#prac2H4",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2H4",
    "text": "2H4\nThe new genetic test, called \\(G=a,b\\) when it identifies species A or B with a and b.\n\\[\nP(G=a \\mid A) = 0.8 \\\\\nP(G=b \\mid B) = 0.65 \\\\\nP(G=a \\mid B) = 1- P(G=b \\mid B) = 1-0.65=0.35\n\\]\nUsing the existing prior on the population of bear \\(P(S=a)=(S=b)=0.5\\)\n\\[\nP(A | G=a)=\\\\\n\\frac{P(G=a \\mid A) P(A)}{P(G=a)}=\\\\\n\\frac{P(G=a \\mid A) P(A)}{P(G=a \\mid A)P(A) + P(G=a \\mid B)P(B)} = \\\\\n\\frac{0.8 \\cdot 0.5}{0.8 \\cdot 0.5 + (1-0.65) \\cdot 0.5} = \\frac{0.45}{0.45+0.325}=\\frac{18}{25} = 0.72\n\\]\nWhich means that our prior of \\(P(A)=0.5\\) has been changed to \\(0.72\\) once we use the genetic test and therefore a better identification.\nSimilarly we will use the prior without genetic test in exercise 2H3 just above which had found \\(P(A') = P(A \\mid T_1 = 1, T_2 =0)=0.36\\) and use the genetic test as a new prior \\(P(A' \\mid G=a)\\)\n\\[\nP(A' \\mid G=a) = \\\\\n\\frac{P(G=a \\mid A')P(A')}{P(G=a \\mid A')P(A') + P(G=a \\mid B')P(B')} \\\\\n\\frac{0.8 \\cdot 0.36}{0.8 \\cdot 0.36 + 0.35 \\cdot (1-0.36)} \\approx 0.56\n\\]"
  },
  {
    "objectID": "ch03_sampling.html",
    "href": "ch03_sampling.html",
    "title": "3  Sampling the Imaginary",
    "section": "",
    "text": "The default theme used by ggplot2"
  },
  {
    "objectID": "ch03_sampling.html#prac3E1",
    "href": "ch03_sampling.html#prac3E1",
    "title": "3  Sampling the Imaginary",
    "section": "3E1",
    "text": "3E1\nThe samples used for the easy practices.\n\neasy_samples <- list()\neasy_samples <- within(easy_samples, {\n  p_grid <- seq(from = 0, to = 1, length.out = 1000)\n  prior <- rep(1, length(p_grid))\n  likelihood <- dbinom(x = 6, size = 9, prob = p_grid)\n  posterior <- likelihood * prior\n  posterior <- posterior / sum(posterior)\n  set.seed(100)\n  data <- sample(x = p_grid, size = 1e4, prob = posterior, replace = TRUE)\n})\n\n\n\n\n\n\n\nWarning\n\n\n\nPublished solution on internet has 5 instead of 4! I verified the code several times.\n\n\nThe nb of samples below 0.2 is\n\n# nb of samples < 0.2\nnb <- sum(easy_samples$data < 0.2)\n# the proportion\nprop <- nb / length(easy_samples$data)\nsprintf(\"%d samples representing %0.2f%%\", nb, 100 * prop)\n\n[1] \"4 samples representing 0.04%\""
  },
  {
    "objectID": "ch03_sampling.html#prac3E2",
    "href": "ch03_sampling.html#prac3E2",
    "title": "3  Sampling the Imaginary",
    "section": "3E2",
    "text": "3E2\n\n# nb of samples < 0.8\nnb <- sum(easy_samples$data > 0.8)\n# the proportion\nprop <- nb / length(easy_samples$data)\nsprintf(\"%d samples representing %0.2f%%\", nb, 100 * prop)\n\n[1] \"1116 samples representing 11.16%\""
  },
  {
    "objectID": "ch03_sampling.html#prac3E3",
    "href": "ch03_sampling.html#prac3E3",
    "title": "3  Sampling the Imaginary",
    "section": "3E3",
    "text": "3E3\n\n# nb of samples between 0.2 ad 0.8\nnb <- sum(0.2 <= easy_samples$data & easy_samples$data <= 0.8)\n# the proportion\nprop <- nb / length(easy_samples$data)\nsprintf(\"%d easy_samples$data representing %0.2f%%\", nb, 100 * prop)\n\n[1] \"8880 easy_samples$data representing 88.80%\""
  },
  {
    "objectID": "ch03_sampling.html#prac3E4",
    "href": "ch03_sampling.html#prac3E4",
    "title": "3  Sampling the Imaginary",
    "section": "3E4",
    "text": "3E4\n\nquantile(x = easy_samples$data, probs = 0.2)\n\n      20% \n0.5185185"
  },
  {
    "objectID": "ch03_sampling.html#prac3E5",
    "href": "ch03_sampling.html#prac3E5",
    "title": "3  Sampling the Imaginary",
    "section": "3E5",
    "text": "3E5\n\nquantile(x = easy_samples$data, probs = 1 - 0.2)\n\n      80% \n0.7557558"
  },
  {
    "objectID": "ch03_sampling.html#prac3E6",
    "href": "ch03_sampling.html#prac3E6",
    "title": "3  Sampling the Imaginary",
    "section": "3E6",
    "text": "3E6\nThis is the posterior high density interval.\nwith rethinking\n\n# with rethinking\nrethinking::HPDI(easy_samples$data, prob = 0.66)\n\n    |0.66     0.66| \n0.5085085 0.7737738 \n\n\nand with ggdist, we get the mean as a bonus and in a dataframe format.\n\n# with ggdist\nggdist::mean_hdi(easy_samples$data, .width = 0.66)\n\n          y      ymin      ymax .width .point .interval\n1 0.6348022 0.5085085 0.7737738   0.66   mean       hdi"
  },
  {
    "objectID": "ch03_sampling.html#prac3E7",
    "href": "ch03_sampling.html#prac3E7",
    "title": "3  Sampling the Imaginary",
    "section": "3E7",
    "text": "3E7\nThis is the usual quantile, symmetric, interval.\nwith rethinking\n\n# with rethinking\nrethinking::PI(easy_samples$data, prob = 0.66)\n\n      17%       83% \n0.5025025 0.7697698 \n\n\nwith ggdist\n\n# with ggdist\nggdist::mean_qi(easy_samples$data, .width = 0.66)\n\n          y      ymin      ymax .width .point .interval\n1 0.6348022 0.5025025 0.7697698   0.66   mean        qi"
  },
  {
    "objectID": "ch03_sampling.html#prac3M1",
    "href": "ch03_sampling.html#prac3M1",
    "title": "3  Sampling the Imaginary",
    "section": "3M1",
    "text": "3M1\nCreate the grid\n\nsim03M01 <- list()\nsim03M01 <- within(sim03M01, {\n  n_success <- 8\n  n_trials <- 15\n  data <- data.frame(\n    p_grid = seq(from = 0, to = 1, length.out = 1000),\n    prior = 1) %>%\n    mutate(\n     likelihood = dbinom(x = n_success, size = n_trials, prob = p_grid),\n     posterior = (likelihood * prior) / sum(likelihood * prior)\n    )\n  stopifnot(near(sum(data$posterior), 1))\n})\n\n\nggplot(data = sim03M01$data, mapping = aes(x = p_grid, y = posterior)) +\n    geom_point(size = 1, color = \"palevioletred\", alpha = 0.9) +\n    theme(legend.position = \"none\") +\n    labs(title = \"Practice 3M1\",\n         subtitle = sprintf(\"Grid size = %d\", nrow(sim03M01)),\n         x = \"grid values of probability of water\", \n         y = \"posterior probability simulated\")"
  },
  {
    "objectID": "ch03_sampling.html#prac3M2",
    "href": "ch03_sampling.html#prac3M2",
    "title": "3  Sampling the Imaginary",
    "section": "3M2",
    "text": "3M2\nCreate the sampled data\n\nset.seed(173)\ndata03M02 <- sim03M01$data |>\n  slice_sample(n = 1e4, weight_by = posterior, replace = TRUE) |>\n  mutate(id = n()) |>\n  relocate(.before = p_grid)\n\nand find the HPDI\n\n# HPDI with rethinking\nrethinking::HPDI(data03M02$p_grid, prob = 0.9)\n\n     |0.9      0.9| \n0.3293293 0.7207207 \n\n\n\n# HPDI with ggdist\ndata03M02 |> \n  ggdist::mean_hdi(p_grid, .width = 0.9)\n\n# A tibble: 1 × 6\n  p_grid .lower .upper .width .point .interval\n   <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n1  0.529  0.329  0.721    0.9 mean   hdi"
  },
  {
    "objectID": "ch03_sampling.html#prac3M3",
    "href": "ch03_sampling.html#prac3M3",
    "title": "3  Sampling the Imaginary",
    "section": "3M3",
    "text": "3M3\nConstructing a posterior prediction by simulating \\(W\\) with the sampled \\(p\\). See the R code 3.26, p. 66.\n\n# using the sampled p we simulate\ndata03M03 <- data03M02 |>\n  mutate(predict = rbinom(n = n(), size = sim03M01$n_trials, prob = p_grid))\n# data03M03\n\nand using it to calculate the prob of having 8 \\(W\\) in 15 trials\n\nsum(data03M03$predict == 8 ) / length(data03M03$predict)\n\n[1] 0.1525\n\n\nthe histogram of the predictions is\n\ncolr <- paletteer::paletteer_d(\"Manu::Hoiho\")\nggplot(data03M03, aes(x=predict)) +\n  geom_histogram(aes(fill = after_stat(count))) +\n  scale_x_continuous(breaks = 0:15) +\n  scale_fill_gradientn(colors = colr) +\n  theme(legend.position = \"none\",\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank()) +\n  labs(title = \"Practice 3M3\",\n       subtitle = sprintf(\"Frequencies of %d predictions\", nrow(data03M03)))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "ch03_sampling.html#prac3M4",
    "href": "ch03_sampling.html#prac3M4",
    "title": "3  Sampling the Imaginary",
    "section": "3M4",
    "text": "3M4\nProb of 6 \\(W\\) in 9 tosses with the post dist of 8 \\(W\\) in 15 tosses. Same process as in 3M3.\n\npost_pred <- rbinom(n = nrow(data03M03), size = 9, prob = data03M03$p_grid)\nsum(post_pred == 6 ) / length(post_pred)\n\n[1] 0.1744"
  },
  {
    "objectID": "ch03_sampling.html#prac3M5",
    "href": "ch03_sampling.html#prac3M5",
    "title": "3  Sampling the Imaginary",
    "section": "3M5",
    "text": "3M5\nCreate the grid\n\ngrid03M05 <- data.frame(\n    p_grid = seq(from = 0, to = 1, length.out = 1000)) |>\n    mutate(\n      prior = ifelse(p_grid < 0.5, 0, 1),\n      likelihood = dbinom(x = 8, size = 15, prob = p_grid),\n      posterior = (likelihood * prior) / sum(likelihood * prior))\nstopifnot(near(sum(grid03M05$posterior), 1))\n\n\nggplot(data = grid03M05, mapping = aes(x = p_grid, y = posterior)) +\n  geom_point(size = 1, color = \"slateblue1\", alpha = 0.9) +\n  geom_line(color = \"slateblue1\") +\n  theme(legend.position = \"none\") +\n  labs(title = \"Practice 3M5\",\n       subtitle = sprintf(\"Grid size = %d\", nrow(grid03M05)),\n       x = \"grid values of probability of water\", \n       y = \"posterior probability simulated\")\n\n\n\n\nCreate the sampled data\n\nset.seed(100)\ndata03M05 <- grid03M05 |>\n  slice_sample(n = 1e4, weight_by = posterior, replace = TRUE) %>%\n  mutate(id = n(), .before = p_grid)\n\nand find the HPDI\n\n# HPDI with rethinking\nrethinking::HPDI(data03M05$p_grid, prob = 0.9)\n\n     |0.9      0.9| \n0.5005005 0.7097097 \n\n\n\n# HPDI with ggdist\ndata03M05 |>\n  ggdist::mean_hdi(p_grid, .width = 0.9)\n\n# A tibble: 1 × 6\n  p_grid .lower .upper .width .point .interval\n   <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n1  0.605  0.501  0.710    0.9 mean   hdi      \n\n\nConstructing a posterior prediction by simulating \\(W\\) with the sampled \\(p\\).\n\n# using the sampled p we simulate the water\ndata03M05 <- data03M05 |>\n  mutate(predict = rbinom(n = n(), size = 15, prob = p_grid))\n\nthe histogram of the predictions is\n\ncolr <- paletteer::paletteer_d(\"Manu::Hoiho\", direction = -1)\nggplot(data03M05, aes(x=predict)) +\n  geom_histogram(aes(fill = after_stat(count))) +\n  scale_x_continuous(breaks = 0:15) +\n  scale_fill_gradientn(colors = colr) +\n  theme(legend.position = \"none\",\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank()) +\n  labs(title = \"Practice 3M5\",\n       subtitle = sprintf(\"Frequencies of %d predictions\", nrow(data03M05)))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "ch03_sampling.html#prac3M6",
    "href": "ch03_sampling.html#prac3M6",
    "title": "3  Sampling the Imaginary",
    "section": "3M6",
    "text": "3M6\nWe perform a sampling from a grid as in section 3.1 but, this time, with a grid covering two variables: the percentage of water (probability of success) \\(p_water\\) as well as the nb of tosses (trials) that is \\(n_tosses\\).\nThe assumed prior for \\(p_water\\) is flat. You can change this at your discretion.\n\np_water <- seq(from = 0, to = 1, by = 0.01)\nn_tosses <- seq(from = 500, to = 5000, by = 500)\nthe_grid <- expand_grid(p_water, n_tosses)\n# assume flat uniform prior, feel free to change it\nthe_grid$prior <- rep(1, times = nrow(the_grid))\nstopifnot(nrow(the_grid) == length(p_water) * length(n_tosses))\n\nand we compute the posterior probability of every \\(p_water\\) in the grid, given \\(n_tosses\\). Since we don’t have \\(y\\), that is the observed nb of successes, we simulate them, assuming \\(p=0.7\\) with rbinom(x = 1, size = the_grid$n_tosses, prob = 0.7).\n\n# compute the x, nb of success using rbinom()\nset.seed(3)\nx_water <- rbinom(n = 1, size = the_grid$n_tosses, prob = 0.7)\nlikelihood <- dbinom(x = x_water, size = the_grid$n_tosses, prob = the_grid$p_water)\n# compute the posterior of p\nposterior <- likelihood * the_grid$prior\nposterior <- posterior / sum(posterior)\nthe_grid$posterior <- posterior\n# the posterior must add up to 1\nstopifnot(sum(the_grid$posterior) == 1)\n\nand we finally create a matrix of simulations where every column of the matrix is a simulated sample using a given nb of tosses.\n\n# create matrix of samples, each column is an assumed nb of tosses\nmsamples <- sapply(X = n_tosses, FUN = function(x){\n  a_grid <- the_grid[the_grid$n_tosses == x, ]\n  samples <- sample(x = a_grid$p_water, size = 1000, prob = a_grid$posterior, replace = TRUE)\n  return(samples)\n})\n# name the columns after the nb of tosses\ncolnames(msamples) <- n_tosses\n\nand the final answer is given by finding the width of the 99% interval fro every assumption of \\(n_tosses\\) (column). The quantile interval rethinking::PI(x, prob = 0.99) but is used, the high-density interval rethinking::HPDI(x, prob = 0.99) could also used.\n\n# find the width of the range for each sample (column)\n(apply(X = msamples, MARGIN = 2, FUN = function(x) diff(rethinking::PI(x, prob = 0.99))))\n\n 500 1000 1500 2000 2500 3000 3500 4000 4500 5000 \n0.11 0.07 0.06 0.04 0.03 0.02 0.03 0.02 0.02 0.01 \n\n\n\nThe answer is therefore that the nb of tosses should >= 2000, assuming a flat uniform prior, using increments of 500 for the nb of tosses."
  },
  {
    "objectID": "ch03_sampling.html#prac3H1",
    "href": "ch03_sampling.html#prac3H1",
    "title": "3  Sampling the Imaginary",
    "section": "3H1",
    "text": "3H1\nLoading the data from the rethinking package\n\ndata(homeworkch3)\n\nGet the prior estimate from the data and calculate the posterior\n\nn_boys <- sum(birth1) + sum(birth2)\nn_births <- length(birth1) + length(birth2)\np_boys <- n_boys / n_births\np_grid <- seq(from = 0, to = 1, by = 0.01)\np_prior <- rep(1, times = length(p_grid))\ndf <- data.frame(\n    p_grid = p_grid,\n    prior = p_prior) %>%\n    mutate(\n     likelihood = dbinom(x = n_boys, size = n_births, prob = p_grid),\n     posterior = (likelihood * prior) / sum(likelihood * prior)\n    )\nstopifnot(sum(df$posterior) == 1)\n\nusing the position of the maximum posterior prob. we find the p that maximize the posterior\n\n(df$p_grid[which.max(df$posterior)])\n\n[1] 0.55"
  },
  {
    "objectID": "ch03_sampling.html#prac3H2",
    "href": "ch03_sampling.html#prac3H2",
    "title": "3  Sampling the Imaginary",
    "section": "3H2",
    "text": "3H2\n\nsamples <- sample(x = df$p_grid, size = 1e4, prob = df$posterior, replace = TRUE)\n# 50%, 89%, 97% with HPDI\nrethinking::HPDI(samples, prob = c(0.5, 0.89, 0.97))\n\n|0.97 |0.89  |0.5  0.5| 0.89| 0.97| \n 0.47  0.49  0.54  0.58  0.60  0.62 \n\n\nand with gdist\n\nggdist::mean_hdi(.data = samples, .width = c(0.50, 0.89, 0.97))\n\n         y ymin ymax .width .point .interval\n1 0.554682 0.54 0.58   0.50   mean       hdi\n2 0.554682 0.49 0.60   0.89   mean       hdi\n3 0.554682 0.47 0.62   0.97   mean       hdi"
  },
  {
    "objectID": "ch03_sampling.html#prac3H3",
    "href": "ch03_sampling.html#prac3H3",
    "title": "3  Sampling the Imaginary",
    "section": "3H3",
    "text": "3H3\n\n# do a posterior prediction\npred <- data.frame(pred = \n                     rbinom(n = length(samples), size = n_births, prob = samples)\n                   )\n# avg nb of boys in the simulation\nmean(pred$pred)\n\n[1] 110.9704\n\n# using the HPDI to find the interval\nrethinking::HPDI(pred$pred, prob = 0.89)\n\n|0.89 0.89| \n   94   126 \n\n\nor getting the mean and interval all at once with ggdist\n\nggdist::mean_hdi(.data = pred$pred, .width = 0.89)\n\n         y ymin ymax .width .point .interval\n1 110.9704   94  126   0.89   mean       hdi\n\n\n\nrng <- range(pred$pred)\nqtl <- c(0.5, 0.8, 0.95, 1)\nx_breaks <- ggdist::mean_qi(.data = pred$pred, .width = qtl) %>%\n  select(y, ymin, ymax) %>%\n  pivot_longer(cols = c(\"y\", \"ymin\", \"ymax\")) %>%\n  distinct(value) %>%\n  arrange(value) %>%\n  pull() %>%\n  as.integer()\n\n# the actual binomial distribution of the observations\nset.seed(3)\ndist_binom <- data.frame(x = rbinom(n = length(samples), size = n_births, prob = p_boys))\nggplot(pred, aes(x = pred)) +\n  stat_halfeye(aes(fill=after_stat(level)),\n               point_interval = ggdist::mean_qi, .width = qtl) +\n  geom_density(data = dist_binom, mapping = aes(x, y = after_stat(scaled)), \n               color = \"violetred\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = c(mean(dist_binom$x), mean(pred$pred)), \n             color = c(\"violetred\", \"darkgreen\"), linetype = c(\"dashed\", \"solid\")) +\n  scale_x_continuous(breaks = x_breaks,limits = rng) +\n  scale_fill_paletteer_d(palette = \"Manu::Takahe\", direction = -1,\n                         na.translate = FALSE) +\n  theme(legend.position = c(0.1,0.75)) +\n  labs(title = \"Practice 3H3\", x = \"nb of boys\", y = \"probability\", fill = \"quantiles\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Using the `size` aesthietic with geom_segment was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead."
  },
  {
    "objectID": "ch03_sampling.html#prac3H4",
    "href": "ch03_sampling.html#prac3H4",
    "title": "3  Sampling the Imaginary",
    "section": "3H4",
    "text": "3H4\nFinding the posterior dist with only the first-born\n\nn_boys <- sum(birth1)\nn_births <- length(birth1)\np_boys <- n_boys / n_births\np_grid <- seq(from = 0, to = 1, by = 0.01)\np_prior <- rep(1, times = length(p_grid))\ndf <- data.frame(\n    p_grid = p_grid,\n    prior = p_prior) %>%\n    mutate(\n     likelihood = dbinom(x = n_boys, size = n_births, prob = p_grid),\n     posterior = (likelihood * prior) / sum(likelihood * prior)\n    )\nstopifnot(sum(df$posterior) == 1)\n\nand create a sample of the \\(p\\) from the grid and its posterior.\n\nset.seed(3)\nsamples <- sample(x = df$p_grid, size = 1e4, prob = df$posterior, replace = TRUE)\n\n\n# do a posterior prediction\npred <- data.frame(pred = \n                     rbinom(n = length(samples), size = n_births, prob = samples)\n                   )\n# avg nb of boys in the simulation\nmean(pred$pred)\n\n[1] 50.9552\n\n# using the HPDI to find the interval of prior\nrethinking::HPDI(pred$pred, prob = 0.89)\n\n|0.89 0.89| \n   39    61 \n\n\nor getting the prior’s mean and interval all at once with ggdist\n\nggdist::mean_hdi(.data = pred$pred, .width = 0.89)\n\n        y ymin ymax .width .point .interval\n1 50.9552   39   61   0.89   mean       hdi\n\n\n\nrng <- range(pred$pred)\n# the acutal binomial distribution of the observations\nset.seed(3)\ndist_binom <- data.frame(x = rbinom(n = length(samples), size = n_births, prob = p_boys))\nggplot(pred, aes(x = pred)) +\n  stat_halfeye(point_interval = ggdist::mean_hdi, .width = 0.89, fill = \"rosybrown1\") +\n  geom_density(data = dist_binom, mapping = aes(x, y = after_stat(scaled)), \n               color = \"navy\", linetype = \"dashed\") +\n  geom_vline(xintercept = c(mean(dist_binom$x), mean(pred$pred)), \n             color = c(\"navy\", \"rosybrown4\"), linetype = c(\"dashed\", \"solid\")) +\n  scale_x_continuous(limits = rng) +\n  labs(title = \"Practice 3H4\", x = \"nb of boys\", y = \"probability\")"
  },
  {
    "objectID": "ch03_sampling.html#prac3H5",
    "href": "ch03_sampling.html#prac3H5",
    "title": "3  Sampling the Imaginary",
    "section": "3H5",
    "text": "3H5\nThe idea here is that, if boys are independent of girls then \\(P(boy \\mid girl) = P(boy)\\) when \\(boy\\) and \\(girl\\) are independent.\nFinding the posterior dist with boys born after a girl.\n\n# births of girls followed by boy\ngirlboy <- (birth1 == 0) & (birth2 == 1)\nn_girlboy <- sum(girlboy)\nn_births <- length(girlboy)\np_girlboy <- n_girlboy / n_births\np_grid <- seq(from = 0, to = 1, by = 0.01)\np_prior <- rep(1, times = length(p_grid))\ndf <- data.frame(\n    p_grid = p_grid,\n    prior = p_prior) %>%\n    mutate(\n     likelihood = dbinom(x = n_girlboy, size = n_births, prob = p_grid),\n     posterior = (likelihood * prior) / sum(likelihood * prior)\n    )\nstopifnot(sum(df$posterior) == 1)\n\nGet a sample of \\(p\\) from the grid using the posterior as probability of the given value. Then make a predicition of boys using these sampled \\(p\\) values\n\n# sample the grid using the posterior probabilities\nsamples <- sample(x = df$p_grid, size = 10000, replace = TRUE, prob = df$posterior)\n# simulate births\npred <- data.frame(pred = \n                     rbinom(n = length(samples), size = n_births, prob = samples)\n                   )\n# using the HPDI to find the interval\nHPDI(pred$pred, prob = 0.89)\n\n|0.89 0.89| \n   28    49 \n\n\nand visualize\n\n# draw a graph with the result\nrng <- range(pred$pred)\n# the acutal binomial distribution of the observations\nset.seed(3)\ndist_binom <- data.frame(x = rbinom(n = length(samples), size = n_births, prob = p_girlboy))\nggplot(pred, aes(x = pred)) +\n  stat_halfeye(point_interval = ggdist::mean_hdi, .width = 0.89, fill = \"peachpuff\") +\n  geom_density(data = dist_binom, mapping = aes(x, y = after_stat(scaled)), \n               color = \"slateblue4\", linetype = \"dashed\") +\n  geom_vline(xintercept = c(mean(dist_binom$x), mean(pred$pred)), \n             color = c(\"slateblue4\", \"peachpuff4\"), linetype = c(\"dashed\", \"solid\")) +\n  scale_x_continuous(limits = rng) +\n  labs(title = \"Practice 3H5\", x = \"nb of boys\", y = \"probability\")\n\n\n\n\nThe average nb of first boys was about 50, see 3H4 above. Now, using the second born boy given a girl was born, the average is 40. It should remain about the same if boys were independent f girls and it is obviously not.\nConclusion: Birth of boy is not independent of girls."
  },
  {
    "objectID": "ch04_linear.html",
    "href": "ch04_linear.html",
    "title": "4  Linear Models",
    "section": "",
    "text": "#  For execution on a local, multicore CPU with excess RAM\noptions(mc.cores = parallel::detectCores())\n#  To avoid recompilation of unchanged Stan programs\nrstan_options(auto_write = TRUE)"
  },
  {
    "objectID": "ch04_linear.html#prac4E1",
    "href": "ch04_linear.html#prac4E1",
    "title": "4  Linear Models",
    "section": "4E1",
    "text": "4E1\nSee section 4.4.1 in McElreath (2020)\n\\(y_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)"
  },
  {
    "objectID": "ch04_linear.html#prac4E2",
    "href": "ch04_linear.html#prac4E2",
    "title": "4  Linear Models",
    "section": "4E2",
    "text": "4E2\n2 parameters, \\(\\mu\\) and \\(\\sigma\\) which are in the posterior distribution \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)"
  },
  {
    "objectID": "ch04_linear.html#prac4E3",
    "href": "ch04_linear.html#prac4E3",
    "title": "4  Linear Models",
    "section": "4E3",
    "text": "4E3\nSee Overthinking in section 4.3.1\n$$ \\[\\begin{align*}\nP(\\mu, \\sigma \\mid \\textbf{y}) &=\n\n\\frac{\n    P(\\textbf{y}, \\mu, \\sigma)\n}{\n    P(\\textbf{y})\n} \\\\\n\n&= \\frac{\n    P(\\textbf{y}, \\mu, \\sigma)\n}{\n    \\int_{\\sigma} \\int_{\\mu} P(\\textbf{y} \\mid \\mu, \\sigma) \\cdot P(\\mu, \\sigma) d\\mu d\\sigma \\\\\n} \\\\\n\n&=\n\n\\frac{\n    \\prod_i P(y_i, \\mu, \\sigma)\n}{\n    \\int_{\\sigma} \\int_{\\mu} \\prod_i P(y_i \\mid \\mu, \\sigma) \\cdot P(\\mu, \\sigma) d\\mu d\\sigma \\\\\n} \\\\\n\n&=\n\n\\frac{\n    \\prod_i P(y_i \\mid \\mu, \\sigma) \\cdot P(\\mu) \\cdot P(\\sigma)\n}{\n    \\int_{\\sigma} \\int_{\\mu} \\prod_i P(y_i \\mid \\mu, \\sigma) \\cdot P(\\mu) \\cdot P(\\sigma) d\\mu d\\sigma \\\\\n} \\\\\n\n&=\n\n\\frac{\n    \\prod_i \\mathcal{N}(y_i \\mid \\mu, \\sigma) \\cdot \\mathcal{N}(\\mu \\mid mean = 0, sd = 10) \\cdot \\mathcal{Exp}(\\sigma \\mid rate = 1)\n}{\n    \\int_{\\sigma} \\int_{\\mu}{\n        \\prod_{i=1}^n \\mathcal{N}(y_i \\mid \\mu, \\sigma) \\cdot \\mathcal{N}(\\mu \\mid mean = 0, sd = 10) \\cdot \\mathcal{Exp}(\\sigma \\mid rate = 1)\n    }\n    d\\mu d\\sigma\n}\n\n\\end{align*}\\] $$"
  },
  {
    "objectID": "ch04_linear.html#prac4E4",
    "href": "ch04_linear.html#prac4E4",
    "title": "4  Linear Models",
    "section": "4E4",
    "text": "4E4\n\\(\\mu_i = \\alpha + \\beta x_i\\)"
  },
  {
    "objectID": "ch04_linear.html#prac4E5",
    "href": "ch04_linear.html#prac4E5",
    "title": "4  Linear Models",
    "section": "4E5",
    "text": "4E5\n2 parameters, \\(\\mu\\) and \\(\\sigma\\)"
  },
  {
    "objectID": "ch04_linear.html#prac4M1",
    "href": "ch04_linear.html#prac4M1",
    "title": "4  Linear Models",
    "section": "4M1",
    "text": "4M1\nSee R code 4.13 in section 4.3.2 using this model.\nWe use the simstudy package to do the simulation. It is a wonderful tools to simulate models and will be used repeatedly in this project.\nAlso we use the posterior package to use the many tools this package offers to simplify using posterior samples.\n\nsim04M01 <- list()\nsim04M01 <- within(sim04M01, {\n  def <- defData(varname = \"mu\", dist = \"normal\", formula = 0, variance = 10^2)\n  def <- defData(def, varname = \"sigma\", dist = \"exponential\", formula = 1)\n  def <- defData(def, varname = \"height\", dist = \"normal\", formula = \"mu\", \n               variance = \"sigma\")\n  # generate the data\n  set.seed(53)  # for fun: 53 is a balanced prime\n  data <- genData(n = 5000, dtDefs = def)\n  \n  # get the intervals\n  widths <- c(0.67, 0.95, 1)\n  intrvl <- data |>\n    select(-id) |>\n    pivot_longer(cols = everything()) |>\n    group_by(name) |>\n    ggdist::median_qi(.width = widths)\n  \n  # the breaks used for the x axis\n  breaks_x <- intrvl |>\n    filter(name == \"height\") |>\n    select(.lower, value, .upper) |>\n    pivot_longer(cols = everything()) |>\n    arrange(value) |>\n    pull(value)\n  })\n\n\nggplot(sim04M01$data, mapping = aes(x = height)) +\n  ggdist::stat_halfeye(aes(fill = after_stat(level)),\n                       point_interval = median_qi,\n                       color = \"darkorange\",\n                       .width = c(0.67, 0.95, 1)) +\n  scale_x_continuous(breaks = sim04M01$breaks_x,\n                     labels = scales::label_number(accuracy = 0.1)) +\n  scale_fill_paletteer_d(\"ggsci::indigo_material\",\n                         direction = 1,\n                         name = \"levels %\",\n                         labels = round(100 * sim04M01$widths, 0),\n                         na.translate = FALSE) +\n  theme(legend.position = c(0.8, 0.8)) +\n  labs(title = \"4M1: Prior prediction of height\", \n       subtitle = sprintf(\"sample size = %d\", nrow(sim04M01$data)))\n\nWarning: Using the `size` aesthietic with geom_segment was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead."
  },
  {
    "objectID": "ch04_linear.html#prac4M2",
    "href": "ch04_linear.html#prac4M2",
    "title": "4  Linear Models",
    "section": "4M2",
    "text": "4M2\nSee section 4.4.2 on how to use quap, R code 4.43 with linear equation with the quap formula, i.e. flist = alist(...).\n\nalist(\n    height ~ dnorm(mean = mu, sd = sigma),\n    mu = a + b * x,\n    a ~ dnorm(mean = 0, sd = 10),\n    b ~ dnorm(mean = 0, sd = 1),\n    sigma ~ dexp(rate = 1)\n    )"
  },
  {
    "objectID": "ch04_linear.html#prac4M3",
    "href": "ch04_linear.html#prac4M3",
    "title": "4  Linear Models",
    "section": "4M3",
    "text": "4M3\nMake sure you remember to index the \\(y\\) so that it is \\(y_i\\) as well as \\(\\mu\\). See section 4.4.2. The published answer does not put an index on \\(\\mu\\) but it has one on \\(y\\) which involves a constant \\(\\mu\\) which is normally the intercept! This question is confusing, here we assume the same meaning as in section 4.4.2., that is \\(\\mu\\) varies for each \\(x_i\\)\n\\[\n\\begin{align*}\ny_i &\\sim \\mathcal{N}(mean = \\mu_i, sd = \\sigma)\\\\\n\\mu_i &= \\alpha + \\beta x_i \\\\\n\\alpha &\\sim \\mathcal{N}(mean = 0, sd = 10) \\\\\n\\beta &\\sim \\mathcal{Uniform}(mean = 0, sd = 1) \\\\\n\\sigma &\\sim \\mathcal{Exponential}(\\lambda = 1)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "ch04_linear.html#prac4M4",
    "href": "ch04_linear.html#prac4M4",
    "title": "4  Linear Models",
    "section": "4M4",
    "text": "4M4\nDon’t forget the index so that \\(height\\) is \\(height_i\\).\nThis will be giving the average height per year. The question is not clear that it wants it by student also.\n\\[\n\\begin{align*}\nheight_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot year_i \\\\\n\\alpha &\\sim \\mathcal{N}(100, 10) \\\\\n\\beta &\\sim \\mathcal{Uniform}(0, 10) \\\\\n\\sigma &\\sim \\mathcal{Exponential}(1)\n\\end{align*}\n\\]\nThe choice of priors are * \\(\\alpha\\): The intercept reflect the population average which is 100 and we expect the 95% of the population to be between 80 and 120 at the very most * \\(\\beta\\): The coefficient should be nonnegative as the height should increase or stay the same in younger age. We choose uniform distribution as we have no information whatsoever about the rate of growth. * \\(\\sigma\\): The overall outcome variance should be positive with a skewed distribution, hence using \\(\\mathcal{Exponential}(1)\\). See p. 118 and p. 119 on using the exponential distribution in the textbook."
  },
  {
    "objectID": "ch04_linear.html#prac4M5",
    "href": "ch04_linear.html#prac4M5",
    "title": "4  Linear Models",
    "section": "4M5",
    "text": "4M5\nThis tells us that \\(\\beta\\) should always be positive be with large values unlikely. We therefore use the log-normal dist as a prior for \\(\\beta\\). See section 4.4.2.\n\\[\n\\begin{align*}\nheight_i &\\sim Normal(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot year_i \\\\\n\\alpha &\\sim \\mathcal{Normal}(100, 10) \\\\\n\\beta &\\sim \\mathcal{LogNormal}(0, 1) \\\\\n\\sigma &\\sim \\mathcal{Exponential}(1)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "ch04_linear.html#prac4M6",
    "href": "ch04_linear.html#prac4M6",
    "title": "4  Linear Models",
    "section": "4M6",
    "text": "4M6\nInstead of using the average range as a prior for \\(\\sigma\\) we would use \\(\\sigma = \\sqrt{64} = 8\\).\n\nIn the official solution solution McElreath says it should be \\(\\sigma \\sim Uniform(0, 64)\\), no sqrt of the variance to obtain the standard deviation is done.\n\n\\[\nheight_i \\sim Normal(\\mu_i, \\sigma) \\\\\nmu_i = \\alpha + \\beta \\cdot year_i \\\\\n\\alpha \\sim Normal(120, 10) \\\\\n\\beta \\sim Normal(0, 10) \\\\\n\\sigma \\sim Uniform(0, 8)\n\\]"
  },
  {
    "objectID": "ch04_linear.html#prac4M7",
    "href": "ch04_linear.html#prac4M7",
    "title": "4  Linear Models",
    "section": "4M7",
    "text": "4M7\nSee section 4.4.2 for model m4.3. We add the centered weight to the data and call it \\(weight_c\\).\n\ndata(Howell1)\ndata04M07 <- Howell1 |>\n  filter(age >= 18) |>\n  mutate(weight_c = as.vector(scale(weight, center = TRUE, scale = FALSE)))\nrm(Howell1)\nskimr::skim(data04M07)\n\n\nData summary\n\n\nName\ndata04M07\n\n\nNumber of rows\n352\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nheight\n0\n1\n154.60\n7.74\n136.52\n148.59\n154.30\n160.66\n179.07\n▂▇▇▃▁\n\n\nweight\n0\n1\n44.99\n6.46\n31.07\n40.26\n44.79\n49.29\n62.99\n▃▆▇▃▁\n\n\nage\n0\n1\n41.14\n15.97\n18.00\n28.00\n39.00\n51.00\n88.00\n▇▇▃▂▁\n\n\nmale\n0\n1\n0.47\n0.50\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▇\n\n\nweight_c\n0\n1\n0.00\n6.46\n-13.92\n-4.73\n-0.20\n4.30\n18.00\n▃▆▇▃▁\n\n\n\n\n\n\nModel\n\\[\n\\begin{align*}\nheight_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta(x_i - \\bar{x}) \\\\\n\\alpha &\\sim \\mathcal{N}(178, 20) \\\\\n\\beta &\\sim \\mathcal{LogNormal}(0, 1) \\\\\n\\sigma &\\sim \\mathcal{Exp}(1)\n\\end{align*}\n\\]\n\n\nFitting strategies\nThis practice is used to illustrate 3 different methods that can be used to fit the model to the data. They are from the package rethinking (of course), the very well-known package brms that is used in Kurz (2019) and the package INLA which state of the art and is explained, for example, by Gomez-Rubio (2020) and Xiaofeng Wang (2018).\nThe package tidybayes is used to harmonize the different commands and demonstrate that the process is the same. Since there is no tidybayes command for INLA, similar functions are coded in the eflINLA package.\nThe package posterior is used to harmonize the results from these 3 types of fit.\n\n\nPriors\nWe simulate the priors using the specifications from the model. The lognormal distribution is not available in simstudy. The solution is to create a custom (nonrandom) distribution as demonstrated in lognormal. However this gives me an error message, so instead, beta is exponentiated in mu’s formula.\n\nsim04M07 <- list()\nsim04M07 <- within(sim04M07, {\n  xrng <- paste(round(range(data04M07$weight_c)), collapse = \";\")\n  def <- defData(varname = \"x\", dist = \"uniform\", formula = xrng)\n  def <- defData(def, varname = \"alpha\", formula = 178, variance = 20^2)\n  def <- defData(def, varname = \"beta\", formula = 0, variance = 1^2)\n  def <- defData(def, varname = \"sigma\", dist = \"exponential\", formula = 1)\n  forml <- \"alpha + exp(beta) *x\"  # convert beta to exp since it is lognormal dist\n  def <- defData(def, varname = \"mu\", dist = \"nonrandom\", formula = forml)\n  def <- defData(def, varname = \"height\", formula = \"mu\", variance = \"sigma\")\n  \n  set.seed(157)  # for fun: 157 is a balanced prime\n  data <- genData(n = 1000, dtDefs = def)\n  \n  # stats used for vertical lines by the plot\n  vlines <- data.frame(\n    model = c(\"prior\", \"observed\"),\n    mode = c(ggdist::Mode(data$height), ggdist::Mode(data04M07$height)))\n})\n\n\nggplot(sim04M07$data) +\n  geom_density(aes(x = height, y = after_stat(scaled), color = \"prior\"),\n               linewidth = 1, alpha = 0.8) +\n  geom_density(data = data04M07, aes(x = height, y = after_stat(scaled), color = \"observed\"),\n               linewidth = 1, alpha = 0.8) +\n  geom_vline(data = sim04M07$vlines, mapping = aes(xintercept = mode, color = model),\n             linetype = \"dashed\") +\n  scale_color_manual(values = c(\"prior\" = \"mediumvioletred\", \n                                \"observed\" = \"mediumseagreen\")) +\n  scale_x_continuous(breaks = scales::breaks_pretty(n = 7)) +\n  coord_cartesian(xlim = c(50, 300)) +\n  theme(legend.position = c(0.8, 0.8)) +\n  labs(title = paste0(\n    \"4M7: Comparing prior predictive distribution vs observed distribution\",\n    \"\\n\", \"vertical lines = mode\"),\n    x = \"height\", y = NULL, color = NULL)\n\n\n\n\nThe prior is reasonable as it reflects an opinion on the overall general population.\n\n\nUsing quap\n\nFits\nThe fit using the centered, model m4.3 in textbook.\n\nfit04M07 <- list()\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"1 secs.\"))\nfit04M07$quap_ctr <- xfun::cache_rds({\n  quap(\n    flist = alist(\n      height ~ dnorm(mu, sigma),\n      mu <- a + b * weight_c,\n      a ~ dnorm(178, 20),\n      b ~ dlnorm(0, 1),\n      sigma ~ dunif(0, 50)\n      ),\n    data = data04M07,\n    start = list(a = mean(data04M07$weight), b = 0.5, sigma = 25)\n    )},\n  file = \"ch04_fit04M07_quap_ctr\")\ntictoc::toc()\n\nrun time of 1 secs., use the cache.: 0 sec elapsed\n\n\nand the summary is\n\nprecis(fit04M07$quap_ctr)[, 1:2]\n\n             mean         sd\na     154.6013682 0.27030768\nb       0.9032808 0.04192363\nsigma   5.0718812 0.19115481\n\n\nThe fit using the predictor on the natural scale\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"1 secs.\"))\nfit04M07$quap_nat <- xfun::cache_rds({\n  quap(\n    flist = alist(\n      height ~ dnorm(mu, sigma),\n      mu <- a + b * weight,\n      a ~ dnorm(178, 20),\n      b ~ dlnorm(0, 1),\n      sigma ~ dunif(0, 50)\n      ),\n    data = data04M07,\n    start = list(a = mean(data04M07$weight), b = 0.5, sigma = 10)\n    )},\n  file = \"ch04_fit04M07_quap_nat\")\ntictoc::toc()\n\nrun time of 1 secs., use the cache.: 0.02 sec elapsed\n\nprecis(fit04M07$quap_nat)[, 1:2]\n\n             mean         sd\na     114.5173363 1.90120195\nb       0.8911311 0.04183397\nsigma   5.0821208 0.19213615\n\n\n\n\nCovariances\nThe parameter corr = TRUE does not seem to work in precis so we use the var-cov matrix and convert it to correlations.\n\nround(cov2cor(vcov(fit04M07$quap_ctr)), 4)\n\n           a       b   sigma\na     1.0000  0.0000  0.0012\nb     0.0000  1.0000 -0.0031\nsigma 0.0012 -0.0031  1.0000\n\n\n\nround(cov2cor(vcov(fit04M07$quap_nat)), 4)\n\n            a       b   sigma\na      1.0000 -0.9898  0.0251\nb     -0.9898  1.0000 -0.0249\nsigma  0.0251 -0.0249  1.0000\n\n\nComments:\n\nThe effect (\\(b\\)) and sigma are the same but the \\(a\\) (Intercepts) coefficients are different.\nThe correlations are strong on the natural scale and non-existent on the centered scale. This is an effect that is well documented with the correlation coefficient when distant data points from the origin are observed\nThe 2 models, on centered and natural scales give the same prediction.\n\n\n\nPosteriors\nGet the samples from the posteriors of the 2 models (centered and natural scales).\n\n# get the posterior samples for both models (centered and natural scale)\npost04M07 <- list()\npost04M07 <- within(post04M07, {\n  ndraws <- 500L\n  \n  # the model on centered scale\n  quap_ctr <- tidy_draws(fit04M07$quap_ctr, n = ndraws) |>\n    # .chain and .iteration are NA and will generate error\n    select(-.chain, -.iteration) |>\n    as_draws_df()\n  \n  # the model with on natural scale\n  quap_nat <- tidy_draws(fit04M07$quap_nat, n = ndraws) |>\n    select(-.chain, -.iteration) |>\n    as_draws_df()\n  \n  # bind the 2 dataframes together\n  quap_all <- bind_rows(\"ctr\" = quap_ctr, \"nat\" = quap_nat, .id =\"model\")\n  \n  # long format used for plotting\n  quap_all <- quap_all |>\n    group_by(model) |>\n    tidybayes::gather_variables()\n  })\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\nand plot them by variable\n\nggplot(post04M07$quap_all, aes(x = .value, color = model)) +\n  ggdist::stat_slabinterval(point_interval = mode_qi, fill = \"antiquewhite\") +\n  scale_color_paletteer_d(\"ggthemes::calc\") +\n  facet_grid(model ~ .variable, scales = \"free\") +\n  theme(legend.position = \"right\") +\n  labs(title = \"4M7: Posterior comparisons by model using quap\",\n       subtitle = sprintf(\"sample size = %d\", post04M07$ndraws),\n       x = NULL, y = NULL)\n\n\n\n\nConclusion: The main difference is with respect to the intercept which is different for uncentered and centered weight. The difference is not only in the location but also in the scale. The uncentered weight is less accurate as its variance is large compared to the centered weight.\n\n\nPredictions\n\n# the predictions for the centered model\npred04M07 <- list()\npred04M07 <- within(pred04M07, {\n  ndraws<- 500L\n  \n  quap_ctr <- data.frame(\n    weight_c = seq_range(data04M07$weight_c, n = 30L)) |>\n    add_predicted_draws(fit04M07$quap_ctr, ndraws = ndraws) |>\n    median_qi() |>\n    # put weight on natural scale to enable comparisons\n    mutate(weight = weight_c + mean(data04M07$weight))\n  \n  quap_nat <- data.frame(\n    weight = seq_range(data04M07$weight, n = 30L)) |>\n    add_predicted_draws(fit04M07$quap_nat, ndraws = ndraws) |>\n    median_qi()\n  \n  quap_all <- bind_rows(\"ctr\"= quap_ctr, \"nat\" = quap_nat, .id = \"model\")\n  })\n\nand the plot is\n\nggplot(pred04M07$quap_all, \n       aes(x = weight, y = .prediction, ymin = .lower, ymax = .upper,\n           color = model)) +\n  geom_pointinterval(position = position_dodge(width = 0.5),\n                     fatten_point = 2, size = 1) +\n  scale_color_paletteer_d(\"ggthemes::calc\") +\n  theme(legend.position = \"bottom\",\n        panel.grid.major.y = element_line()) +\n  labs(title = \"Centered vs Natural Predictions\",\n       subtitle = \"4M7 using quap\",\n       y = \"predicted height\")\n\n\n\n\n\n\n\nUsing brm\nWe will use brm only for the centered model since this is only to compare with quap and inla.\n\nFits\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"65 secs.\"))\nfit04M07$brm_ctr <- xfun::cache_rds({\n  brms::brm(\n  data = data04M07,\n  family = gaussian,\n  formula = height ~ 1 + weight_c,\n  prior = c(\n    prior(normal(178, 20), class = Intercept),\n    prior(lognormal(0, 1), class = b, lb = 0, ub = 3),\n    prior(exponential(1), class = sigma)),\n  iter = 2000, warmup = 1000, chains = 4, cores = detectCores(),  seed = 4)},\n  file = \"ch04_fit04M07_brm_ctr\")\ntictoc::toc()\n\nrun time of 65 secs., use the cache.: 0.14 sec elapsed\n\n\n\nsummary(fit04M07$brm_ctr)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: height ~ 1 + weight_c \n   Data: data04M07 (Number of observations: 352) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   154.60      0.26   154.09   155.10 1.00     4105     3063\nweight_c      0.90      0.04     0.82     0.99 1.00     4275     2896\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     5.06      0.19     4.71     5.46 1.00     4702     3170\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"60 secs.\"))\nfit04M07$brm_nat <- xfun::cache_rds({\n  brms::brm(\n  data = data04M07,\n  family = gaussian,\n  formula = height ~ 1 + weight,\n  prior = c(\n    prior(normal(178, 20), class = Intercept),\n    prior(lognormal(0, 1), class = b, lb = 0, ub = 3),\n    prior(exponential(1), class = sigma)),\n  iter = 2000, warmup = 1000, chains = 4, cores = detectCores(),  seed = 4)},\n  file = \"ch04_fit04M07_brm_nat\")\ntictoc::toc()\n\nrun time of 60 secs., use the cache.: 0.15 sec elapsed\n\n\n\nsummary(fit04M07$brm_nat)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: height ~ 1 + weight \n   Data: data04M07 (Number of observations: 352) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   113.95      1.87   110.20   117.53 1.00     5008     2918\nweight        0.90      0.04     0.83     0.98 1.00     4945     2977\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     5.07      0.20     4.71     5.48 1.00     4970     3100\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\nPosteriors\nWe extract the samples using tidybayes which gives the exact same commands as for rethinking::quap above.\n\npost04M07 <- within(post04M07, {\n  brm_ctr <- tidy_draws(fit04M07$brm_ctr, n = ndraws) |>\n    # .chain and .iteration are NA and will generate error\n    select(-.chain, -.iteration) |>\n    # mutate(model = 1) |>\n    as_draws_df() |>\n    # mutate_variables(model = 1) |>\n    identity()\n  \n  \n  brm_nat <- tidy_draws(fit04M07$brm_nat, n = ndraws) |>\n    select(-.chain, -.iteration) |>\n    # mutate(model = 2) |>\n    as_draws_df() |>\n    # mutate_variables(model = 2) |>\n    identity()\n  \n  # bind the 2 dataframes together\n  brm_all <- bind_rows(\"ctr\" = brm_ctr, \"nat\" = brm_nat, .id =\"model\")\n  \n  # long format used for plotting\n  brm_all_lng <- brm_all |>\n    group_by(model) |>\n    tidybayes::gather_variables() |>\n    mutate(.variable = if_else(.variable == \"b_weight_c\", \"b_weight\", .variable))\n  })\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\nand plot them by variable\n\npost04M07$brm_all_lng |>\n  filter(.variable %in% c(\"b_Intercept\", \"b_weight\")) |>\n  ggplot(aes(x = .value, color = model)) +\n  ggdist::stat_slabinterval(point_interval = mode_qi, fill = \"antiquewhite\") +\n  scale_color_paletteer_d(\"ggthemes::calc\") +\n  facet_grid(model ~ .variable, scales = \"free\") +\n  theme(legend.position = \"right\") +\n  labs(title = \"4M7: Posterior comparisons by model using brm\",\n       subtitle = sprintf(\"sample size = %d\", post04M07$ndraws),\n       x = NULL, y = NULL)\n\nWarning: Removed 4000 rows containing missing values (`stat_slabinterval()`).\nRemoved 4000 rows containing missing values (`stat_slabinterval()`).\n\n\n\n\n\n\n\nPredictions\nAnd, again, we can use the exact same command using tidybayes with brms as we used with rethinking.\n\n# the predictions for the centered model\npred04M07 <- within(pred04M07, {\n  brm_ctr <- data.frame(\n    weight_c = seq_range(data04M07$weight_c, n = 30L)) |>\n    add_predicted_draws(fit04M07$brm_ctr, ndraws = ndraws) |>\n    median_qi() |>\n    # put weight on natural scale to enable comparisons\n    mutate(weight = weight_c + mean(data04M07$weight))\n  \n  brm_nat <- data.frame(\n    weight = seq_range(data04M07$weight, n = 30L)) |>\n    add_predicted_draws(fit04M07$brm_nat, ndraws = ndraws) |>\n    median_qi()\n  \n  # put all intervals together\n  brm_all <- bind_rows(\"ctr\"= brm_ctr, \"nat\" = brm_nat, .id = \"model\")\n  })\n\nand the plot\n\nggplot(pred04M07$brm_all, \n       aes(x = weight, y = .prediction, ymin = .lower, ymax = .upper,\n           color = model)) +\n  geom_pointinterval(position = position_dodge(width = 0.5),\n                     fatten_point = 2, size = 1) +\n  scale_color_paletteer_d(\"ggthemes::calc\") +\n  theme(legend.position = \"bottom\",\n        panel.grid.major.y = element_line()) +\n  labs(title = \"Centered vs Natural Predictions\",\n       subtitle = \"4M7 using brm\")"
  },
  {
    "objectID": "ch04_linear.html#prac4M8",
    "href": "ch04_linear.html#prac4M8",
    "title": "4  Linear Models",
    "section": "4M8",
    "text": "4M8\nThe methodology used here comes from section 4.5 of Kurz (2020) to whom I am forever grateful for the wonderful books he gives us.\nWe remove the rows with NA in the doy variable.\n\ndata(\"cherry_blossoms\")\ndata04M08 <- cherry_blossoms |>\n  drop_na(doy)\nrm(cherry_blossoms)\nstopifnot(all.equal(dim(data04M08), c(827L, 5L)))\nskimr::skim(data04M08, year, doy, temp)\n\n\nData summary\n\n\nName\ndata04M08\n\n\nNumber of rows\n827\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1.00\n1548.84\n304.15\n812.00\n1325.00\n1583.00\n1803.50\n2015.0\n▂▅▆▇▇\n\n\ndoy\n0\n1.00\n104.54\n6.41\n86.00\n100.00\n105.00\n109.00\n124.0\n▁▅▇▅▁\n\n\ntemp\n40\n0.95\n6.10\n0.68\n4.69\n5.62\n6.06\n6.46\n8.3\n▃▇▇▂▁\n\n\n\n\n\n\nModel\n\\[\n\\begin{align*}\ndoy_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\sum_{k=1}^Kw_kB_{k, i} \\\\\n\\alpha &\\sim \\mathcal{N}(100, 10) \\\\\nw_j &\\sim \\mathcal{N}(0, 10) \\\\\n\\sigma &\\sim \\mathcal{Exp}(1)\n\\end{align*}\n\\]\n\n\nFunctions\nThis function will be used to create the B matrix. See R code 4.74 in section 4.5.2 of the textbook.\n\n# create the B (basis) matrix\nget_B <- function(x, knots, degree = 3L, intercept = TRUE) {\n  out <- splines::bs(x = x, \n                     knots = knots[-c(1, length(knots))], \n                     degree = degree, \n                     intercept = intercept)\n  stopifnot(all.equal(dim(out), c(length(x), length(knots) + degree - 1)))\n  out\n}\n\nA function to create the plot used in this practice\n\n# the basic plot used in 4M8\nplot_04M08 <- function(data, x_var = \"year\", y_var = \"doy\", color_var = \"temp\", \n                       knots = 15L, leg_pos = c(0.05, 0.8), \n                       colrs = \"grDevices::SunsetDark\",\n                       titles = list()) {\n  \n  ggplot(data, aes(x = .data[[x_var]], y = .data[[y_var]], \n                   color = .data[[color_var]])) +\n    geom_point(shape = 20, size = 2, alpha = 2/3) +\n    geom_vline(xintercept = knots, color = \"slateblue\", alpha = 1/2) +\n    scale_x_continuous(breaks = knots, labels = scales::label_number(big.mark = \"\")) +\n  scale_color_paletteer_c(colrs) +\n  theme(legend.position = leg_pos,\n        axis.text.x = element_text(size = rel(0.9))) +\n  labs(title = titles$title, subtitle = titles$subtitle)\n}\n\n\n\n4.0.1 a) Knots = 15, \\(w_j \\sim \\mathcal{N}(0, 10)\\)\nCreate the knots and bias function with degree 3 (cubic spline) and an intercept\n\nsplinA <- list()\nsplinA <- within(splinA, {\n  data <- data04M08\n  knots = quantile(data$year, \n                   probs = seq(from = 0, to = 1, length.out = 15L))\n  B <- get_B(x = data$year, knots = knots, degree = 3L, intercept = TRUE)\n  bias <- B |>\n    as.data.frame() |>\n    setNames(sprintf(\"B%02d\", seq_len(ncol(B)))) |>\n    mutate(year = data$year) |>\n    pivot_longer(cols = -year, names_to = \"bias_func\", values_to = \"bias\")\n  # the last column is a matrix column, with same nb of rows as the other\n  # columns but with a column including 17 subcolumns (!)\n  data <- data |>\n    mutate(B = B)\n})\n\n\nfit04M08 <- list()\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"60 secs.\"))\nfit04M08$splinA <- xfun::cache_rds({\n  brm(data = splinA$data,\n      family = gaussian,\n      doy ~ 1 + B,\n      prior = c(prior(normal(100, 10), class = Intercept),\n                prior(normal(0, 10), class = b),\n                prior(exponential(1), class = sigma)),\n      cores = detectCores(), seed = 4)},\n  file = \"ch04_fit04M08_splinA\")\ntictoc::toc()\n\nrun time of 60 secs., use the cache.: 0.19 sec elapsed\n\n\n\nsummary(fit04M08$splinA)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: doy ~ 1 + B \n   Data: splinA$data (Number of observations: 827) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   103.51      2.43    98.75   108.31 1.01      657     1083\nB1           -3.14      3.92   -10.74     4.61 1.00     1472     2103\nB2           -1.05      3.93    -8.78     6.66 1.00     1512     2289\nB3           -1.17      3.69    -8.35     6.08 1.00     1121     2198\nB4            4.66      2.94    -1.09    10.40 1.00      950     1799\nB5           -0.98      2.98    -6.65     5.04 1.01      860     1448\nB6            4.17      2.95    -1.68     9.87 1.00      946     1843\nB7           -5.47      2.87   -11.16     0.25 1.00      844     1264\nB8            7.68      2.88     2.15    13.32 1.01      864     1804\nB9           -1.16      2.92    -6.92     4.66 1.00      978     1688\nB10           2.84      2.98    -2.90     8.50 1.00      890     1897\nB11           4.51      2.94    -1.31    10.09 1.00      906     1686\nB12          -0.30      2.92    -5.97     5.41 1.01      910     1429\nB13           5.39      2.93    -0.44    11.13 1.01      883     1521\nB14           0.55      3.05    -5.41     6.42 1.00      938     1691\nB15          -0.97      3.31    -7.40     5.44 1.00     1079     1880\nB16          -7.13      3.43   -13.84    -0.39 1.00     1124     2086\nB17          -7.81      3.28   -14.32    -1.50 1.00     1151     1906\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     5.95      0.15     5.67     6.24 1.00     4602     2860\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n# get the fitted values (linpred)\nlpred04M08 <- list()\nlpred04M08 <- within(lpred04M08,{\n  data <- data04M08\n  A <- list()\n  A$newdata <- data.frame(\n    year = seq_range(data$year, n = 30)) |>\n    # NOTE: must use mutate() to add B matrix \"as is\"\n    mutate(B = get_B(x = year, knots = splinA$knots, \n                     degree = 3, intercept = TRUE))\n  \n  # linpred_draws is the same as fitted\n  A$intrvl <- linpred_draws(fit04M08$splinA, newdata = A$newdata) |>\n    as.data.frame() |>\n    select(-B) |>\n    group_by(year) |>\n    mean_qi()\n  })\n\n\n# plot the fitted values\nplot04M08 <- list()\ntitles <- list(\n  title = sprintf(\n    \"4M8 a): Cherry Blossom in Japan with %d knots\", length(splinA$knots)),\n  subtitle = sprintf(\"%d observations\", nrow(data04M08)))\nplot04M08$A <- plot_04M08(data04M08, knots = splinA$knots, titles = titles) +\n  labs(subtitle = \"4M8 a)\") +\n  geom_smooth(data = lpred04M08$A$intrvl, \n              mapping = aes(x = year, y = .linpred, ymin = .lower, ymax = .upper),\n              inherit.aes = FALSE,\n              color = \"blueviolet\", fill = \"cornflowerblue\", alpha = 1/2)\nplot04M08$A\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nb) Knots = 25, \\(w_j \\sim \\mathcal{N}(0, 10)\\)\nWe use the same process as in a) above but with different nb of knots\n\nsplinB <- list()\nsplinB <- within(splinB, {\n  data <- data04M08\n  knots = quantile(data$year, \n                   probs = seq(from = 0, to = 1, length.out = 25L))\n  B <- get_B(x = data$year, knots = knots, degree = 3L, intercept = TRUE)\n  bias <- B |>\n    as.data.frame() |>\n    setNames(sprintf(\"B%02d\", seq_len(ncol(B)))) |>\n    mutate(year = data$year) |>\n    pivot_longer(cols = -year, names_to = \"bias_func\", values_to = \"bias\")\n  # the last column is a matrix column, with same nb of rows as the other\n  # columns but with a column including 17 subcolumns (!)\n  data <- data |>\n    mutate(B = B)\n})\n\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"60 secs.\"))\nfit04M08$splinB <- xfun::cache_rds({\n  brm(data = splinB$data,\n      family = gaussian,\n      doy ~ 1 + B,\n      prior = c(prior(normal(100, 10), class = Intercept),\n                prior(normal(0, 10), class = b),\n                prior(exponential(1), class = sigma)),\n      cores = detectCores(), seed = 4)},\n  file = \"ch04_fit04M08_splinB\")\ntictoc::toc()\n\nrun time of 60 secs., use the cache.: 0.22 sec elapsed\n\n\n\nsummary(fit04M08$splinB)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: doy ~ 1 + B \n   Data: splinB$data (Number of observations: 827) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   103.99      1.96   100.34   107.91 1.00      725     1147\nB1           -4.78      4.01   -12.57     3.00 1.00     2348     2985\nB2            0.26      3.99    -7.20     8.23 1.00     2055     2872\nB3           -3.74      3.82   -11.41     3.72 1.00     1802     2720\nB4            2.09      3.04    -3.88     8.00 1.00     1345     2373\nB5            1.62      2.81    -4.03     7.12 1.00     1280     2006\nB6            4.21      2.73    -1.34     9.42 1.00     1150     1738\nB7           -4.63      2.98   -10.54     1.23 1.00     1400     2052\nB8            6.59      2.99     0.60    12.37 1.00     1424     2171\nB9           -1.94      2.94    -7.80     3.73 1.00     1346     2144\nB10          -2.87      2.75    -8.45     2.38 1.00     1280     2141\nB11           0.22      2.87    -5.31     5.65 1.00     1375     1936\nB12           0.55      2.77    -5.00     5.91 1.00     1280     2435\nB13           7.75      2.82     2.27    13.24 1.00     1342     2412\nB14          -2.80      2.95    -8.63     2.79 1.00     1252     2496\nB15           1.48      3.02    -4.46     7.26 1.00     1347     2332\nB16           1.64      2.94    -4.24     7.43 1.00     1373     2499\nB17           5.51      2.86     0.04    11.12 1.00     1295     2353\nB18          -0.20      2.88    -5.93     5.55 1.00     1385     2357\nB19           1.99      2.86    -3.50     7.49 1.00     1276     2086\nB20           0.97      2.85    -4.69     6.62 1.00     1400     2345\nB21           5.28      2.87    -0.24    11.00 1.00     1270     2274\nB22          -0.23      2.95    -6.11     5.37 1.00     1514     1735\nB23           1.62      2.94    -4.16     7.30 1.00     1240     2238\nB24          -2.51      3.07    -8.62     3.28 1.00     1375     2033\nB25          -5.17      3.37   -11.70     1.29 1.00     1584     2878\nB26          -7.72      3.58   -14.82    -0.77 1.00     1654     2481\nB27          -8.33      3.37   -14.97    -1.59 1.00     1889     2753\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     5.92      0.14     5.65     6.21 1.00     5965     2848\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n# get the fitted values (linpred)\nlpred04M08 <- within(lpred04M08,{\n  B <- list()\n  B$newdata <- data.frame(\n    year = seq_range(data$year, n = 30)) |>\n    # NOTE: must use mutate() to add B matrix \"as is\"\n    mutate(B = get_B(x = year, knots = splinB$knots, \n                     degree = 3L, intercept = TRUE))\n  \n  # linpred_draws is the same as fitted\n  B$intrvl <- linpred_draws(fit04M08$splinB, newdata = B$newdata) |>\n    as.data.frame() |>\n    select(-B) |>\n    group_by(year) |>\n    mean_qi()\n  })\n\n\n# plot the fitted values\ntitles <- list(\n  title = sprintf(\n    \"4M8 b): Cherry Blossom in Japan with %d knots\", length(splinB$knots)),\n  subtitle = sprintf(\"%d observations\", nrow(data04M08)))\nplot04M08$B <- plot_04M08(data04M08, knots = splinB$knots, titles = titles) +\n  geom_smooth(data = lpred04M08$B$intrvl, \n              mapping = aes(x = year, y = .linpred, ymin = .lower, ymax = .upper),\n              inherit.aes = FALSE,\n              color = \"blueviolet\", fill = \"cornflowerblue\", alpha = 1/2)\nplot04M08$B\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nc) Knots = 25, \\(w_j \\sim \\mathcal{N}(0, 20)\\)\n\nsplinC <- list()\nsplinC <- within(splinC, {\n  data <- data04M08\n  knots = quantile(data$year, \n                   probs = seq(from = 0, to = 1, length.out = 25L))\n  B <- get_B(x = data$year, knots = knots, degree = 3L, intercept = TRUE)\n  bias <- B |>\n    as.data.frame() |>\n    setNames(sprintf(\"B%02d\", seq_len(ncol(B)))) |>\n    mutate(year = data$year) |>\n    pivot_longer(cols = -year, names_to = \"bias_func\", values_to = \"bias\")\n  # the last column is a matrix column, with same nb of rows as the other\n  # columns but with a column including 17 subcolumns (!)\n  data <- data |>\n    mutate(B = B)\n})\n\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"60 secs.\"))\nfit04M08$splinC <- xfun::cache_rds({\n  brm(data = splinC$data,\n      family = gaussian,\n      doy ~ 1 + B,\n      prior = c(prior(normal(100, 10), class = Intercept),\n                prior(normal(0, 20), class = b),\n                prior(exponential(1), class = sigma)),\n      cores = detectCores(), seed = 4)},\n  file = \"ch04_fit04M08_splinC\")\ntictoc::toc()\n\nrun time of 60 secs., use the cache.: 0.23 sec elapsed\n\n\n\nsummary(fit04M08$splinC)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: doy ~ 1 + B \n   Data: splinC$data (Number of observations: 827) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   103.92      3.71    96.69   111.17 1.01      533      866\nB1           -5.41      5.19   -15.61     4.72 1.00      947     1662\nB2            1.07      5.40    -9.69    11.79 1.00      986     1554\nB3           -4.48      5.02   -14.41     5.44 1.00      851     1527\nB4            2.66      4.53    -6.08    11.35 1.00      741     1208\nB5            1.37      4.24    -7.06     9.67 1.00      685     1070\nB6            4.62      4.26    -3.59    12.92 1.00      657     1191\nB7           -4.94      4.32   -13.39     3.36 1.00      705     1261\nB8            7.10      4.45    -1.62    15.52 1.00      713     1308\nB9           -2.08      4.29   -10.52     6.24 1.00      713     1306\nB10          -2.84      4.26   -11.41     5.46 1.01      649     1279\nB11           0.41      4.26    -8.02     8.54 1.00      671     1044\nB12           0.45      4.27    -7.91     8.74 1.01      682     1281\nB13           8.09      4.23    -0.30    16.38 1.00      652     1062\nB14          -3.06      4.37   -11.48     5.49 1.00      726     1297\nB15           1.82      4.32    -6.71    10.44 1.00      698     1244\nB16           1.52      4.31    -6.91     9.76 1.01      699     1376\nB17           5.88      4.31    -2.59    14.15 1.00      684     1307\nB18          -0.39      4.31    -8.93     7.87 1.00      730     1251\nB19           2.27      4.31    -6.41    10.57 1.00      707     1353\nB20           0.87      4.30    -7.50     9.17 1.00      657     1265\nB21           5.52      4.32    -2.77    13.80 1.00      724     1200\nB22          -0.28      4.37    -8.81     8.22 1.00      653     1188\nB23           1.74      4.35    -6.73    10.41 1.00      769     1396\nB24          -2.47      4.55   -11.54     6.61 1.00      666     1358\nB25          -5.05      4.78   -14.07     4.40 1.00      920     1638\nB26          -7.75      5.07   -17.71     2.03 1.00      781     1403\nB27          -8.64      4.69   -17.64     0.49 1.00      838     1605\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     5.93      0.15     5.64     6.22 1.00     3494     2795\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n# get the fitted values (linpred)\nlpred04M08 <- within(lpred04M08,{\n  C <- list()\n  C$newdata <- data.frame(\n    year = seq_range(data$year, n = 30)) |>\n    # NOTE: must use mutate() to add B matrix \"as is\"\n    mutate(B = get_B(x = year, knots = splinC$knots, \n                     degree = 3L, intercept = TRUE))\n  \n  # linpred_draws is the same as fitted\n  C$intrvl <- linpred_draws(fit04M08$splinC, newdata = C$newdata) |>\n    as.data.frame() |>\n    select(-B) |>\n    group_by(year) |>\n    mean_qi()\n  })\n\n\n# plot the fitted values\ntitles <- list(\n  title = sprintf(\n    \"4M8 c): Cherry Blossom in Japan with %d knots and increased weight sd to 20\",\n    length(splinB$knots)),\n  subtitle = sprintf(\"%d observations\", nrow(data04M08)))\nplot04M08$C <- plot_04M08(data04M08, knots = splinC$knots, titles = titles) +\n  geom_smooth(data = lpred04M08$C$intrvl, \n              mapping = aes(x = year, y = .linpred, ymin = .lower, ymax = .upper),\n              inherit.aes = FALSE,\n              color = \"blueviolet\", fill = \"cornflowerblue\", alpha = 1/2)\nplot04M08$C\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nConclusion\n\nPlots\nThe increase of nb of knots increases the fits (i.e. nb of turns)\n\nplot04M08$A / plot04M08$B\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nand the increase in variability of the weight increase the range of the coefficient.\n\nplot04M08$B / plot04M08$C\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nHowever this is not visually obvious when looking at the scatter plot. See just below the coefficient comparisons which is more informative.\n\n\nSummaries\n\nsumm <- list()\nsumm$A <- data.frame(model = \"A\", fixef(fit04M08$splinA)) |>\n  tibble::rownames_to_column(var = \"variable\")\nsumm$B <- data.frame(model = \"B\", fixef(fit04M08$splinB)) |>\n  tibble::rownames_to_column(var = \"variable\")\nsumm$C <- data.frame(model = \"C\", fixef(fit04M08$splinC)) |>\n  tibble::rownames_to_column(var = \"variable\")\nsumm$data <- bind_rows(summ$A, summ$B, summ$C) |>\n  mutate(variable = factor(variable,\n                           levels = c(\"Intercept\", sprintf(\"B%d\", 1:27)),\n                           ordered = TRUE))\n\nggplot(summ$data[summ$data$variable != \"Intercept\", ], \n       aes(x = variable, y = Estimate, ymin = Q2.5, ymax = Q97.5, color = model)) +\n  geom_pointinterval(position = position_dodge(width = 1/2)) +\n  scale_color_paletteer_d(\"futurevisions::cancri\") +\n  theme(legend.position = \"bottom\",\n        legend.direction = \"horizontal\",\n        panel.grid.major.y = element_line(),\n        axis.text.x = element_text(size = rel(0.85))) +\n  labs(title = \"Comparing the models' coefficients (excludding intercept)\",\n       subtitle = \"4M8\",\n       x = NULL, y = NULL)\n\n\n\n\nWe can see that the model are similar expect that\n\nModel A has significantly lower B16 and B17 coefficients. They are nonetheless similar to the B26 and B27 coefficients of models B and C\nModel B and C have the same coefficient but model C which is the model with the increased prior variance for the weights has a wider confidence range for all coefficients\n\nTo better visualize, we could look at the models coefficient after aliging the knots with the year"
  },
  {
    "objectID": "ch04_linear.html#prac4H1",
    "href": "ch04_linear.html#prac4H1",
    "title": "4  Linear Models",
    "section": "4H1",
    "text": "4H1\n\nData and model\n\ndata(\"Howell1\")\ndata04H01 <- Howell1 |>\n  filter(age >= 18) |>\n  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE))\nrm(\"Howell1\")\nstopifnot(identical(dim(data04H01), c(352L, 5L)))\n\nand the model that will be used\n\\[\n\\begin{align*}\nheight_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot weight_i \\\\\n\\alpha &\\sim \\mathcal{N}(178, 20) \\\\\n\\beta &\\sim \\mathcal{LogNormal}(1, 0.5) \\\\\n\\sigma &\\sim \\mathcal{Exponential}(1)\n\\end{align*}\n\\]\nand get the fit with quap\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"1 secs.\"))\nfit04H01 <- xfun::cache_rds({\n  quap(\n    flist = alist(\n      height ~ dnorm(mu, sigma),\n      mu <- a + b * weight,\n      a ~ dnorm(178, 20),\n      b ~ dlnorm(1, 0.5),\n      sigma ~ dexp(1)),\n  data = data04H01,\n  start = list(a = mean(data04H01$height), b = 0.5, sigma = 0.5))},\n  file = \"ch04_fit04H01\")\ntictoc::toc()\n\nrun time of 1 secs., use the cache.: 0.01 sec elapsed\n\n\n\nsummary(fit04H01)\n\n             mean         sd        5.5%      94.5%\na     114.1524632 1.86961878 111.1644513 117.140475\nb       0.8992102 0.04113258   0.8334724   0.964948\nsigma   5.0364393 0.18784197   4.7362315   5.336647\n\n\nget the samples of posterior likelihood\n\npost04H01 <- extract.samples(fit04H01, n = 1000L)\n\n\n\nUsing rethinking::link()\nFind the predictions using the detailed method as described in overthinking box of section 4.4.3.4. The rethinking::link() function does that.\n\npred04H01 <- list()\npred04H01 <- within(pred04H01, {\n  # set the weights\n  weights <- c(46.95, 43.72, 64.78, 32.59, 54.63)\n  # name the weights\n  names(weights) <- paste0(\"ind\", seq_along(weights))\n  # create the newdata\n  newdata <- data.frame(\"weight\" = weights,\n                        row.names = names(weights))\n  \n  # simulate for each weight\n  sim <- sapply(X = newdata$weight, FUN = function(x) {\n    set.seed(173)  # for fun: balanced prime number\n    mu <- post04H01$a + post04H01$b * x\n    rnorm(n = length(mu), mean = mu, sd = post04H01$sigma)\n    })\n  \n  # get the confidence intervals for each weight\n  intrvl <- apply(X = sim, MARGIN = 2, FUN = ggdist::mean_hdi, .width = 0.89)\n  intrvl <- do.call(rbind, intrvl) |>\n    data.frame(row.names = names(weights))\n})\n\n\n\nUsing tidyverse\nThe tidyverse way will be used from hereon.\n\npred04H01 <- list()\npred04H01 <- within(pred04H01, {\n  weights <- c(46.95, 43.72, 64.78, 32.59, 54.63)\n  names(weights) <- paste0(\"ind\", seq_along(weights))\n  newdata <- data.frame(\"weight\" = weights,\n                        row.names = names(weights))\n  # get the simulated predictions\n  sim <- purrr::map_dfr(\n    .x = weights,\n    .f = function(x) {\n      set.seed(173)  # for fun: balanced prime number\n      mu <- post04H01$a + post04H01$b * x\n      y <- rnorm(n = length(mu), mean = mu, sd = post04H01$sigma)\n      data.frame(weight = x, height = y)},\n    .id = \"ind\")\n  \n  # the predictions intervals\n  intrvl <- sim |>\n    group_by(weight) |>\n    ggdist::mean_hdi(height, .width = 0.89) |>\n    mutate(individual = names(weights)[order(weights)]) |>\n    relocate(individual)\n})\n# glimpse(pred04H01$intr)"
  },
  {
    "objectID": "ch04_linear.html#prac4H2",
    "href": "ch04_linear.html#prac4H2",
    "title": "4  Linear Models",
    "section": "4H2",
    "text": "4H2\nLoad the data\n\ndata(\"Howell1\")\ndata04H02 <- Howell1 |>\n  filter(age < 18) |>\n  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE))\nrm(\"Howell1\")\n# there should be 192 rows\nstopifnot(identical(dim(data04H02), c(192L, 5L)))\nskimr::skim(data04H02)\n\n\nData summary\n\n\nName\ndata04H02\n\n\nNumber of rows\n192\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nheight\n0\n1\n108.32\n25.75\n53.98\n89.13\n111.12\n127.72\n158.12\n▃▆▇▇▅\n\n\nweight\n0\n1\n18.41\n8.94\n4.25\n11.71\n16.98\n23.42\n44.74\n▆▇▅▂▁\n\n\nage\n0\n1\n7.72\n5.37\n0.00\n3.00\n7.00\n12.00\n17.00\n▇▅▅▅▅\n\n\nmale\n0\n1\n0.48\n0.50\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▇\n\n\nweight_c\n0\n1\n0.00\n8.94\n-14.16\n-6.71\n-1.43\n5.00\n26.32\n▆▇▅▂▁\n\n\n\n\n\n\nModel\n\\[\n\\begin{align*}\nheight_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot weight_i \\\\\n\\alpha &\\sim \\mathcal{N}(80, 40) \\\\\n\\beta &\\sim \\mathcal{LogNormal}(1, 0.5) \\\\\n\\sigma &\\sim \\mathcal{Exp}(1)\n\\end{align*}\n\\]\n\n\n4H2 a) with quap\n\nNote on priors\n\nUsing sigma ~ dexp(rate = 1) which seems to work well with this model\na ~ dnorm(80, 40) is based on the average height of the kids\nb ~ dlnorm(1, 0.5) since we assume the growth rate is positive\n\nStart values\n\nusing start data helps very much for this model converge consistently\nfor \\(a\\) simply use the average height\nfor \\(b\\) we use 1 as it should be strictly positive and assuming kids grow faster than adults.\n\n\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"1 secs.\"))\nfit04H02 <- list()\nfit04H02$quap <- xfun::cache_rds({\n  quap(\n    flist = alist(\n        height ~ dnorm(mu, sigma),\n        mu <- a + b * weight,\n        a ~ dnorm(80, 40),\n        b ~ dlnorm(1, 0.5),\n        sigma ~ dexp(1)\n        ),\n    data = data04H02,\n    start = list(a = mean(data04H01$height), b = 1)\n    )},\n  file = \"ch04_fit04H02_quap\")\ntictoc::toc()\n\nrun time of 1 secs., use the cache.: 0.01 sec elapsed\n\n\n\npred04H02 <- list()\npred04H02$quap <- rethinking::precis(fit04H02$quap, prob = 0.89)\npred04H02$quap\n\n           mean         sd      5.5%     94.5%\na     58.292967 1.36635508 56.109268 60.476667\nb      2.716866 0.06678045  2.610138  2.823594\nsigma  8.261618 0.40864709  7.608521  8.914715\n\n\nfor 10 more units of weights the child should be taller by the following nb of cm\n\nwith(pred04H02, {\n  quap$mean[row.names(quap) == \"a\"] + 10 * quap$mean[row.names(quap) == \"b\"] \n  })\n\n[1] 85.46163\n\n\n\n\n4H2 b) with quap\n\nGet the fitted values with quap\nSee section 4.4.3.4 for more details.\n\nlpred04H02 <- list()\nlpred04H02 <- within(lpred04H02, {\n  ndraws <- 200L\n  weights <- modelr::seq_range(data04H02$weight, n = 30L)\n  newdata <- data.frame(weight = weights)\n  \n  quap <- list()\n  # See the overthinking box in section 4.4.3.4 to explain `rethinking::link()'\n  quap$draws <- rethinking::link(fit = fit04H02$quap, data = newdata, \n                                 n = ndraws)\n  # compute the confidence intervals\n  quap$intrvl <- apply(X = quap$draws, MARGIN = 2, FUN = function(x) {\n    c(\"mean\" = mean(x), rethinking::HPDI(x))\n    }) |>\n    t() |>\n    bind_cols(weight = weights) |>\n  as.data.frame() |>\n    relocate(weight)\n  })\n\nand the prediction intervals are obtained as described in section 4.4.3.5 using rethinking::sim()\n\npred04H02 <- list()\npred04H02 <- within(pred04H02, {\n  ndraws <- 200L\n  weights <- modelr::seq_range(data04H02$weight, n = 30L)\n  newdata <- data.frame(weight = weights)\n  \n  # the predicted samples\n  quap <- list()\n  quap$draws <- rethinking::sim(fit = fit04H02$quap,\n                          data = newdata,\n                          n = ndraws)\n  # the intervals\n  quap$intrvl <- apply(X = quap$draws, MARGIN = 2, \n        FUN = function(x) {\n          c(\"mean\" = mean(x), rethinking::HPDI(x))\n          }) |> \n    t() |>\n    bind_cols(weight = weights) |>\n    as.data.frame() |>\n    relocate(weight)\n})\n# pred04H02$quap$intrvl\n\n\nggplot(data = data04H02, aes(x = weight)) +\n  geom_ribbon(data = pred04H02$quap$intrvl,\n              aes(ymin = `|0.89`, ymax = `0.89|`),\n              fill = \"lightcyan\") +\n  geom_smooth(data = lpred04H02$quap$intrvl,\n              aes(y = mean, ymin = `|0.89`, ymax = `0.89|`),\n              stat = \"identity\",\n              fill = \"lightcyan3\", color = \"black\", alpha = 1, size = 1/2) +\n  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +\n  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +\n  scale_color_paletteer_c(\"pals::kovesi.linear_kryw_5_100_c67\") +\n  theme(legend.position = c(0.1, 0.8)) +\n  labs(title = \"quap fit - Practice 4H2\", x = \"weight\", y = \"height\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n4H2 a) with brm\nSame comments and conclusion as for quap above\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"1 secs.\"))\nfit04H02$brm <- xfun::cache_rds({\n  brms::brm(\n    data = data04H02,\n    formula = height ~ 1 + weight,\n    family = gaussian(),\n    prior = c(\n      prior(normal(100, 50), class = Intercept),\n      prior(lognormal(0, 2), class = b, lb = 0),\n      prior(cauchy(0, 1), class = sigma)),\n    iter = 2000, warmup = 1000, chains = 4,\n    cores = detectCores(), seed = 4)},\n  file = \"ch04_fit04H02_brm\")\ntictoc::toc()\n\nrun time of 1 secs., use the cache.: 0.22 sec elapsed\n\n\n\nbrms::fixef(fit04H02$brm)\n\n           Estimate Est.Error      Q2.5     Q97.5\nIntercept 58.265998 1.4125688 55.452497 61.073812\nweight     2.718329 0.0686844  2.584124  2.850573\n\n\n\n\n4H2 b) with brm\nThe fitted values\n\nlpred04H02 <- within(lpred04H02, {\n  brm <- list()\n  brm$draws <- linpred_draws(fit04H02$brm, newdata = newdata, ndraws = ndraws)\n  # compute the confidence intervals\n  brm$intrvl <- median_qi(brm$draws)\n  })\n# glimpse(lpred04H02$brm$intrvl)\n\nand the prediction intervals\n\npred04H02 <- within(pred04H02, {\n  brm <- list()\n  brm$draws <- predicted_draws(fit04H02$brm, newdata = newdata, \n                                 ndraws = ndraws)\n  # compute the confidence intervals\n  brm$intrvl <- median_qi(brm$draws)\n  })\n\nand we illustrate the results\n\nggplot(data = data04H02, aes(x = weight)) +\n  geom_ribbon(data = pred04H02$brm$intrvl,\n              aes(ymin = .lower, ymax = .upper),\n              fill = \"lightcyan\") +\n  geom_smooth(data = lpred04H02$brm$intrvl,\n              aes(y = .linpred, ymin = .lower, ymax = .upper),\n              stat = \"identity\",\n              fill = \"lightcyan3\", color = \"black\", alpha = 1, linewidth = 1/2) +\n  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +\n  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +\n  scale_color_paletteer_c(\"pals::kovesi.linear_kryw_5_100_c67\") +\n  theme(legend.position = c(0.1, 0.8)) +\n  labs(title = \"BRMS fit - Practice 4H2\", x = \"weight\", y = \"height\")\n\n\n\n\n\n\n4H2 c)\nThe data points seem to have a nonlinear relation with weight, visually. The relation could hypothetized to be quadratic. It could also be logarithmic."
  },
  {
    "objectID": "ch04_linear.html#prac4H3",
    "href": "ch04_linear.html#prac4H3",
    "title": "4  Linear Models",
    "section": "4H3",
    "text": "4H3\nThis is covered by section 4.5.1 polynomial regression but instead of polynomial we use a logarithmic relation.\nThe data is\n\ndata(\"Howell1\")\ndata04H03 <- Howell1 |>\n  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE),\n         weight_log = log(weight))\nrm(\"Howell1\")\nstopifnot(identical(dim(data04H03), c(544L, 6L)),\n          all(is.finite(data04H03$weight_log)))\nskimr::skim(data04H03)\n\n\nData summary\n\n\nName\ndata04H03\n\n\nNumber of rows\n544\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nheight\n0\n1\n138.26\n27.60\n53.98\n125.10\n148.59\n157.48\n179.07\n▁▂▂▇▇\n\n\nweight\n0\n1\n35.61\n14.72\n4.25\n22.01\n40.06\n47.21\n62.99\n▃▂▃▇▂\n\n\nage\n0\n1\n29.34\n20.75\n0.00\n12.00\n27.00\n43.00\n88.00\n▇▆▅▂▁\n\n\nmale\n0\n1\n0.47\n0.50\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▇\n\n\nweight_c\n0\n1\n0.00\n14.72\n-31.36\n-13.60\n4.45\n11.60\n27.38\n▃▂▃▇▂\n\n\nweight_log\n0\n1\n3.44\n0.58\n1.45\n3.09\n3.69\n3.85\n4.14\n▁▁▂▂▇\n\n\n\n\n\nThe model used is\n\\[\n\\begin{align*}\nheight_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\log{(\\beta)} \\cdot weight_i \\\\\n\\alpha &\\sim \\mathcal{N}(178, 20) \\\\\n\\beta &\\sim \\mathcal{N}(0, 10) \\\\\n\\sigma &\\sim \\mathcal{Exponential}(1)\n\\end{align*}\n\\]\n\n4H3 a) using quap\n\nImportant: We have to use dunif for sigma to make the quap converge. Otherwise the cov matrix is not positive definite.\n\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"1 secs.\"))\nfit04H03 <- list()\nfit04H03$quap <- xfun::cache_rds({\n  rethinking::quap(\n    flist = alist(\n        height ~ dnorm(mu, sigma),\n        mu <- a + b * log(weight),\n        a ~ dnorm(178, 20),\n        b ~ dnorm(0, 10),\n        sigma ~ dunif(0, 50)\n        ),\n    data = data04H03\n    )},\n  file = \"ch04_fit04H03_quap\")\ntictoc::toc()\n\nrun time of 1 secs., use the cache.: 0 sec elapsed\n\n\n\nprecis(fit04H03$quap, prob = 0.89)\n\n            mean        sd       5.5%      94.5%\na     -22.690446 1.3340597 -24.822531 -20.558361\nb      46.764545 0.3822489  46.153638  47.375453\nsigma   5.138479 0.1560052   4.889153   5.387805\n\n\nSince we use \\(\\log{weight}\\) than any change of \\(\\log{weight}\\) represents a percentage change of \\(weight\\), therefore \\(b\\) represents that, for every percentage increase of the weight, the height is increased by 46.76 of a percentage.\n\n\n4H3 b) using quap\nsame process as in 4H2 above where we sample the fitted and predicted values\n\nlpred04H03 <- list()\nlpred04H03 <- within(lpred04H03, {\n  ndraws <- 1000L\n  weights <- modelr::seq_range(data04H03$weight, n = 30L)\n  newdata <- data.frame(weight = weights)\n  \n  quap <- list()\n  # See the overthinking box in section 4.4.3.4 to explain `rethinking::link()'\n  quap$draws <- rethinking::link(fit = fit04H03$quap, data = newdata, \n                                 n = ndraws)\n  # compute the confidence intervals\n  quap$intrvl <- apply(X = quap$draws, MARGIN = 2, FUN = function(x) {\n    c(\"mean\" = mean(x), rethinking::HPDI(x))\n    }) |>\n    t() |>\n    bind_cols(weight = weights) |>\n  as.data.frame() |>\n    relocate(weight)\n  })\n# glimpse(lpred04H03$quap$intrvl)\n\nand the prediction intervals are obtained as described in section 4.4.3.5 using rethinking::sim()\n\npred04H03 <- list()\npred04H03 <- within(pred04H03, {\n  ndraws <- 1000L\n  weights <- modelr::seq_range(data04H03$weight, n = 30L)\n  newdata <- data.frame(weight = weights)\n  \n  # the predicted samples\n  quap <- list()\n  quap$draws <- rethinking::sim(fit = fit04H03$quap,\n                          data = newdata,\n                          n = ndraws)\n  # the intervals\n  quap$intrvl <- apply(X = quap$draws, MARGIN = 2, \n        FUN = function(x) {\n          c(\"mean\" = mean(x), rethinking::HPDI(x))\n          }) |> \n    t() |>\n    bind_cols(weight = weights) |>\n    as.data.frame() |>\n    relocate(weight)\n})\n# glimpse(pred04H03$quap$intrvl)\n\nand the plot is\n\nggplot(data = data04H03, aes(x = weight)) +\n  geom_ribbon(data = pred04H03$quap$intrvl,\n              aes(ymin = `|0.89`, ymax = `0.89|`),\n              fill = \"aquamarine1\") +\n  geom_smooth(data = lpred04H03$quap$intrvl,\n              aes(y = mean, ymin = `|0.89`, ymax = `0.89|`),\n              stat = \"identity\",\n              fill = \"aquamarine4\", color = \"black\", alpha = 1, linewidth = 1/2) +\n  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +\n  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +\n  scale_color_paletteer_c(\"pals::kovesi.linear_kry_5_98_c75\") +\n  theme(legend.position = c(0.1, 0.8)) +\n  labs(title = \"quap fit - Practice 4H3\", x = \"weight\", y = \"height\")\n\n\n\n\n\n\n4H3 a) using brm\nSame comments and conclusion as for quap above. The results are very similar.\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"60 secs.\"))\nfit04H03$brm <- xfun::cache_rds({\n  brms::brm(\n    data = data04H03,\n    formula = height ~ 1 + log(weight),\n    family = gaussian,\n    prior = \n      c(prior(normal(178, 20), class = Intercept),\n        prior(normal(0, 10), class = b),\n        prior(cauchy(0, 1), class = sigma)),\n    iter = 2000, warmup = 1000, chains = 4,\n    cores = detectCores(), seed = 4)},\n  file = \"ch04_fit04H03_brm\")\ntictoc::toc()\n\nrun time of 60 secs., use the cache.: 0.24 sec elapsed\n\n\n\nbrms::fixef(fit04H03$brm)\n\n           Estimate Est.Error      Q2.5     Q97.5\nIntercept -23.60134 1.3674185 -26.28827 -20.89767\nlogweight  47.02476 0.3920551  46.24847  47.79955\n\n\n\n\n4H3 b) using brm\nThe fitted values\n\nlpred04H03 <- within(lpred04H03, {\n  brm <- list()\n  brm$draws <- linpred_draws(fit04H03$brm, newdata = newdata, ndraws = ndraws)\n  # compute the confidence intervals\n  brm$intrvl <- median_qi(brm$draws)\n  })\n# glimpse(lpred04H03$brm$intrvl)\n\nand the prediction intervals\n\npred04H03 <- within(pred04H03, {\n  brm <- list()\n  brm$draws <- predicted_draws(fit04H03$brm, newdata = newdata, \n                                 ndraws = ndraws)\n  # compute the confidence intervals\n  brm$intrvl <- median_qi(brm$draws)\n  })\n\nand we illustrate the results which are similar to quap above.\n\nggplot(data = data04H03, aes(x = weight)) +\n  geom_ribbon(data = pred04H03$brm$intrvl,\n              aes(ymin = .lower, ymax = .upper),\n              fill = \"aquamarine1\") +\n  geom_smooth(data = lpred04H03$brm$intrvl,\n              aes(y = .linpred, ymin = .lower, ymax = .upper),\n              stat = \"identity\",\n              fill = \"aquamarine4\", color = \"black\", alpha = 1, linewidth = 1/2) +\n  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +\n  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +\n  scale_color_paletteer_c(\"pals::kovesi.linear_kry_5_98_c75\") +\n  theme(legend.position = c(0.1, 0.8)) +\n  labs(title = \"BRMS fit - Practice 4H3\", x = \"weight\", y = \"height\")"
  },
  {
    "objectID": "ch04_linear.html#prac4H4",
    "href": "ch04_linear.html#prac4H4",
    "title": "4  Linear Models",
    "section": "4H4",
    "text": "4H4\nSee section 4.5.1 for reference to this practice. R code 4.65 (p. 111)\nThe data is as in section 4.5.1. This practice is using techniques that are illustrated at the beginning of section 5.1 in the next chapter.\n\ndata(\"Howell1\")\ndata04H04 <- Howell1 |>\n  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE),\n         weight_c2 = weight_c ^ 2)\nstopifnot(identical(dim(data04H04), c(544L, 6L)))\nrm(\"Howell1\")\nskimr::skim(data04H04)\n\n\nData summary\n\n\nName\ndata04H04\n\n\nNumber of rows\n544\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nheight\n0\n1\n138.26\n27.60\n53.98\n125.10\n148.59\n157.48\n179.07\n▁▂▂▇▇\n\n\nweight\n0\n1\n35.61\n14.72\n4.25\n22.01\n40.06\n47.21\n62.99\n▃▂▃▇▂\n\n\nage\n0\n1\n29.34\n20.75\n0.00\n12.00\n27.00\n43.00\n88.00\n▇▆▅▂▁\n\n\nmale\n0\n1\n0.47\n0.50\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▇\n\n\nweight_c\n0\n1\n0.00\n14.72\n-31.36\n-13.60\n4.45\n11.60\n27.38\n▃▂▃▇▂\n\n\nweight_c2\n0\n1\n216.26\n223.23\n0.00\n40.12\n142.02\n325.73\n983.34\n▇▂▂▁▁\n\n\n\n\n\nthe model has been slightly modified by using the centered weight instead of the standard weight. It seems to work better with quap.\nThe values for \\(a\\) are from the summary using skimr just above.\n\\[\n\\begin{align*}\nh_i &\\sim \\mathcal{N}(\\mu_i, \\sigma)\\\\\n\\mu_i &= \\alpha + \\beta_1 \\cdot weight\\_c_i + \\beta_2 \\cdot weight\\_c^2_i \\\\\n\\alpha &\\sim \\mathcal{N}(138, 50) \\\\\n\\beta_1 &\\sim \\mathcal{LogNormal}(0,1) \\\\\n\\beta_2 &\\sim \\mathcal{N}(0,1) \\\\\n\\sigma &\\sim \\mathcal{Exp}(1)\n\\end{align*}\n\\]\n\n4H4 using quap\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"1 secs.\"))\nfit04H04 <- list()\nfit04H04$quap <- xfun::cache_rds({\n  rethinking::quap(\n    flist = alist(\n      height ~ dnorm(mu, sigma),\n      mu <- a + b1 * weight_c + b2 * weight_c2,\n      a ~ dnorm(138, 50),\n      b1 ~ dlnorm(0, 1),\n      b2 ~ dnorm(-0.25, 0.25),\n      sigma ~ exp(1)),\n  data = data04H04\n)},\n  file = \"ch04_fit04H04_quap\")\ntictoc::toc()\n\nrun time of 1 secs., use the cache.: 0.02 sec elapsed\n\n\n\nrethinking::precis(fit04H04$quap)\n\n           mean           sd         5.5%        94.5%\na  146.66120894 0.1767028875 146.37880360 146.94361428\nb1   1.45480677 0.0093146246   1.43992020   1.46969334\nb2  -0.03883204 0.0006141831  -0.03981362  -0.03785046\n\n\nThe function rethinking::extract.prior() is used to sample the prior distributions from the fit. Then the process of finding the mu’s is the same as the overthinking box of section 4.4.3.4 (p.107). See also practice 4H1 above for the method.\n\nprior04H04 <- list()\nprior04H04 <- within(prior04H04,{\n  ndraws <- 500L\n  quap <- list()\n  quap$draws <- extract.prior(fit04H04$quap, n = ndraws) |>\n    as.data.frame() |>\n    mutate(sigma = rexp(n = n(), rate = 1)) |>\n    identity()\n})\n# glimpse(prior04H04$quap$draws)\n\nand find the predictions using the detailed method as described in overthinking box of section 4.4.3.4. The rethinking::link() function does that. For an example, see at the beginning of section 5.1 in the next chapter, R code 5.4.\nFor this exercise, we will do it the long way. See practice 4H1 for an example on how to do this.\n\nprior04H04 <- within(prior04H04, {\n  newdata <- data.frame(\n    weight_c = modelr::seq_range(data04H04$weight_c, n = 30L)) |>\n    mutate(weight_c2 = weight_c^2)\n  \n  # simulate for each weight predictor using the draws\n  quap$sim <- purrr::map_dfr(\n    .x = newdata$weight_c,\n    .f = function(x) {\n      mu <- quap$draws$a + quap$draws$b1 * x + quap$draws$b2 * x^2\n      y = rnorm(n = length(mu), mean = mu, sd = quap$draws$sigma)\n      data.frame(weight_c = x, height = y)\n    })\n  \n  quap$intrvl <- quap$sim |>\n    group_by(weight_c) |>\n    ggdist::mean_hdi(height, .width = 0.89)\n})\n# prior04H04$quap$intrvl\n\n\nggplot(data = data04H04, aes(x = weight_c)) +\n  geom_line(data = prior04H04$quap$intrvl, aes(y = height), linewidth = 1, color = \"purple\") +\n  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +\n  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +\n  scale_color_paletteer_c(\"pals::kovesi.rainbow_bgyrm_35_85_c71\") +\n  theme(legend.position = c(0.85, 0.30)) +\n  labs(title = \"quap fit with PRIOR - Practice 4H4\", x = \"weight\", y = \"height\")\n\n\n\n\nwhich shows that the prior is not so bad, it’s shape aligns with the data, only the intercept actually need to be modified.\n\nConclusion: It’s a very good idea to simulate the priors. It tells us if they make sense. It helps greatly in having a converging fit.\n\n\n\n4H4 using brm\nNote the use of sample_prior = TRUE to be able to obtain the prior samples. We use the prior \\(b1 \\sim \\mathcal{N}(0,1)\\) instead of \\(\\mathcal{LogNormal}\\) which gives a much better prior in this case.\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"60 secs.\"))\nfit04H04$brm <- xfun::cache_rds({\n  brms::brm(data = data04H04,\n                   formula = height ~ 1 + weight_c + weight_c2,\n                   family = gaussian,\n                   prior =\n                     c(prior(normal(138, 50), class = Intercept),\n                       prior(normal(0, 1), class = b, coef = \"weight_c\"),\n                       prior(normal(-0.25, 0.25), class = b, coef = \"weight_c2\"),\n                       prior(cauchy(0, 1), class = sigma)),\n                   iter = 2000, warmup = 1000, chains = 4,\n                   sample_prior = TRUE,\n                   cores = detectCores(), seed = 4)},\n  file = \"ch04_fit04H04_brm\")\ntictoc::toc()\n\nrun time of 60 secs., use the cache.: 0.28 sec elapsed\n\n\n\nprior04H04 <- within(prior04H04,{\n  brm <- list()\n  brm$draws <- brms::prior_draws(fit04H04$brm)\n  })\n# glimpse(prior04H04$brm$draws)\n\n\nprior04H04 <- within(prior04H04, {\n  # simulate for each weight predictor using the draws\n  brm$sim <- purrr::map_dfr(\n    .x = newdata$weight_c,\n    .f = function(x) {\n      mu <- brm$draws$Intercept + brm$draws$b_weight_c * x + \n        brm$draws$b_weight_c2 * x^2\n      y = rnorm(n = length(mu), mean = mu, sd = brm$draws$sigma)\n      data.frame(weight_c = x, height = y)\n    })\n  \n  brm$intrvl <- brm$sim |>\n    group_by(weight_c) |>\n    ggdist::mean_hdi(height, .width = 0.89)\n})\n# glimpse(prior04H04$brm$intrvl)\n\n\nggplot(data = data04H04, aes(x = weight_c)) +\n  geom_line(data = prior04H04$brm$intrvl, aes(y = height), linewidth = 1, color = \"purple\") +\n  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +\n  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +\n  scale_color_paletteer_c(\"pals::kovesi.rainbow_bgyrm_35_85_c71\") +\n  theme(legend.position = c(0.85, 0.30)) +\n  labs(title = \"brm fit with PRIOR - Practice 4H4\", x = \"weight\", y = \"height\")"
  },
  {
    "objectID": "ch04_linear.html#prac4H5",
    "href": "ch04_linear.html#prac4H5",
    "title": "4  Linear Models",
    "section": "4H5",
    "text": "4H5\n\n4.0.2 The data\n\ndata(\"cherry_blossoms\")\ndata04H05 <- cherry_blossoms |>\n  drop_na()\nrm(cherry_blossoms)\nskimr::skim(data04H05)\n\n\nData summary\n\n\nName\ndata04H05\n\n\nNumber of rows\n787\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n1533.40\n291.12\n851.00\n1318.00\n1563.00\n1778.50\n1980.00\n▂▅▆▇▇\n\n\ndoy\n0\n1\n104.92\n6.26\n86.00\n101.00\n105.00\n109.00\n124.00\n▁▅▇▅▁\n\n\ntemp\n0\n1\n6.10\n0.68\n4.69\n5.62\n6.06\n6.46\n8.30\n▃▇▇▂▁\n\n\ntemp_upper\n0\n1\n6.94\n0.81\n5.45\n6.38\n6.80\n7.38\n12.10\n▇▇▂▁▁\n\n\ntemp_lower\n0\n1\n5.26\n0.76\n2.61\n4.77\n5.25\n5.65\n7.74\n▁▃▇▂▁\n\n\n\n\n\n\n\n4.0.3 The model\nThere does not seem to be an obvious relations in the data. We will therefore use cubic splines again.\n\\[\n\\begin{align*}\ndoy_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\sum_{k=1}^Kw_kB_{k, i} \\\\\n\\alpha &\\sim \\mathcal{N}(100, 10) \\\\\nw_j &\\sim \\mathcal{N}(0, 10) \\\\\n\\sigma &\\sim \\mathcal{Exp}(1)\n\\end{align*}\n\\]\n\n\nFunctions used\nA function to create the plot\n\n# the basis plot used in 4M8\nplot_4H5 <- function(data, x_var = \"temp\", y_var = \"doy\", color_var = \"year\", \n                     knots, colrs = \"pals::isol\", titles = list()) {\n  ggplot(data, aes(x = .data[[x_var]], y = .data[[y_var]], \n                   color = .data[[color_var]])) +\n    geom_point(shape = 20, size = 2, alpha = 2/3) +\n    geom_vline(xintercept = knots, color = \"slateblue\", alpha = 1/2) +\n    scale_x_continuous(breaks = knots,\n                       labels = scales::label_number(accuracy = 0.1)) +\n  scale_color_paletteer_c(colrs) +\n  theme(legend.position = c(0.90, 0.85),\n        axis.text.x = element_text(size = rel(0.9))) +\n  labs(title = titles$title, subtitle = titles$subtitle)\n}\n\n\n\nThe splines\n\n# the data for the spline\nsplin <- list()\nsplin <- within(splin, {\n  knots = quantile(data04H05$temp, \n                   probs = seq(from = 0, to = 1, length.out = 12))\n  B <- get_B(x = data04H05$temp, knots = knots, degree = 3L, intercept = TRUE)\n  data <- data04H05 |>\n    mutate(B = B)\n})\n\n\n\nWith quap\nSee code example in R code 4.76, 4.77 and 4.78 in section4.5.2\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"1 secs.\"))\nfit04H05 <- list()\nfit04H05$quap <- xfun::cache_rds({\n  rethinking::quap(\n  alist(\n    D ~ dnorm(mu, sigma),\n    mu <- a + B %*% w,\n    a ~ dnorm(100, 10),\n    w ~ dnorm(0, 10),\n    sigma ~ dexp(1)),\n  data=list(D=data04H05$doy, B=splin$B),\n  start=list(w=rep(0,ncol(splin$B)))\n  )},\n  file = \"ch04_fit04H05_quap\")\ntictoc::toc()\n\nrun time of 1 secs., use the cache.: 0.01 sec elapsed\n\n\nand the fitted values with their interval\n\nlpred04H05 <- list()\nlpred04H05 <- within(lpred04H05, {\n  ndraws <- 500L\n  \n  quap <- list()\n  # See the overthinking box in section 4.4.3.4 to explain `rethinking::link()'\n  quap$draws <- rethinking::link(fit04H05$quap, n = ndraws) |>\n    as.data.frame() |>\n    pivot_longer(cols = everything(), names_to = \"temp\", values_to = \"doy\") |>\n    mutate(temp = rep(data04H05$temp, times = ndraws))\n  # compute the confidence intervals\n  quap$intrvl <- quap$draws |>\n    group_by(temp) |>\n    ggdist::mean_qi(.width = 0.95)\n  })\n# glimpse(lpred04H05$quap$draws)\n# glimpse(lpred04H05$quap$intrvl)\n\n\ntitles <- list(\n  title = sprintf(\"Cherry Blossom in Japan with %d knots with quap\", length(splin$knots)),\n  subtitle = sprintf(\"%d observations\", nrow(data04H05)))\nplot_4H5(data04H05, knots = splin$knots, titles= titles) +\n  geom_smooth(data = lpred04H05$quap$intrvl,\n              mapping = aes(x = temp, y = doy, ymin = .lower, ymax = .upper),\n              inherit.aes = FALSE,\n              stat = \"identity\", color = \"darksalmon\", fill = \"sandybrown\")\n\n\n\n\n\n\nWith brm\n\nglimpse(splin$data)\n\nRows: 787\nColumns: 6\n$ year       <int> 851, 864, 866, 889, 891, 892, 894, 895, 896, 902, 908, 912,…\n$ doy        <int> 108, 100, 106, 104, 109, 108, 106, 104, 104, 102, 98, 95, 1…\n$ temp       <dbl> 7.38, 6.42, 6.44, 6.83, 6.98, 7.11, 6.98, 7.08, 7.20, 7.50,…\n$ temp_upper <dbl> 12.10, 8.69, 8.11, 8.48, 8.96, 9.11, 8.40, 8.57, 8.69, 8.95…\n$ temp_lower <dbl> 2.66, 4.14, 4.77, 5.19, 5.00, 5.11, 5.55, 5.58, 5.72, 6.06,…\n$ B          <bs[,14]> <bs[26 x 14]>\n\n\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"60 secs.\"))\nfit04H05$brm <- xfun::cache_rds({\n  brms::brm(data = splin$data,\n      family = gaussian,\n      doy ~ 1 + B,\n      prior = c(prior(normal(100, 10), class = Intercept),\n                prior(normal(0, 10), class = b),\n                prior(exponential(1), class = sigma)),\n      cores = detectCores(), seed = 4)},\n  file = \"ch04_fit04H05_brm\")\ntictoc::toc()\n\nrun time of 60 secs., use the cache.: 0.31 sec elapsed\n\n\n\nlpred04H05 <- within(lpred04H05, {\n  \n  newdata <- data.frame(\n    temp = seq_range(data04H05$temp, n = 30)) |>\n    # NOTE: must use mutate() to add B matrix \"as is\"\n    mutate(B = get_B(x = temp, knots = splin$knots,\n                     degree = 3, intercept = TRUE))\n\n  brm <- list()\n  # linpred_draws is the same as fitted()\n  brm$intrvl <- linpred_draws(fit04H05$brm, newdata = newdata) |>\n    as.data.frame() |>\n    select(-B) |>\n    group_by(temp) |>\n    mean_qi()\n  })\n# glimpse(lpred04H05$brm$draws)\n# glimpse(lpred04H05$brm$intrvl)\n\nand plot the results\n\ntitles <- list(\n  title = sprintf(\"Cherry Blossom in Japan with %d knots with brm\", length(splin$knots)),\n  subtitle = sprintf(\"%d observations\", nrow(data04H05)))\nplot_4H5(data04H05, knots = splin$knots, titles = titles) +\n  geom_smooth(data = lpred04H05$brm$intrvl,\n              mapping = aes(x = temp, y = .linpred, ymin = .lower, ymax = .upper),\n              inherit.aes = FALSE,\n              stat = \"identity\", color = \"darksalmon\", fill = \"sandybrown\")"
  },
  {
    "objectID": "ch04_linear.html#prac4H6",
    "href": "ch04_linear.html#prac4H6",
    "title": "4  Linear Models",
    "section": "4H6",
    "text": "4H6\nSee 4.5.2 on splines for a discussion on the spline matrix. The following simulation is inspired by that section.\nThe dimensions f the B matrix are explained in section 4.5.2, on p. 117, between R code 4.74 and R code 4.75.\n\nData\n\ndata(\"cherry_blossoms\")\ndata04H06 <- cherry_blossoms |>\n  drop_na()\nskimr::skim(data04H06)\n\n\nData summary\n\n\nName\ndata04H06\n\n\nNumber of rows\n787\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n1533.40\n291.12\n851.00\n1318.00\n1563.00\n1778.50\n1980.00\n▂▅▆▇▇\n\n\ndoy\n0\n1\n104.92\n6.26\n86.00\n101.00\n105.00\n109.00\n124.00\n▁▅▇▅▁\n\n\ntemp\n0\n1\n6.10\n0.68\n4.69\n5.62\n6.06\n6.46\n8.30\n▃▇▇▂▁\n\n\ntemp_upper\n0\n1\n6.94\n0.81\n5.45\n6.38\n6.80\n7.38\n12.10\n▇▇▂▁▁\n\n\ntemp_lower\n0\n1\n5.26\n0.76\n2.61\n4.77\n5.25\n5.65\n7.74\n▁▃▇▂▁\n\n\n\n\n\n\n\nModel\n\\[\n\\begin{align*}\ndoy_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\sum_{k=1}^Kw_kB_{k, i} \\\\\n\\alpha &\\sim \\mathcal{N}(100, 10) \\\\\nw_j &\\sim \\mathcal{N}(0, 10) \\\\\n\\sigma &\\sim \\mathcal{Exp}(1)\n\\end{align*}\n\\]\n\n\nFunctions\nWe need to create functions to simulate the prior and plotting.\nThe functions used for the simulation\n\n# simulate the prior using the B matrix\nsim_prior_gam <- function(B, n = 1000L,\n                          alpha_prior = list(mean = 0, sd = 10),\n                          weight_prior = list(mean = 0, sd = 10),\n                          sigma_prior = list(rate = 1)) {\n  \n  out <- sapply(X=seq_len(nrow(B)), FUN = function(i) {\n    # get a sample of intercept\n    intercept <- rnorm(n=1, alpha_prior$mean, sd=alpha_prior$sd)\n    # get the sample of coefficients, one for each coefficient\n    weights <- sapply(X = seq_len(ncol(B)), FUN = function(j) {\n      rnorm(n=1, mean=weight_prior$mean, sd=weight_prior$sd)\n      })\n    # multiply the weights by the B matrix for that specific observation\n    # to get the mu\n    mu <- intercept + B[i, ] %*% weights\n    # sample sigma\n    sigma <- rexp(n = 1, rate = sigma_prior$rate)\n    # sample the predictions with mu and sigma\n    rnorm(n=n, mean=mu, sd=sigma)\n  })\n  stopifnot(all.equal(dim(out), c(n, nrow(B))))\n  out\n}\n\n\n\nPrior distribution simulation\nThe simulation with weight prior \\(sd = 10\\)\n\n# the list used to hold sim data and variables\nsim04H06 <- list()\nsim04H06 <- within(sim04H06, {\n  n <- 1000L\n  # the knots used\n  knots <- quantile(data04H06$temp, probs = seq(from = 0, to = 1, length.out = 12))\n  # the predictors used\n  preds <- seq_range(data04H06$temp, n = 20L)\n  B <- get_B(x=preds, knots=knots, degree = 3L, intercept = TRUE)\n  data <- sim_prior_gam(B=B, n = n,\n                          alpha_prior = list(mean = 100, sd = 10),\n                          weight_prior = list(mean = 0, sd = 10),\n                          sigma_prior = list(rate = 1))\n  })\n\n\nsim04H06 <- within(sim04H06, {\n  # put data in log format for use with stat_lineribbon\n  data_lng <- data |>\n    as.data.frame() |>\n    pivot_longer(cols = everything(), names_to = \"temp\", values_to = \"doy\") |>\n    mutate(temp = rep(preds, times = n))\n  \n  # create dataframe of intervals for use with geom_smooth\n  intrvl <- data_lng |>\n    group_by(temp) |>\n    ggdist::mean_qi()\n})\n\nand plot the results\n\nplot04H06 <- list()\nplot04H06$A <- ggplot(data=data04H06,mapping=aes(x = temp, y = doy, color = year)) +\n  geom_vline(xintercept = sim04H06$knots, color = \"slateblue\", alpha = 1/2) +\n  geom_smooth(data=sim04H06$intrvl, inherit.aes = FALSE,\n              mapping=aes(x = temp, y = doy, ymin = .lower, ymax = .upper),\n              stat = \"identity\", linewidth = 1, color = \"royalblue\", fill = \"lightskyblue\") +\n  geom_point(size = 1) +\n  scale_x_continuous(breaks = sim04H06$knots, labels = scales::label_number(accuracy = 0.1)) +\n  scale_y_continuous(breaks = scales::breaks_extended(n = 5), \n                     labels = scales::label_number(accuracy = 1),\n                     limits = c(30, 150)) +\n  scale_fill_paletteer_d(\"ggsci::amber_material\") +\n  scale_color_paletteer_c(\"pals::isol\") +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(size = rel(0.9))) +\n  labs(title = sprintf(\"Cherry Blossoms: Prior distribution with %d knots\", length(sim04H06$knots)),\n       subtitle = \"with weights' sd = 10\")\nplot04H06$A\n\n\n\n\nThe simulation with weight prior \\(sd = 20\\)\n\n# the list used to hold sim data and variables\nsim04H06 <- list()\nsim04H06 <- within(sim04H06, {\n  n <- 1000L\n  # the knots used\n  knots <- quantile(data04H06$temp, probs = seq(from = 0, to = 1, length.out = 12))\n  # the predictors used\n  preds <- seq_range(data04H06$temp, n = 20L)\n  B <- get_B(x=preds, knots=knots, degree = 3L, intercept = TRUE)\n  data <- sim_prior_gam(B=B, n = n,\n                          alpha_prior = list(mean = 100, sd = 10),\n                          weight_prior = list(mean = 0, sd = 20),\n                          sigma_prior = list(rate = 1))\n  })\n\n\nsim04H06 <- within(sim04H06, {\n  # put data in log format for use with stat_lineribbon\n  data_lng <- data |>\n    as.data.frame() |>\n    pivot_longer(cols = everything(), names_to = \"temp\", values_to = \"doy\") |>\n    mutate(temp = rep(preds, times = n))\n  \n  # create dataframe of intervals for use with geom_smooth\n  intrvl <- data_lng |>\n    group_by(temp) |>\n    ggdist::mean_qi()\n})\n\nand plot the results\n\nplot04H06$B <- ggplot(data=data04H06,mapping=aes(x = temp, y = doy, color = year)) +\n  geom_vline(xintercept = sim04H06$knots, color = \"slateblue\", alpha = 1/2) +\n  geom_smooth(data=sim04H06$intrvl, inherit.aes = FALSE,\n              mapping=aes(x = temp, y = doy, ymin = .lower, ymax = .upper),\n              stat = \"identity\", linewidth = 1, color = \"royalblue\", fill = \"lightskyblue\") +\n  geom_point(size = 1) +\n  scale_x_continuous(breaks = sim04H06$knots, labels = scales::label_number(accuracy = 0.1)) +\n  scale_y_continuous(breaks = scales::breaks_extended(n = 5), \n                     labels = scales::label_number(accuracy = 1),\n                     limits = c(30, 150)) +\n  scale_fill_paletteer_d(\"ggsci::amber_material\") +\n  scale_color_paletteer_c(\"pals::isol\") +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(size = rel(0.9))) +\n  labs(title = sprintf(\"Cherry Blossoms: Prior distribution with %d knots\", length(sim04H06$knots)),\n       subtitle = \"with weights' sd = 20\")\nplot04H06$B\n\n\n\n\nand comparing the 2 plots\n\nplot04H06$A / plot04H06$B\n\n\n\n\nConclusion: The prior affect the weights in the same manner as the priors affects regression coefficients. In the current example, by increasing the sd of the normally distributed prior we affect the variability of the weights."
  },
  {
    "objectID": "ch04_linear.html#prac4H7",
    "href": "ch04_linear.html#prac4H7",
    "title": "4  Linear Models",
    "section": "4H7",
    "text": "4H7\n\n\nPractice 4H7 is missing in the second edition!"
  },
  {
    "objectID": "ch04_linear.html#prac4H8",
    "href": "ch04_linear.html#prac4H8",
    "title": "4  Linear Models",
    "section": "4H8",
    "text": "4H8\nTo answer the question about what needs to be done to make the model without intercept work, here is the suggested answer\n\nUse argument intercept = FALSE in spline::bs()\nChange the formula to doy ~ 0 + B from doy ~ 1 + B\nRemove the prior prior(normal(100, 10), class = Intercept)\n\n\ndata(\"cherry_blossoms\")\ndata04H08 <- cherry_blossoms |>\n  drop_na(doy)\nrm(cherry_blossoms)\nstopifnot(identical(dim(data04H08), c(827L, 5L)))\nskimr::skim(data04H08)\n\n\nData summary\n\n\nName\ndata04H08\n\n\nNumber of rows\n827\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1.00\n1548.84\n304.15\n812.00\n1325.00\n1583.00\n1803.50\n2015.00\n▂▅▆▇▇\n\n\ndoy\n0\n1.00\n104.54\n6.41\n86.00\n100.00\n105.00\n109.00\n124.00\n▁▅▇▅▁\n\n\ntemp\n40\n0.95\n6.10\n0.68\n4.69\n5.62\n6.06\n6.46\n8.30\n▃▇▇▂▁\n\n\ntemp_upper\n40\n0.95\n6.94\n0.81\n5.45\n6.38\n6.80\n7.38\n12.10\n▇▇▂▁▁\n\n\ntemp_lower\n40\n0.95\n5.26\n0.76\n2.61\n4.77\n5.25\n5.65\n7.74\n▁▃▇▂▁\n\n\n\n\n\nDefine the knots\n\nknots <- quantile(data04H08$year, probs = seq(from = 0, to = 1, length.out = 15))\nknots\n\n       0% 7.142857% 14.28571% 21.42857% 28.57143% 35.71429% 42.85714%       50% \n      812      1036      1174      1269      1377      1454      1518      1583 \n57.14286% 64.28571% 71.42857% 78.57143% 85.71429% 92.85714%      100% \n     1650      1714      1774      1833      1893      1956      2015 \n\n\nthe code knots[-c(1, nknots)] is required because bs places knots at the boundaries by default, so we have to remove them.\n\nImportant: Since we don’t have an intercept, we set the parameter intercept = FALSE in spline::bs().\n\n\nB <- splines::bs(x = data04H08$year, \n                 knots = knots, \n                 degree = 3, intercept = FALSE)\n# str(B)\n\nWe first append the matrix to the data in one column. See Kurz (2020) on this data structure. We need to use mutate to keep the matrix as is.\n\ndata04H08 <- data04H08 |>\n  mutate(B = B)\n\nand we fit without the intercept\n\ntictoc::tic(msg = sprintf(\"run time of %s, use the cache.\", \"60 secs.\"))\nfit04H08 <- xfun::cache_rds({\n  brm(data = data04H08,\n      formula = doy ~ 0 + B,\n      family = gaussian,\n      prior = c(prior(normal(0, 10), class = b),\n                prior(exponential(1), class = sigma)),\n      cores = detectCores(), seed = 4)},\n  file = \"ch04_fit04H08\")\ntictoc::toc()\n\nrun time of 60 secs., use the cache.: 0.14 sec elapsed\n\n\nget the fitted value (linear prediction in tidybayes)\n\nlpred04H08 <- list()\nlpred04H08 <- within(lpred04H08, {\n  newdata <- data04H08\n  draws <- linpred_draws(fit04H08, newdata = newdata)\n  intrvl <- draws |>\n    ungroup() |>\n    select(-B) |>\n    group_by(year) |>\n    mean_qi(.linpred)\n  })\n\n\nclrs <- unclass(paletteer::paletteer_d(\"futurevisions::cancri\"))\nggplot(lpred04H08$intrvl, aes(x = year, y = .linpred)) +\n  geom_vline(xintercept = knots, color = \"slateblue\", alpha = 1/2) +\n  geom_point(data04H08, mapping = aes(x = year, y = doy, color = temp),\n             inherit.aes = FALSE) +\n  geom_lineribbon(aes(x = year, y = .linpred, ymin = .lower, ymax = .upper),\n                  color = \"blueviolet\", fill = \"cornflowerblue\", alpha = 1/2) +\n  scale_x_continuous(breaks = knots, labels = scales::label_number(big.mark = \"\")) +\n  scale_color_gradientn(colors = clrs) +\n  theme(legend.position = \"none\") +\n  labs(title = \"4H8: Cheery Blossom Spline Without Intercept\",\n       subtitle = sprintf(\"%d observations.\", nrow(data04H08)),\n       x = \"year\", y = \"doy\")\n\nWarning: Using the `size` aesthietic with geom_ribbon was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\nWarning: Unknown or uninitialised column: `linewidth`.\n\n\nWarning: Using the `size` aesthietic with geom_line was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\n\n\n\n\n\n\n\nGomez-Rubio, Virgilio. 2020. Bayesian Inference with INLA. 1st ed. Boca Raton, Florida: Chapman; Hall/CRC. http://www.taylorandfrancis.com.\n\n\nKurz, Solomon. 2019. Statistical Rethinking with Brms. 1st ed. https://bookdown.org/content/3890/.\n\n\n———. 2020. Statistical Rethinking with Brms. 2nd ed. https://bookdown.org/content/4857/.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://www.taylorandfrancis.com.\n\n\nXiaofeng Wang, Julian J. Faraway, Yu Ryan Yue. 2018. Bayesian Regression Modeling with INLA. 1st ed. Boca Raton, Florida: Chapman; Hall/CRC. http://www.taylorandfrancis.com."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Gomez-Rubio, Virgilio. 2020. Bayesian Inference with INLA. 1st\ned. Boca Raton, Florida: Chapman; Hall/CRC. http://www.taylorandfrancis.com.\n\n\nKurz, Solomon. 2019. Statistical Rethinking with Brms. 1st ed.\nhttps://bookdown.org/content/3890/.\n\n\n———. 2020. Statistical Rethinking with Brms. 2nd ed. https://bookdown.org/content/4857/.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in R and Stan. 2nd ed. Boca Raton,\nFlorida: Chapman; Hall/CRC. http://www.taylorandfrancis.com.\n\n\nXiaofeng Wang, Julian J. Faraway, Yu Ryan Yue. 2018. Bayesian\nRegression Modeling with INLA. 1st ed. Boca Raton, Florida:\nChapman; Hall/CRC. http://www.taylorandfrancis.com."
  }
]